{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85815f8b",
   "metadata": {},
   "source": [
    "# Telecom Churn case study using PCA and Ensemble\n",
    "\n",
    "### Problem Statement\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "\n",
    "For many incumbent operators, retaining high profitable customers is the number one business\n",
    "goal. To reduce customer churn, telecom companies need to predict which customers are at high risk of churn. In this project, you will analyze customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn.\n",
    "\n",
    "In this competition, your goal is to build a machine learning model that is able to predict churning customers based on the features provided for their usage.\n",
    "\n",
    "### Goal\n",
    "It is your job to predict if a customer will churn, given the ~170 columns containing customer behavior, usage patterns, payment patterns, and other features that might be relevant. Your target variable is \"churn_probability\"\n",
    "Note: Make sure your accuracy is greater than the sample submission that is present in the leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5dfb968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db327e7",
   "metadata": {},
   "source": [
    "## Step 1. Reading, Understanding and Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b4d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_train_df = pd.read_csv('train (1).csv')\n",
    "telecom_test_df = pd.read_csv('test (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aafd7bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>...</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>31.277</td>\n",
       "      <td>87.009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>122.787</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>60.806</td>\n",
       "      <td>103.176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>156.362</td>\n",
       "      <td>205.260</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>240.708</td>\n",
       "      <td>128.191</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0   0        109             0.0             0.0             0.0   \n",
       "1   1        109             0.0             0.0             0.0   \n",
       "2   2        109             0.0             0.0             0.0   \n",
       "3   3        109             0.0             0.0             0.0   \n",
       "4   4        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8   arpu_6  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   31.277   \n",
       "1            6/30/2014            7/31/2014            8/31/2014    0.000   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   60.806   \n",
       "3            6/30/2014            7/31/2014            8/31/2014  156.362   \n",
       "4            6/30/2014            7/31/2014            8/31/2014  240.708   \n",
       "\n",
       "    arpu_7  ...  sachet_3g_7  sachet_3g_8  fb_user_6  fb_user_7  fb_user_8  \\\n",
       "0   87.009  ...            0            0        NaN        NaN        NaN   \n",
       "1  122.787  ...            0            0        NaN        1.0        NaN   \n",
       "2  103.176  ...            0            0        NaN        NaN        NaN   \n",
       "3  205.260  ...            0            0        NaN        NaN        NaN   \n",
       "4  128.191  ...            1            0        1.0        1.0        1.0   \n",
       "\n",
       "    aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  churn_probability  \n",
       "0  1958         0.0         0.0         0.0                  0  \n",
       "1   710         0.0         0.0         0.0                  0  \n",
       "2   882         0.0         0.0         0.0                  0  \n",
       "3   982         0.0         0.0         0.0                  0  \n",
       "4   647         0.0         0.0         0.0                  0  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ff9072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>...</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69999</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>91.882</td>\n",
       "      <td>65.330</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1692</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>414.168</td>\n",
       "      <td>515.568</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2533</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70001</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>329.844</td>\n",
       "      <td>434.884</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>525.61</td>\n",
       "      <td>758.41</td>\n",
       "      <td>241.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70002</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>43.550</td>\n",
       "      <td>171.390</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70003</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>306.854</td>\n",
       "      <td>406.289</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>462</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0  69999        109             0.0             0.0             0.0   \n",
       "1  70000        109             0.0             0.0             0.0   \n",
       "2  70001        109             0.0             0.0             0.0   \n",
       "3  70002        109             0.0             0.0             0.0   \n",
       "4  70003        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8   arpu_6  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   91.882   \n",
       "1            6/30/2014            7/31/2014            8/31/2014  414.168   \n",
       "2            6/30/2014            7/31/2014            8/31/2014  329.844   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   43.550   \n",
       "4            6/30/2014            7/31/2014            8/31/2014  306.854   \n",
       "\n",
       "    arpu_7  ...  sachet_3g_6  sachet_3g_7  sachet_3g_8  fb_user_6  fb_user_7  \\\n",
       "0   65.330  ...            0            0            0        NaN        NaN   \n",
       "1  515.568  ...            0            0            0        NaN        NaN   \n",
       "2  434.884  ...            0            0            0        NaN        NaN   \n",
       "3  171.390  ...            0            0            0        NaN        NaN   \n",
       "4  406.289  ...            0            0            0        NaN        NaN   \n",
       "\n",
       "   fb_user_8   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \n",
       "0        NaN  1692        0.00        0.00        0.00  \n",
       "1        NaN  2533        0.00        0.00        0.00  \n",
       "2        NaN   277      525.61      758.41      241.84  \n",
       "3        NaN  1244        0.00        0.00        0.00  \n",
       "4        NaN   462        0.00        0.00        0.00  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3eee97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 172)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade9e8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 171)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5176fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'circle_id', 'loc_og_t2o_mou', 'std_og_t2o_mou', 'loc_ic_t2o_mou',\n",
       "       'last_date_of_month_6', 'last_date_of_month_7', 'last_date_of_month_8',\n",
       "       'arpu_6', 'arpu_7',\n",
       "       ...\n",
       "       'sachet_3g_7', 'sachet_3g_8', 'fb_user_6', 'fb_user_7', 'fb_user_8',\n",
       "       'aon', 'aug_vbc_3g', 'jul_vbc_3g', 'jun_vbc_3g', 'churn_probability'],\n",
       "      dtype='object', length=172)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd748c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69999 entries, 0 to 69998\n",
      "Columns: 172 entries, id to churn_probability\n",
      "dtypes: float64(135), int64(28), object(9)\n",
      "memory usage: 91.9+ MB\n"
     ]
    }
   ],
   "source": [
    "telecom_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6803651e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>...</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.0</td>\n",
       "      <td>69297.0</td>\n",
       "      <td>69297.0</td>\n",
       "      <td>69297.0</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.00000</td>\n",
       "      <td>69999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34999.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283.134365</td>\n",
       "      <td>278.185912</td>\n",
       "      <td>278.858826</td>\n",
       "      <td>133.153275</td>\n",
       "      <td>133.894438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081444</td>\n",
       "      <td>0.085487</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.909544</td>\n",
       "      <td>0.890319</td>\n",
       "      <td>1220.639709</td>\n",
       "      <td>68.108597</td>\n",
       "      <td>65.935830</td>\n",
       "      <td>60.07674</td>\n",
       "      <td>0.101887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20207.115084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.213918</td>\n",
       "      <td>344.366927</td>\n",
       "      <td>351.924315</td>\n",
       "      <td>299.963093</td>\n",
       "      <td>311.277193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634547</td>\n",
       "      <td>0.680035</td>\n",
       "      <td>0.276907</td>\n",
       "      <td>0.286842</td>\n",
       "      <td>0.312501</td>\n",
       "      <td>952.426321</td>\n",
       "      <td>269.328659</td>\n",
       "      <td>267.899034</td>\n",
       "      <td>257.22681</td>\n",
       "      <td>0.302502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2258.709000</td>\n",
       "      <td>-1289.715000</td>\n",
       "      <td>-945.808000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17499.500000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.581000</td>\n",
       "      <td>86.714000</td>\n",
       "      <td>84.095000</td>\n",
       "      <td>7.410000</td>\n",
       "      <td>6.675000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34999.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.484000</td>\n",
       "      <td>191.588000</td>\n",
       "      <td>192.234000</td>\n",
       "      <td>34.110000</td>\n",
       "      <td>32.280000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>868.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52498.500000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370.791000</td>\n",
       "      <td>365.369500</td>\n",
       "      <td>369.909000</td>\n",
       "      <td>119.390000</td>\n",
       "      <td>115.837500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1813.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69998.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27731.088000</td>\n",
       "      <td>35145.834000</td>\n",
       "      <td>33543.624000</td>\n",
       "      <td>7376.710000</td>\n",
       "      <td>8157.780000</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4337.000000</td>\n",
       "      <td>12916.220000</td>\n",
       "      <td>9165.600000</td>\n",
       "      <td>11166.21000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  \\\n",
       "count  69999.000000    69999.0         69297.0         69297.0   \n",
       "mean   34999.000000      109.0             0.0             0.0   \n",
       "std    20207.115084        0.0             0.0             0.0   \n",
       "min        0.000000      109.0             0.0             0.0   \n",
       "25%    17499.500000      109.0             0.0             0.0   \n",
       "50%    34999.000000      109.0             0.0             0.0   \n",
       "75%    52498.500000      109.0             0.0             0.0   \n",
       "max    69998.000000      109.0             0.0             0.0   \n",
       "\n",
       "       loc_ic_t2o_mou        arpu_6        arpu_7        arpu_8   onnet_mou_6  \\\n",
       "count         69297.0  69999.000000  69999.000000  69999.000000  67231.000000   \n",
       "mean              0.0    283.134365    278.185912    278.858826    133.153275   \n",
       "std               0.0    334.213918    344.366927    351.924315    299.963093   \n",
       "min               0.0  -2258.709000  -1289.715000   -945.808000      0.000000   \n",
       "25%               0.0     93.581000     86.714000     84.095000      7.410000   \n",
       "50%               0.0    197.484000    191.588000    192.234000     34.110000   \n",
       "75%               0.0    370.791000    365.369500    369.909000    119.390000   \n",
       "max               0.0  27731.088000  35145.834000  33543.624000   7376.710000   \n",
       "\n",
       "        onnet_mou_7  ...   sachet_3g_7   sachet_3g_8     fb_user_6  \\\n",
       "count  67312.000000  ...  69999.000000  69999.000000  17568.000000   \n",
       "mean     133.894438  ...      0.081444      0.085487      0.916325   \n",
       "std      311.277193  ...      0.634547      0.680035      0.276907   \n",
       "min        0.000000  ...      0.000000      0.000000      0.000000   \n",
       "25%        6.675000  ...      0.000000      0.000000      1.000000   \n",
       "50%       32.280000  ...      0.000000      0.000000      1.000000   \n",
       "75%      115.837500  ...      0.000000      0.000000      1.000000   \n",
       "max     8157.780000  ...     33.000000     41.000000      1.000000   \n",
       "\n",
       "          fb_user_7     fb_user_8           aon    aug_vbc_3g    jul_vbc_3g  \\\n",
       "count  17865.000000  18417.000000  69999.000000  69999.000000  69999.000000   \n",
       "mean       0.909544      0.890319   1220.639709     68.108597     65.935830   \n",
       "std        0.286842      0.312501    952.426321    269.328659    267.899034   \n",
       "min        0.000000      0.000000    180.000000      0.000000      0.000000   \n",
       "25%        1.000000      1.000000    468.000000      0.000000      0.000000   \n",
       "50%        1.000000      1.000000    868.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.000000   1813.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000   4337.000000  12916.220000   9165.600000   \n",
       "\n",
       "        jun_vbc_3g  churn_probability  \n",
       "count  69999.00000       69999.000000  \n",
       "mean      60.07674           0.101887  \n",
       "std      257.22681           0.302502  \n",
       "min        0.00000           0.000000  \n",
       "25%        0.00000           0.000000  \n",
       "50%        0.00000           0.000000  \n",
       "75%        0.00000           0.000000  \n",
       "max    11166.21000           1.000000  \n",
       "\n",
       "[8 rows x 163 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be15a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "circle_id              0\n",
       "loc_og_t2o_mou       702\n",
       "std_og_t2o_mou       702\n",
       "loc_ic_t2o_mou       702\n",
       "                    ... \n",
       "aon                    0\n",
       "aug_vbc_3g             0\n",
       "jul_vbc_3g             0\n",
       "jun_vbc_3g             0\n",
       "churn_probability      0\n",
       "Length: 172, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be40b9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "circle_id              int64\n",
       "loc_og_t2o_mou       float64\n",
       "std_og_t2o_mou       float64\n",
       "loc_ic_t2o_mou       float64\n",
       "                      ...   \n",
       "aon                    int64\n",
       "aug_vbc_3g           float64\n",
       "jul_vbc_3g           float64\n",
       "jun_vbc_3g           float64\n",
       "churn_probability      int64\n",
       "Length: 172, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6b6c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns which we have to impute as Zero as thy should not be dropped based on missing values becuase they are important.\n",
    "rech_cols_to_impute = [x for x in telecom_train_df.columns if 'rech' in x and \n",
    "                       'count' not in x and 'date' not in x and 'num' not in x]\n",
    "telecom_train_df[rech_cols_to_impute] = telecom_train_df[rech_cols_to_impute].apply(lambda x: x.fillna(0))\n",
    "telecom_test_df[rech_cols_to_impute] = telecom_test_df[rech_cols_to_impute].apply(lambda x: x.fillna(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c81836f",
   "metadata": {},
   "source": [
    "### Dropping rows for both train and test datasets\n",
    " - Rows which are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "060c74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_train_df.dropna(axis=0, how='all', inplace=True)\n",
    "telecom_test_df.dropna(axis=0, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af10b97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69999, 172)\n",
      "(30000, 171)\n"
     ]
    }
   ],
   "source": [
    "print(telecom_train_df.shape)\n",
    "print(telecom_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e06618c",
   "metadata": {},
   "source": [
    "### Dropping columns for both train and test datasets\n",
    "\n",
    "    - Not needed columns like Id, last_date_of_month_6 etc.\n",
    "    - Columns having more than 70% values as null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abd04209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For us dates doesn't matter as long as customer is doing a recharge.\n",
    "cols_to_delete = ['id', 'last_date_of_month_6', 'last_date_of_month_7', 'last_date_of_month_8',\n",
    "                  'date_of_last_rech_data_6', 'date_of_last_rech_data_7', 'date_of_last_rech_data_8',\n",
    "                  'date_of_last_rech_6', 'date_of_last_rech_7', 'date_of_last_rech_8'\n",
    "                 ]\n",
    "telecom_train_df.drop(cols_to_delete, axis=1, inplace=True)\n",
    "telecom_test_df.drop(cols_to_delete, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d5907c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arpu_3g_8           0.74\n",
       "night_pck_user_8    0.74\n",
       "night_pck_user_7    0.74\n",
       "arpu_2g_8           0.74\n",
       "arpu_2g_7           0.74\n",
       "fb_user_7           0.74\n",
       "arpu_3g_7           0.74\n",
       "fb_user_8           0.74\n",
       "count_rech_3g_8     0.74\n",
       "count_rech_3g_7     0.74\n",
       "count_rech_2g_8     0.74\n",
       "count_rech_2g_7     0.74\n",
       "arpu_2g_6           0.75\n",
       "count_rech_3g_6     0.75\n",
       "night_pck_user_6    0.75\n",
       "fb_user_6           0.75\n",
       "arpu_3g_6           0.75\n",
       "count_rech_2g_6     0.75\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check the % of null values\n",
    "round((pd.isnull(telecom_train_df).sum()/len(telecom_train_df.index)),2)[pd.isnull(telecom_train_df).sum()/ len(telecom_train_df.index) > 0.70].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af4da69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of missing data > 70% columns in train dataset\n",
    "len(round((pd.isnull(telecom_train_df).sum()/len(telecom_train_df.index)),2)[pd.isnull(telecom_train_df).sum()/ len(telecom_train_df.index) > 0.70].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08b6ed61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of missing data > 70% columns in test dataset\n",
    "len(round((pd.isnull(telecom_test_df).sum()/len(telecom_test_df.index)),2)[pd.isnull(telecom_test_df).sum()/ len(telecom_test_df.index) > 0.70].sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b77121",
   "metadata": {},
   "source": [
    "### As we have more than 70% data as null for 18 columns in train and test, we are dropping these columns from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "176525b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_delete = ((pd.isnull(telecom_train_df).sum()/len(telecom_train_df.index))[pd.isnull(telecom_train_df).sum()/ len(telecom_train_df.index) > 0.70].sort_values()).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "decb3b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arpu_3g_8', 'night_pck_user_8', 'arpu_2g_8', 'count_rech_3g_8', 'fb_user_8', 'count_rech_2g_8', 'arpu_3g_7', 'fb_user_7', 'arpu_2g_7', 'night_pck_user_7', 'count_rech_2g_7', 'count_rech_3g_7', 'count_rech_3g_6', 'arpu_3g_6', 'arpu_2g_6', 'night_pck_user_6', 'fb_user_6', 'count_rech_2g_6']\n"
     ]
    }
   ],
   "source": [
    "cols_to_delete = cols_to_delete.to_list()\n",
    "print(cols_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03312c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_train_df = telecom_train_df.drop(cols_to_delete, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be9a60c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 144)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ada9939",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_test_df = telecom_test_df.drop(cols_to_delete, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa95c6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 143)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e359e28",
   "metadata": {},
   "source": [
    "## Lets check the data types of columns now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51cfe2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 69999 entries, 0 to 69998\n",
      "Columns: 144 entries, circle_id to churn_probability\n",
      "dtypes: float64(117), int64(27)\n",
      "memory usage: 77.4 MB\n"
     ]
    }
   ],
   "source": [
    "telecom_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d47ca287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 30000 entries, 0 to 29999\n",
      "Columns: 143 entries, circle_id to jun_vbc_3g\n",
      "dtypes: float64(117), int64(26)\n",
      "memory usage: 33.0 MB\n"
     ]
    }
   ],
   "source": [
    "telecom_test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0444c3e",
   "metadata": {},
   "source": [
    "### We can see now we don't have any categorical data, all are numerical data only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80afd3",
   "metadata": {},
   "source": [
    "### Imputing the na values with\n",
    " - Median for numerical variables\n",
    " - Mode for categorical variables - Not needed in out this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ce3ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A generic method to impute na\n",
    "def replace_na(df, columns, data_type):\n",
    "    for col in columns:\n",
    "        if data_type == 'categorical':\n",
    "            value = pd.to_datetime(df[col]).mode()\n",
    "        else:\n",
    "            value = df[col].median()\n",
    "        df[col].fillna(value, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b802153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_train_df = replace_na(telecom_train_df, telecom_train_df.columns, 'numerical')\n",
    "telecom_test_df = replace_na(telecom_test_df, telecom_test_df.columns, 'numerical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21f588",
   "metadata": {},
   "source": [
    "### Lets check for unique entries in train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bafbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_to_delete_unique(df, df_columns, threshold=4):\n",
    "    # threshold=4 means column has only 1 unique value\n",
    "    # eg. telecom_train_df['circle_id'].describe().unique() --> array([30000.,   109.,     0.])\n",
    "    # Here because there are all 109 in column, we have only 3 entries in array.\n",
    "    cols_to_delete = []\n",
    "    for column in df_columns:\n",
    "        if len(df[column].describe().unique()) < threshold:\n",
    "            cols_to_delete.append(column)\n",
    "    \n",
    "    return cols_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf0895de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69999, 144)\n",
      "(30000, 143)\n"
     ]
    }
   ],
   "source": [
    "print(telecom_train_df.shape)\n",
    "print(telecom_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c597e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69999, 134)\n",
      "(30000, 133)\n"
     ]
    }
   ],
   "source": [
    "# on train data\n",
    "telecom_train_df = telecom_train_df.drop(cols_to_delete_unique(telecom_train_df, telecom_train_df.columns), axis=1)\n",
    "print(telecom_train_df.shape)\n",
    "\n",
    "# on test data\n",
    "telecom_test_df = telecom_test_df.drop(cols_to_delete_unique(telecom_test_df, telecom_test_df.columns), axis=1)\n",
    "print(telecom_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6d3fb",
   "metadata": {},
   "source": [
    "### Lets find the high value customers based on recharge done in 6th and 7th month and update dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6656b1",
   "metadata": {},
   "source": [
    "### For train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea5fecfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total data recharge in 6th, 7th and 8th months\n",
    "telecom_train_df[\"total_data_recharge_amnt_6\"] = telecom_train_df.total_rech_data_6 * telecom_train_df.av_rech_amt_data_6\n",
    "telecom_train_df[\"total_data_recharge_amnt_7\"] = telecom_train_df.total_rech_data_7 * telecom_train_df.av_rech_amt_data_7\n",
    "telecom_train_df[\"total_data_recharge_amnt_8\"] = telecom_train_df.total_rech_data_8 * telecom_train_df.av_rech_amt_data_8\n",
    "\n",
    "# total amount spent on recharge in 6th, 7th and 8th months\n",
    "telecom_train_df[\"total_recharge_amnt_6\"] = telecom_train_df.total_rech_amt_6 + telecom_train_df.total_data_recharge_amnt_6\n",
    "telecom_train_df[\"total_recharge_amnt_7\"] = telecom_train_df.total_rech_amt_7 + telecom_train_df.total_data_recharge_amnt_7\n",
    "telecom_train_df[\"total_recharge_amnt_8\"] = telecom_train_df.total_rech_amt_8 + telecom_train_df.total_data_recharge_amnt_8\n",
    "\n",
    "# average recharge for 6th and 7th month\n",
    "telecom_train_df['average_amnt_6_7'] = (telecom_train_df[\"total_recharge_amnt_6\"] + telecom_train_df[\"total_recharge_amnt_7\"])/2\n",
    "\n",
    "# 70th percentile of average_amnt_6_7\n",
    "telecom_train_df['average_amnt_6_7'].quantile(.70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0768613e",
   "metadata": {},
   "source": [
    "## Filter dataset based on average_amnt_6_7 (70th percentile for train dataset is 477.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5af14b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_train_df = telecom_train_df[telecom_train_df[\"average_amnt_6_7\"]>= telecom_train_df[\"average_amnt_6_7\"].quantile(.70)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "982270cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21013, 141)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db1002",
   "metadata": {},
   "source": [
    "## Lets visualize the 8th month and average_amnt_6_7 months data to check behavior pattern of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34e0ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look it later\n",
    "#plt.scatter(telecom_train_df[['average_amnt_6_7', 'total_recharge_amnt_8']])\n",
    "#plt.show()\n",
    "#sns.\n",
    "#telecom_train_df.plot.scatter(x='average_amnt_6_7', y='total_recharge_amnt_8')\n",
    "#telecom_train_df.DataFrame(np.random.rand(10, 3), columns =['average_amnt_6_7', 'total_recharge_amnt_8'])\n",
    "\n",
    "#telecom_train_df.plot.bar(x=\"average_amnt_6_7\", y=\"total_recharge_amnt_8\", rot=70);\n",
    "\n",
    "#ig, ax = plt.subplots()\n",
    "\n",
    "#ax.plot(telecom_train_df['average_amnt_6_7'], telecom_train_df['total_recharge_amnt_8'])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3127d8b",
   "metadata": {},
   "source": [
    "### For test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f97c52c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total data recharge in 6th, 7th and 8th months\n",
    "telecom_test_df[\"total_data_recharge_amnt_6\"] = telecom_test_df.total_rech_data_6 * telecom_test_df.av_rech_amt_data_6\n",
    "telecom_test_df[\"total_data_recharge_amnt_7\"] = telecom_test_df.total_rech_data_7 * telecom_test_df.av_rech_amt_data_7\n",
    "telecom_test_df[\"total_data_recharge_amnt_8\"] = telecom_test_df.total_rech_data_8 * telecom_test_df.av_rech_amt_data_8\n",
    "\n",
    "# total amount spent on recharge in 6th, 7th and 8th months\n",
    "telecom_test_df[\"total_recharge_amnt_6\"] = telecom_test_df.total_rech_amt_6 + telecom_test_df.total_data_recharge_amnt_6\n",
    "telecom_test_df[\"total_recharge_amnt_7\"] = telecom_test_df.total_rech_amt_7 + telecom_test_df.total_data_recharge_amnt_7\n",
    "telecom_test_df[\"total_recharge_amnt_8\"] = telecom_test_df.total_rech_amt_8 + telecom_test_df.total_data_recharge_amnt_8\n",
    "\n",
    "# average recharge\n",
    "telecom_test_df['average_amnt_6_7'] = (telecom_test_df[\"total_recharge_amnt_6\"] + telecom_test_df[\"total_recharge_amnt_7\"])/2\n",
    "\n",
    "# 70th percentile of average_amnt_6_7\n",
    "telecom_test_df['average_amnt_6_7'].quantile(.70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10222eb0",
   "metadata": {},
   "source": [
    "### Filter dataset based on average_amnt_6_7 (70th percentile for test dataset is 478.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cf6d5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9003, 140)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_test_df = telecom_test_df[telecom_test_df[\"average_amnt_6_7\"]>= telecom_test_df[\"average_amnt_6_7\"].quantile(.70)]\n",
    "telecom_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40627e53",
   "metadata": {},
   "source": [
    "## Lets focus on Outliers now and treat them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0b9f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic method to remove outliers\n",
    "def remove_outliers(df, features):\n",
    "    for feature in features:\n",
    "        q1 = df[feature].quantile(0.25)\n",
    "        q3 = df[feature].quantile(0.99)\n",
    "        iqr = q3-q1\n",
    "        lower_value  = q1 - (1.5 * iqr)\n",
    "        higer_value = q3 + (1.5 * iqr)\n",
    "        df = df[(df[feature] <= higer_value) & (df[feature] >= lower_value)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "537a1234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#telecom_train_df = remove_outliers(telecom_train_df, telecom_train_df.columns)\n",
    "#telecom_test_df = remove_outliers(telecom_test_df, telecom_test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09c79cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21013, 141)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7911de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9003, 140)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad731d80",
   "metadata": {},
   "source": [
    "## Let's check for Data imbalance here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7df398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data_rows = telecom_train_df['churn_probability'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "addc0c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.275829248560415"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_data_rows/len(telecom_train_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa850d6",
   "metadata": {},
   "source": [
    "### We can see that there is a data imbalance. We have only about 8.28% of data as Churn and 91.72% as not churn.\n",
    "### So we need to apply data imbalance technique. We will use SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624b7f7",
   "metadata": {},
   "source": [
    "## Dividing the data from telecom_train_df to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c3467e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = telecom_train_df['churn_probability']\n",
    "X = telecom_train_df.drop(['churn_probability'], axis=1)\n",
    "\n",
    "telecom_train_df.drop('churn_probability', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3edc2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad1282",
   "metadata": {},
   "source": [
    "## Taking a backup of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20dae04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ori, X_test_ori, y_train_ori, y_test_ori = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5496cd44",
   "metadata": {},
   "source": [
    "## Rescaling of the variables\n",
    "\n",
    "- We will use Min-Max scaling (Normalization) --> compresses all the data between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ad21932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>total_data_recharge_amnt_6</th>\n",
       "      <th>total_data_recharge_amnt_7</th>\n",
       "      <th>total_data_recharge_amnt_8</th>\n",
       "      <th>total_recharge_amnt_6</th>\n",
       "      <th>total_recharge_amnt_7</th>\n",
       "      <th>total_recharge_amnt_8</th>\n",
       "      <th>average_amnt_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6968</th>\n",
       "      <td>0.127277</td>\n",
       "      <td>0.274576</td>\n",
       "      <td>0.081830</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.011537</td>\n",
       "      <td>0.040985</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42203</th>\n",
       "      <td>0.156166</td>\n",
       "      <td>0.094305</td>\n",
       "      <td>0.083632</td>\n",
       "      <td>0.066057</td>\n",
       "      <td>0.041462</td>\n",
       "      <td>0.074009</td>\n",
       "      <td>0.065428</td>\n",
       "      <td>0.053213</td>\n",
       "      <td>0.049054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.009557</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>0.002008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18406</th>\n",
       "      <td>0.151447</td>\n",
       "      <td>0.122733</td>\n",
       "      <td>0.087708</td>\n",
       "      <td>0.015153</td>\n",
       "      <td>0.016084</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.056327</td>\n",
       "      <td>0.259820</td>\n",
       "      <td>0.136117</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>0.019367</td>\n",
       "      <td>0.017273</td>\n",
       "      <td>0.009450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21455</th>\n",
       "      <td>0.171177</td>\n",
       "      <td>0.128305</td>\n",
       "      <td>0.077781</td>\n",
       "      <td>0.009636</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.081607</td>\n",
       "      <td>0.121132</td>\n",
       "      <td>0.038009</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.043865</td>\n",
       "      <td>0.039021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011038</td>\n",
       "      <td>0.011124</td>\n",
       "      <td>0.015034</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.023503</td>\n",
       "      <td>0.026840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66143</th>\n",
       "      <td>0.138174</td>\n",
       "      <td>0.087866</td>\n",
       "      <td>0.074838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033354</td>\n",
       "      <td>0.020053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016759</td>\n",
       "      <td>0.045971</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.026593</td>\n",
       "      <td>0.029892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         arpu_6    arpu_7    arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  \\\n",
       "6968   0.127277  0.274576  0.081830     0.004624     0.004018     0.002985   \n",
       "42203  0.156166  0.094305  0.083632     0.066057     0.041462     0.074009   \n",
       "18406  0.151447  0.122733  0.087708     0.015153     0.016084     0.008306   \n",
       "21455  0.171177  0.128305  0.077781     0.009636     0.010909     0.006579   \n",
       "66143  0.138174  0.087866  0.074838     0.000000     0.006171     0.001633   \n",
       "\n",
       "       offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  ...  \\\n",
       "6968       0.011537      0.040985      0.006554       0.000000  ...   \n",
       "42203      0.065428      0.053213      0.049054       0.000000  ...   \n",
       "18406      0.056327      0.259820      0.136117       0.005055  ...   \n",
       "21455      0.081607      0.121132      0.038009       0.005166  ...   \n",
       "66143      0.000000      0.033354      0.020053       0.000000  ...   \n",
       "\n",
       "       aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  total_data_recharge_amnt_6  \\\n",
       "6968     0.000000    0.002051    0.000000                    0.000000   \n",
       "42203    0.000000    0.000000    0.000000                    0.000000   \n",
       "18406    0.000000    0.000000    0.000000                    0.000000   \n",
       "21455    0.029661    0.043865    0.039021                    0.000000   \n",
       "66143    0.098218    0.000000    0.000000                    0.043938   \n",
       "\n",
       "       total_data_recharge_amnt_7  total_data_recharge_amnt_8  \\\n",
       "6968                     0.000000                    0.000000   \n",
       "42203                    0.000000                    0.003787   \n",
       "18406                    0.000000                    0.000000   \n",
       "21455                    0.011038                    0.011124   \n",
       "66143                    0.000000                    0.016759   \n",
       "\n",
       "       total_recharge_amnt_6  total_recharge_amnt_7  total_recharge_amnt_8  \\\n",
       "6968                0.000000               0.096264               0.000000   \n",
       "42203               0.009557               0.009933               0.016496   \n",
       "18406               0.008632               0.019367               0.017273   \n",
       "21455               0.015034               0.032992               0.023503   \n",
       "66143               0.045971               0.006063               0.026593   \n",
       "\n",
       "       average_amnt_6_7  \n",
       "6968           0.069171  \n",
       "42203          0.002008  \n",
       "18406          0.009450  \n",
       "21455          0.026840  \n",
       "66143          0.029892  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "# fit on data\n",
    "# removed churn_probability becuase test data is not having it.\n",
    "# Also churn_probability is having 0 and 1 only. So it need not be scaled.\n",
    "train_numerical_columns = telecom_train_df.columns.to_list()\n",
    "X_train[train_numerical_columns] = scaler.fit_transform(X_train[train_numerical_columns])\n",
    "X_train.head()\n",
    "# So all numberic values are now between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e87381ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37e1ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90982153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27020, 140)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a229479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_resampled)/len(y_resampled) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f8f8db",
   "metadata": {},
   "source": [
    "## Now there is no data imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b84d8439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>total_data_recharge_amnt_6</th>\n",
       "      <th>total_data_recharge_amnt_7</th>\n",
       "      <th>total_data_recharge_amnt_8</th>\n",
       "      <th>total_recharge_amnt_6</th>\n",
       "      <th>total_recharge_amnt_7</th>\n",
       "      <th>total_recharge_amnt_8</th>\n",
       "      <th>average_amnt_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.150615</td>\n",
       "      <td>0.099685</td>\n",
       "      <td>0.064554</td>\n",
       "      <td>0.010236</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.056723</td>\n",
       "      <td>0.092260</td>\n",
       "      <td>0.028195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>0.008917</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>0.000701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.145864</td>\n",
       "      <td>0.095230</td>\n",
       "      <td>0.083592</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040694</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>0.017833</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.008485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.152781</td>\n",
       "      <td>0.091615</td>\n",
       "      <td>0.065131</td>\n",
       "      <td>0.151258</td>\n",
       "      <td>0.103391</td>\n",
       "      <td>0.064113</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011352</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>0.007362</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.190866</td>\n",
       "      <td>0.119009</td>\n",
       "      <td>0.094514</td>\n",
       "      <td>0.053212</td>\n",
       "      <td>0.032421</td>\n",
       "      <td>0.040272</td>\n",
       "      <td>0.024393</td>\n",
       "      <td>0.048810</td>\n",
       "      <td>0.029353</td>\n",
       "      <td>0.012276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022596</td>\n",
       "      <td>0.019973</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.021967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.135918</td>\n",
       "      <td>0.117934</td>\n",
       "      <td>0.085279</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>0.231259</td>\n",
       "      <td>0.138588</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018315</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.014516</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>0.001853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      arpu_6    arpu_7    arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  \\\n",
       "1   0.150615  0.099685  0.064554     0.010236     0.005052     0.001845   \n",
       "2   0.145864  0.095230  0.083592     0.001022     0.000963     0.000781   \n",
       "21  0.152781  0.091615  0.065131     0.151258     0.103391     0.064113   \n",
       "23  0.190866  0.119009  0.094514     0.053212     0.032421     0.040272   \n",
       "26  0.135918  0.117934  0.085279     0.017062     0.231259     0.138588   \n",
       "\n",
       "    offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  ...  aug_vbc_3g  \\\n",
       "1       0.056723      0.092260      0.028195       0.000000  ...    0.000000   \n",
       "2       0.002031      0.006797      0.003215       0.008728  ...    0.040694   \n",
       "21      0.001799      0.004487      0.001984       0.000000  ...    0.000000   \n",
       "23      0.024393      0.048810      0.029353       0.012276  ...    0.000000   \n",
       "26      0.002456      0.017742      0.004589       0.007378  ...    0.014353   \n",
       "\n",
       "    jul_vbc_3g  jun_vbc_3g  total_data_recharge_amnt_6  \\\n",
       "1     0.000000      0.0000                         0.0   \n",
       "2     0.082745      0.0319                         0.0   \n",
       "21    0.000000      0.0000                         0.0   \n",
       "23    0.000000      0.0000                         0.0   \n",
       "26    0.000000      0.0000                         0.0   \n",
       "\n",
       "    total_data_recharge_amnt_7  total_data_recharge_amnt_8  \\\n",
       "1                     0.000000                    0.000000   \n",
       "2                     0.000000                    0.000000   \n",
       "21                    0.000000                    0.000000   \n",
       "23                    0.001816                    0.000000   \n",
       "26                    0.000000                    0.018315   \n",
       "\n",
       "    total_recharge_amnt_6  total_recharge_amnt_7  total_recharge_amnt_8  \\\n",
       "1                0.009067               0.008917               0.008442   \n",
       "2                0.009067               0.017833               0.016884   \n",
       "21               0.011352               0.008845               0.007362   \n",
       "23               0.022596               0.019973               0.019417   \n",
       "26               0.004715               0.014516               0.032468   \n",
       "\n",
       "    average_amnt_6_7  \n",
       "1           0.000701  \n",
       "2           0.008485  \n",
       "21          0.002600  \n",
       "23          0.021967  \n",
       "26          0.001853  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets fit the scaler for train data as well\n",
    "test_numerical_columns = telecom_test_df.columns.to_list()\n",
    "telecom_test_df[test_numerical_columns] = scaler.transform(telecom_test_df[test_numerical_columns])\n",
    "telecom_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c47b1",
   "metadata": {},
   "source": [
    "## Modelling \n",
    "\n",
    "1. Logistic Regression using RFE - To get important predictors for Churn probability\n",
    "2. Logistic Regression - To know Churn probability + PCA\n",
    "    - Lasso\n",
    "    - Ridge\n",
    "3. Tree models\n",
    "    - XGBoost\n",
    "    - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bca16f",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression using RFE - To get importnat predictors for Churn probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd4d9e79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>churn_probability</td> <th>  No. Observations:  </th>  <td> 27020</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>        <th>  Df Residuals:      </th>  <td> 26886</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>      <th>  Df Model:          </th>  <td>   133</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>        <th>  Log-Likelihood:    </th> <td> -8608.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 14 Sep 2022</td>  <th>  Deviance:          </th> <td>  17217.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:37:08</td>      <th>  Pearson chi2:      </th> <td>1.44e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>100</td>        <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                      <td>   -2.4285</td> <td>    0.689</td> <td>   -3.524</td> <td> 0.000</td> <td>   -3.779</td> <td>   -1.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_6</th>                     <td>    2.6441</td> <td>    3.733</td> <td>    0.708</td> <td> 0.479</td> <td>   -4.672</td> <td>    9.961</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_7</th>                     <td>   14.4367</td> <td>    4.447</td> <td>    3.246</td> <td> 0.001</td> <td>    5.720</td> <td>   23.154</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_8</th>                     <td>   36.7215</td> <td>    5.100</td> <td>    7.200</td> <td> 0.000</td> <td>   26.725</td> <td>   46.718</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_6</th>                <td> -108.6588</td> <td>   34.093</td> <td>   -3.187</td> <td> 0.001</td> <td> -175.479</td> <td>  -41.839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_7</th>                <td>  -60.1910</td> <td>   32.538</td> <td>   -1.850</td> <td> 0.064</td> <td> -123.964</td> <td>    3.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_8</th>                <td>   -2.8597</td> <td>   48.949</td> <td>   -0.058</td> <td> 0.953</td> <td>  -98.799</td> <td>   93.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_6</th>               <td> -113.4470</td> <td>   38.288</td> <td>   -2.963</td> <td> 0.003</td> <td> -188.490</td> <td>  -38.404</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_7</th>               <td>  -50.1050</td> <td>   26.087</td> <td>   -1.921</td> <td> 0.055</td> <td> -101.235</td> <td>    1.025</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_8</th>               <td>  -48.5581</td> <td>   62.415</td> <td>   -0.778</td> <td> 0.437</td> <td> -170.889</td> <td>   73.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_ic_mou_6</th>              <td>    1.5657</td> <td>    1.126</td> <td>    1.390</td> <td> 0.164</td> <td>   -0.641</td> <td>    3.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_ic_mou_7</th>              <td>    1.2488</td> <td>    1.324</td> <td>    0.943</td> <td> 0.345</td> <td>   -1.346</td> <td>    3.843</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_ic_mou_8</th>              <td>   -1.7700</td> <td>    1.419</td> <td>   -1.247</td> <td> 0.212</td> <td>   -4.551</td> <td>    1.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_6</th>              <td>   53.9969</td> <td>   17.425</td> <td>    3.099</td> <td> 0.002</td> <td>   19.845</td> <td>   88.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_7</th>              <td>   23.9400</td> <td>   11.007</td> <td>    2.175</td> <td> 0.030</td> <td>    2.366</td> <td>   45.514</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>              <td>   17.5740</td> <td>   24.038</td> <td>    0.731</td> <td> 0.465</td> <td>  -29.539</td> <td>   64.687</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_6</th>           <td>-2.199e+04</td> <td> 2.55e+04</td> <td>   -0.862</td> <td> 0.389</td> <td> -7.2e+04</td> <td>  2.8e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_7</th>           <td>-1803.2706</td> <td> 2.89e+04</td> <td>   -0.062</td> <td> 0.950</td> <td>-5.84e+04</td> <td> 5.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_8</th>           <td> 1.851e+05</td> <td> 4.44e+04</td> <td>    4.170</td> <td> 0.000</td> <td> 9.81e+04</td> <td> 2.72e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_6</th>           <td>-1.607e+04</td> <td> 1.86e+04</td> <td>   -0.862</td> <td> 0.389</td> <td>-5.26e+04</td> <td> 2.05e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>           <td>-1116.5022</td> <td> 1.78e+04</td> <td>   -0.063</td> <td> 0.950</td> <td>-3.59e+04</td> <td> 3.37e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_8</th>           <td> 8.544e+04</td> <td> 2.05e+04</td> <td>    4.171</td> <td> 0.000</td> <td> 4.53e+04</td> <td> 1.26e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_6</th>           <td>-2117.4271</td> <td> 2450.463</td> <td>   -0.864</td> <td> 0.388</td> <td>-6920.246</td> <td> 2685.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_7</th>           <td> -200.3540</td> <td> 3178.992</td> <td>   -0.063</td> <td> 0.950</td> <td>-6431.063</td> <td> 6030.355</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>           <td> 1.013e+04</td> <td> 2428.740</td> <td>    4.172</td> <td> 0.000</td> <td> 5373.287</td> <td> 1.49e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2c_mou_6</th>           <td>   -7.9074</td> <td>    1.540</td> <td>   -5.135</td> <td> 0.000</td> <td>  -10.925</td> <td>   -4.889</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2c_mou_7</th>           <td>   -4.3733</td> <td>    2.682</td> <td>   -1.631</td> <td> 0.103</td> <td>   -9.630</td> <td>    0.883</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2c_mou_8</th>           <td>    7.5812</td> <td>    1.600</td> <td>    4.738</td> <td> 0.000</td> <td>    4.445</td> <td>   10.717</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_6</th>               <td> 1.527e+04</td> <td> 4.78e+04</td> <td>    0.319</td> <td> 0.749</td> <td>-7.84e+04</td> <td> 1.09e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_7</th>               <td>-1.259e+04</td> <td> 3.52e+04</td> <td>   -0.357</td> <td> 0.721</td> <td>-8.17e+04</td> <td> 5.65e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_8</th>               <td>-2.436e+05</td> <td> 5.41e+04</td> <td>   -4.506</td> <td> 0.000</td> <td> -3.5e+05</td> <td>-1.38e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_6</th>           <td>-1.662e+05</td> <td> 3.52e+04</td> <td>   -4.719</td> <td> 0.000</td> <td>-2.35e+05</td> <td>-9.72e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_7</th>           <td>-2.632e+04</td> <td> 4.04e+04</td> <td>   -0.651</td> <td> 0.515</td> <td>-1.06e+05</td> <td> 5.29e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_8</th>           <td> 1.549e+05</td> <td> 4.21e+04</td> <td>    3.684</td> <td> 0.000</td> <td> 7.25e+04</td> <td> 2.37e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_6</th>           <td>-1.876e+05</td> <td> 3.97e+04</td> <td>   -4.720</td> <td> 0.000</td> <td>-2.65e+05</td> <td> -1.1e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_7</th>           <td>-2.143e+04</td> <td> 3.29e+04</td> <td>   -0.651</td> <td> 0.515</td> <td>-8.59e+04</td> <td> 4.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>           <td> 2.697e+05</td> <td> 7.32e+04</td> <td>    3.684</td> <td> 0.000</td> <td> 1.26e+05</td> <td> 4.13e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2f_mou_6</th>           <td>-7626.5095</td> <td> 1615.935</td> <td>   -4.720</td> <td> 0.000</td> <td>-1.08e+04</td> <td>-4459.335</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2f_mou_7</th>           <td>-1508.5269</td> <td> 2315.193</td> <td>   -0.652</td> <td> 0.515</td> <td>-6046.222</td> <td> 3029.168</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2f_mou_8</th>           <td> 6840.8481</td> <td> 1858.923</td> <td>    3.680</td> <td> 0.000</td> <td> 3197.427</td> <td> 1.05e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_6</th>               <td> 1.735e+05</td> <td> 4.38e+04</td> <td>    3.962</td> <td> 0.000</td> <td> 8.77e+04</td> <td> 2.59e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>               <td> 1.102e+04</td> <td>  4.5e+04</td> <td>    0.245</td> <td> 0.807</td> <td>-7.72e+04</td> <td> 9.92e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_8</th>               <td>-3.381e+05</td> <td> 8.12e+04</td> <td>   -4.165</td> <td> 0.000</td> <td>-4.97e+05</td> <td>-1.79e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_og_mou_6</th>               <td>-1.174e+04</td> <td> 1.72e+04</td> <td>   -0.684</td> <td> 0.494</td> <td>-4.54e+04</td> <td> 2.19e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_og_mou_7</th>               <td>-1.038e+04</td> <td> 1.78e+04</td> <td>   -0.584</td> <td> 0.559</td> <td>-4.52e+04</td> <td> 2.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_og_mou_8</th>               <td>-2.758e+04</td> <td> 1.89e+04</td> <td>   -1.460</td> <td> 0.144</td> <td>-6.46e+04</td> <td> 9437.563</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_og_mou_6</th>               <td>-2030.9713</td> <td> 2977.772</td> <td>   -0.682</td> <td> 0.495</td> <td>-7867.298</td> <td> 3805.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_og_mou_7</th>               <td>-2392.8243</td> <td> 4096.948</td> <td>   -0.584</td> <td> 0.559</td> <td>-1.04e+04</td> <td> 5637.046</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_og_mou_8</th>               <td>-3806.0950</td> <td> 2605.739</td> <td>   -1.461</td> <td> 0.144</td> <td>-8913.250</td> <td> 1301.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>og_others_6</th>                <td>-1245.0736</td> <td> 1776.319</td> <td>   -0.701</td> <td> 0.483</td> <td>-4726.595</td> <td> 2236.448</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>og_others_7</th>                <td> -148.3731</td> <td>  217.740</td> <td>   -0.681</td> <td> 0.496</td> <td> -575.135</td> <td>  278.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>og_others_8</th>                <td>-2195.3611</td> <td> 1327.334</td> <td>   -1.654</td> <td> 0.098</td> <td>-4796.887</td> <td>  406.165</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>             <td> 2.135e+04</td> <td> 3.11e+04</td> <td>    0.687</td> <td> 0.492</td> <td>-3.95e+04</td> <td> 8.22e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_7</th>             <td> 1.568e+04</td> <td> 2.68e+04</td> <td>    0.585</td> <td> 0.559</td> <td>-3.69e+04</td> <td> 6.82e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_8</th>             <td> 6.813e+04</td> <td> 4.67e+04</td> <td>    1.459</td> <td> 0.144</td> <td>-2.34e+04</td> <td>  1.6e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_6</th>           <td>-1.018e+05</td> <td> 1.64e+04</td> <td>   -6.220</td> <td> 0.000</td> <td>-1.34e+05</td> <td>-6.97e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_7</th>           <td>  6.21e+04</td> <td> 2.14e+04</td> <td>    2.895</td> <td> 0.004</td> <td> 2.01e+04</td> <td> 1.04e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_8</th>           <td> 1.381e+05</td> <td> 1.52e+04</td> <td>    9.090</td> <td> 0.000</td> <td> 1.08e+05</td> <td> 1.68e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_6</th>           <td>-1.039e+05</td> <td> 1.67e+04</td> <td>   -6.220</td> <td> 0.000</td> <td>-1.37e+05</td> <td>-7.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_7</th>           <td>  4.38e+04</td> <td> 1.51e+04</td> <td>    2.895</td> <td> 0.004</td> <td> 1.42e+04</td> <td> 7.35e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_8</th>           <td> 1.614e+05</td> <td> 1.78e+04</td> <td>    9.090</td> <td> 0.000</td> <td> 1.27e+05</td> <td> 1.96e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_6</th>           <td>-3.205e+04</td> <td> 5151.160</td> <td>   -6.222</td> <td> 0.000</td> <td>-4.21e+04</td> <td> -2.2e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_7</th>           <td> 2.158e+04</td> <td> 7449.499</td> <td>    2.897</td> <td> 0.004</td> <td> 6981.513</td> <td> 3.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>           <td> 5.073e+04</td> <td> 5581.819</td> <td>    9.088</td> <td> 0.000</td> <td> 3.98e+04</td> <td> 6.17e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_6</th>               <td> 1.342e+05</td> <td> 2.82e+04</td> <td>    4.764</td> <td> 0.000</td> <td>  7.9e+04</td> <td> 1.89e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_7</th>               <td>-5.241e+04</td> <td> 2.51e+04</td> <td>   -2.091</td> <td> 0.037</td> <td>-1.02e+05</td> <td>-3288.414</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>               <td>-1.096e+05</td> <td> 2.08e+04</td> <td>   -5.279</td> <td> 0.000</td> <td> -1.5e+05</td> <td>-6.89e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_6</th>           <td>-9278.7064</td> <td> 1.44e+04</td> <td>   -0.643</td> <td> 0.521</td> <td>-3.76e+04</td> <td>  1.9e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_7</th>           <td>-4.942e+04</td> <td> 2.05e+04</td> <td>   -2.406</td> <td> 0.016</td> <td>-8.97e+04</td> <td>-9162.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_8</th>           <td> 5.071e+04</td> <td> 1.81e+04</td> <td>    2.804</td> <td> 0.005</td> <td> 1.53e+04</td> <td> 8.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_6</th>           <td>-1.104e+04</td> <td> 1.72e+04</td> <td>   -0.643</td> <td> 0.521</td> <td>-4.47e+04</td> <td> 2.26e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_7</th>           <td>-3.069e+04</td> <td> 1.28e+04</td> <td>   -2.407</td> <td> 0.016</td> <td>-5.57e+04</td> <td>-5697.677</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_8</th>           <td> 4.267e+04</td> <td> 1.52e+04</td> <td>    2.805</td> <td> 0.005</td> <td> 1.29e+04</td> <td> 7.25e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2f_mou_6</th>           <td>-4136.8282</td> <td> 6422.039</td> <td>   -0.644</td> <td> 0.519</td> <td>-1.67e+04</td> <td> 8450.137</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2f_mou_7</th>           <td>-1.325e+04</td> <td> 5510.036</td> <td>   -2.405</td> <td> 0.016</td> <td> -2.4e+04</td> <td>-2450.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2f_mou_8</th>           <td> 2.066e+04</td> <td> 7368.461</td> <td>    2.804</td> <td> 0.005</td> <td> 6217.252</td> <td> 3.51e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_6</th>               <td>-8256.5728</td> <td> 1.79e+04</td> <td>   -0.460</td> <td> 0.645</td> <td>-4.34e+04</td> <td> 2.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_7</th>               <td> 6.244e+04</td> <td> 2.22e+04</td> <td>    2.813</td> <td> 0.005</td> <td> 1.89e+04</td> <td> 1.06e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_8</th>               <td>-2705.4832</td> <td>  2.1e+04</td> <td>   -0.129</td> <td> 0.897</td> <td>-4.38e+04</td> <td> 3.84e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_6</th>             <td> 4.118e+04</td> <td> 1.81e+04</td> <td>    2.279</td> <td> 0.023</td> <td> 5758.923</td> <td> 7.66e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_7</th>             <td>-2.062e+04</td> <td> 1.87e+04</td> <td>   -1.104</td> <td> 0.269</td> <td>-5.72e+04</td> <td>  1.6e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_8</th>             <td>-8.556e+04</td> <td> 1.55e+04</td> <td>   -5.536</td> <td> 0.000</td> <td>-1.16e+05</td> <td>-5.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_6</th>               <td>  -97.6341</td> <td>   46.802</td> <td>   -2.086</td> <td> 0.037</td> <td> -189.365</td> <td>   -5.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_7</th>               <td>   31.0942</td> <td>   34.050</td> <td>    0.913</td> <td> 0.361</td> <td>  -35.643</td> <td>   97.831</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_8</th>               <td>   10.9361</td> <td>    3.297</td> <td>    3.317</td> <td> 0.001</td> <td>    4.475</td> <td>   17.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_ic_mou_6</th>               <td>-3.624e+04</td> <td> 1.59e+04</td> <td>   -2.279</td> <td> 0.023</td> <td>-6.74e+04</td> <td>-5066.775</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_ic_mou_7</th>               <td>  1.25e+04</td> <td> 1.13e+04</td> <td>    1.104</td> <td> 0.270</td> <td>-9694.705</td> <td> 3.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_ic_mou_8</th>               <td> 3.381e+04</td> <td> 6106.282</td> <td>    5.536</td> <td> 0.000</td> <td> 2.18e+04</td> <td> 4.58e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ic_others_6</th>                <td>-7199.3129</td> <td> 3149.195</td> <td>   -2.286</td> <td> 0.022</td> <td>-1.34e+04</td> <td>-1027.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ic_others_7</th>                <td> 4149.6726</td> <td> 3753.378</td> <td>    1.106</td> <td> 0.269</td> <td>-3206.814</td> <td> 1.15e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ic_others_8</th>                <td> 1.707e+04</td> <td> 3082.551</td> <td>    5.538</td> <td> 0.000</td> <td>  1.1e+04</td> <td> 2.31e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_6</th>           <td>   -1.1331</td> <td>    0.730</td> <td>   -1.551</td> <td> 0.121</td> <td>   -2.565</td> <td>    0.298</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_7</th>           <td>    5.0477</td> <td>    0.730</td> <td>    6.912</td> <td> 0.000</td> <td>    3.616</td> <td>    6.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_8</th>           <td>   -8.0932</td> <td>    0.838</td> <td>   -9.663</td> <td> 0.000</td> <td>   -9.735</td> <td>   -6.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_6</th>           <td>    6.0418</td> <td>    3.168</td> <td>    1.907</td> <td> 0.057</td> <td>   -0.168</td> <td>   12.252</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_7</th>           <td>   -9.4816</td> <td>    3.710</td> <td>   -2.556</td> <td> 0.011</td> <td>  -16.753</td> <td>   -2.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_8</th>           <td>  -33.0258</td> <td>    4.309</td> <td>   -7.664</td> <td> 0.000</td> <td>  -41.472</td> <td>  -24.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_6</th>             <td>   -3.9072</td> <td>    1.022</td> <td>   -3.824</td> <td> 0.000</td> <td>   -5.910</td> <td>   -1.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_7</th>             <td>   -0.4242</td> <td>    0.830</td> <td>   -0.511</td> <td> 0.609</td> <td>   -2.051</td> <td>    1.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_8</th>             <td>   11.8242</td> <td>    1.318</td> <td>    8.973</td> <td> 0.000</td> <td>    9.241</td> <td>   14.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_6</th>         <td>   -1.0248</td> <td>    0.911</td> <td>   -1.125</td> <td> 0.261</td> <td>   -2.810</td> <td>    0.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_7</th>         <td>    2.1517</td> <td>    0.696</td> <td>    3.093</td> <td> 0.002</td> <td>    0.788</td> <td>    3.515</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th>         <td>  -17.6083</td> <td>    1.233</td> <td>  -14.282</td> <td> 0.000</td> <td>  -20.025</td> <td>  -15.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_6</th>          <td>    1.7596</td> <td>    0.523</td> <td>    3.361</td> <td> 0.001</td> <td>    0.734</td> <td>    2.786</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_7</th>          <td>    1.0726</td> <td>    0.713</td> <td>    1.504</td> <td> 0.133</td> <td>   -0.325</td> <td>    2.470</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_8</th>          <td>   -7.1482</td> <td>    1.106</td> <td>   -6.461</td> <td> 0.000</td> <td>   -9.317</td> <td>   -4.980</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_6</th>            <td>    4.7109</td> <td>    0.865</td> <td>    5.444</td> <td> 0.000</td> <td>    3.015</td> <td>    6.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_7</th>            <td>   -2.3616</td> <td>    0.931</td> <td>   -2.538</td> <td> 0.011</td> <td>   -4.186</td> <td>   -0.538</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_8</th>            <td>   -5.4246</td> <td>    1.106</td> <td>   -4.903</td> <td> 0.000</td> <td>   -7.593</td> <td>   -3.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_6</th>         <td>  -14.4922</td> <td>    2.853</td> <td>   -5.079</td> <td> 0.000</td> <td>  -20.085</td> <td>   -8.899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_7</th>         <td>    5.9519</td> <td>    2.053</td> <td>    2.899</td> <td> 0.004</td> <td>    1.928</td> <td>    9.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_8</th>         <td>   -1.8387</td> <td>    2.611</td> <td>   -0.704</td> <td> 0.481</td> <td>   -6.956</td> <td>    3.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_6</th>                <td>   -1.1950</td> <td>    0.837</td> <td>   -1.427</td> <td> 0.154</td> <td>   -2.836</td> <td>    0.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_7</th>                <td>    4.1450</td> <td>    0.964</td> <td>    4.298</td> <td> 0.000</td> <td>    2.255</td> <td>    6.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_8</th>                <td>   -8.8219</td> <td>    1.358</td> <td>   -6.496</td> <td> 0.000</td> <td>  -11.484</td> <td>   -6.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_6</th>                <td>  -11.4172</td> <td>    3.072</td> <td>   -3.716</td> <td> 0.000</td> <td>  -17.439</td> <td>   -5.396</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_7</th>                <td>    8.7082</td> <td>    1.914</td> <td>    4.551</td> <td> 0.000</td> <td>    4.958</td> <td>   12.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_8</th>                <td>   -7.0634</td> <td>    2.373</td> <td>   -2.976</td> <td> 0.003</td> <td>  -11.715</td> <td>   -2.412</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_6</th>               <td>   -0.5209</td> <td>    0.333</td> <td>   -1.562</td> <td> 0.118</td> <td>   -1.175</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_7</th>               <td>   -1.1207</td> <td>    0.436</td> <td>   -2.571</td> <td> 0.010</td> <td>   -1.975</td> <td>   -0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_8</th>               <td>   -3.9140</td> <td>    0.634</td> <td>   -6.170</td> <td> 0.000</td> <td>   -5.157</td> <td>   -2.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_6</th>                <td>    0.3683</td> <td>    0.525</td> <td>    0.702</td> <td> 0.483</td> <td>   -0.661</td> <td>    1.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_7</th>                <td>   -0.4193</td> <td>    0.567</td> <td>   -0.740</td> <td> 0.460</td> <td>   -1.531</td> <td>    0.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_8</th>                <td>   -3.1354</td> <td>    0.706</td> <td>   -4.444</td> <td> 0.000</td> <td>   -4.518</td> <td>   -1.753</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_6</th>               <td>    2.3675</td> <td>    0.780</td> <td>    3.036</td> <td> 0.002</td> <td>    0.839</td> <td>    3.896</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_7</th>               <td>   -2.0901</td> <td>    1.201</td> <td>   -1.740</td> <td> 0.082</td> <td>   -4.444</td> <td>    0.264</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_8</th>               <td>   -4.9497</td> <td>    1.803</td> <td>   -2.746</td> <td> 0.006</td> <td>   -8.483</td> <td>   -1.417</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_6</th>                <td>    2.5049</td> <td>    0.945</td> <td>    2.652</td> <td> 0.008</td> <td>    0.654</td> <td>    4.356</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_7</th>                <td>    3.4215</td> <td>    1.102</td> <td>    3.104</td> <td> 0.002</td> <td>    1.261</td> <td>    5.582</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_8</th>                <td>   -5.4518</td> <td>    1.637</td> <td>   -3.330</td> <td> 0.001</td> <td>   -8.661</td> <td>   -2.243</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aon</th>                        <td>   -0.4016</td> <td>    0.108</td> <td>   -3.729</td> <td> 0.000</td> <td>   -0.613</td> <td>   -0.191</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>                 <td>   -7.4819</td> <td>    1.855</td> <td>   -4.033</td> <td> 0.000</td> <td>  -11.118</td> <td>   -3.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jul_vbc_3g</th>                 <td>   -1.9774</td> <td>    1.043</td> <td>   -1.897</td> <td> 0.058</td> <td>   -4.021</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jun_vbc_3g</th>                 <td>    3.0169</td> <td>    0.813</td> <td>    3.711</td> <td> 0.000</td> <td>    1.424</td> <td>    4.610</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_data_recharge_amnt_6</th> <td>    0.8672</td> <td>    1.450</td> <td>    0.598</td> <td> 0.550</td> <td>   -1.975</td> <td>    3.709</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_data_recharge_amnt_7</th> <td>   -2.5484</td> <td>    1.758</td> <td>   -1.449</td> <td> 0.147</td> <td>   -5.995</td> <td>    0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_data_recharge_amnt_8</th> <td>   12.5081</td> <td>    1.969</td> <td>    6.354</td> <td> 0.000</td> <td>    8.650</td> <td>   16.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_recharge_amnt_6</th>      <td>    2.7793</td> <td>    1.201</td> <td>    2.313</td> <td> 0.021</td> <td>    0.425</td> <td>    5.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_recharge_amnt_7</th>      <td>   -5.7503</td> <td>    1.417</td> <td>   -4.057</td> <td> 0.000</td> <td>   -8.528</td> <td>   -2.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_recharge_amnt_8</th>      <td>    0.1646</td> <td>    1.729</td> <td>    0.095</td> <td> 0.924</td> <td>   -3.225</td> <td>    3.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>average_amnt_6_7</th>           <td>   -2.5980</td> <td>    1.011</td> <td>   -2.570</td> <td> 0.010</td> <td>   -4.580</td> <td>   -0.616</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:      churn_probability   No. Observations:                27020\n",
       "Model:                            GLM   Df Residuals:                    26886\n",
       "Model Family:                Binomial   Df Model:                          133\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -8608.7\n",
       "Date:                Wed, 14 Sep 2022   Deviance:                       17217.\n",
       "Time:                        16:37:08   Pearson chi2:                 1.44e+05\n",
       "No. Iterations:                   100                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "const                         -2.4285      0.689     -3.524      0.000      -3.779      -1.078\n",
       "arpu_6                         2.6441      3.733      0.708      0.479      -4.672       9.961\n",
       "arpu_7                        14.4367      4.447      3.246      0.001       5.720      23.154\n",
       "arpu_8                        36.7215      5.100      7.200      0.000      26.725      46.718\n",
       "onnet_mou_6                 -108.6588     34.093     -3.187      0.001    -175.479     -41.839\n",
       "onnet_mou_7                  -60.1910     32.538     -1.850      0.064    -123.964       3.582\n",
       "onnet_mou_8                   -2.8597     48.949     -0.058      0.953     -98.799      93.079\n",
       "offnet_mou_6                -113.4470     38.288     -2.963      0.003    -188.490     -38.404\n",
       "offnet_mou_7                 -50.1050     26.087     -1.921      0.055    -101.235       1.025\n",
       "offnet_mou_8                 -48.5581     62.415     -0.778      0.437    -170.889      73.772\n",
       "roam_ic_mou_6                  1.5657      1.126      1.390      0.164      -0.641       3.773\n",
       "roam_ic_mou_7                  1.2488      1.324      0.943      0.345      -1.346       3.843\n",
       "roam_ic_mou_8                 -1.7700      1.419     -1.247      0.212      -4.551       1.011\n",
       "roam_og_mou_6                 53.9969     17.425      3.099      0.002      19.845      88.149\n",
       "roam_og_mou_7                 23.9400     11.007      2.175      0.030       2.366      45.514\n",
       "roam_og_mou_8                 17.5740     24.038      0.731      0.465     -29.539      64.687\n",
       "loc_og_t2t_mou_6           -2.199e+04   2.55e+04     -0.862      0.389    -7.2e+04     2.8e+04\n",
       "loc_og_t2t_mou_7           -1803.2706   2.89e+04     -0.062      0.950   -5.84e+04    5.47e+04\n",
       "loc_og_t2t_mou_8            1.851e+05   4.44e+04      4.170      0.000    9.81e+04    2.72e+05\n",
       "loc_og_t2m_mou_6           -1.607e+04   1.86e+04     -0.862      0.389   -5.26e+04    2.05e+04\n",
       "loc_og_t2m_mou_7           -1116.5022   1.78e+04     -0.063      0.950   -3.59e+04    3.37e+04\n",
       "loc_og_t2m_mou_8            8.544e+04   2.05e+04      4.171      0.000    4.53e+04    1.26e+05\n",
       "loc_og_t2f_mou_6           -2117.4271   2450.463     -0.864      0.388   -6920.246    2685.392\n",
       "loc_og_t2f_mou_7            -200.3540   3178.992     -0.063      0.950   -6431.063    6030.355\n",
       "loc_og_t2f_mou_8            1.013e+04   2428.740      4.172      0.000    5373.287    1.49e+04\n",
       "loc_og_t2c_mou_6              -7.9074      1.540     -5.135      0.000     -10.925      -4.889\n",
       "loc_og_t2c_mou_7              -4.3733      2.682     -1.631      0.103      -9.630       0.883\n",
       "loc_og_t2c_mou_8               7.5812      1.600      4.738      0.000       4.445      10.717\n",
       "loc_og_mou_6                1.527e+04   4.78e+04      0.319      0.749   -7.84e+04    1.09e+05\n",
       "loc_og_mou_7               -1.259e+04   3.52e+04     -0.357      0.721   -8.17e+04    5.65e+04\n",
       "loc_og_mou_8               -2.436e+05   5.41e+04     -4.506      0.000    -3.5e+05   -1.38e+05\n",
       "std_og_t2t_mou_6           -1.662e+05   3.52e+04     -4.719      0.000   -2.35e+05   -9.72e+04\n",
       "std_og_t2t_mou_7           -2.632e+04   4.04e+04     -0.651      0.515   -1.06e+05    5.29e+04\n",
       "std_og_t2t_mou_8            1.549e+05   4.21e+04      3.684      0.000    7.25e+04    2.37e+05\n",
       "std_og_t2m_mou_6           -1.876e+05   3.97e+04     -4.720      0.000   -2.65e+05    -1.1e+05\n",
       "std_og_t2m_mou_7           -2.143e+04   3.29e+04     -0.651      0.515   -8.59e+04    4.31e+04\n",
       "std_og_t2m_mou_8            2.697e+05   7.32e+04      3.684      0.000    1.26e+05    4.13e+05\n",
       "std_og_t2f_mou_6           -7626.5095   1615.935     -4.720      0.000   -1.08e+04   -4459.335\n",
       "std_og_t2f_mou_7           -1508.5269   2315.193     -0.652      0.515   -6046.222    3029.168\n",
       "std_og_t2f_mou_8            6840.8481   1858.923      3.680      0.000    3197.427    1.05e+04\n",
       "std_og_mou_6                1.735e+05   4.38e+04      3.962      0.000    8.77e+04    2.59e+05\n",
       "std_og_mou_7                1.102e+04    4.5e+04      0.245      0.807   -7.72e+04    9.92e+04\n",
       "std_og_mou_8               -3.381e+05   8.12e+04     -4.165      0.000   -4.97e+05   -1.79e+05\n",
       "isd_og_mou_6               -1.174e+04   1.72e+04     -0.684      0.494   -4.54e+04    2.19e+04\n",
       "isd_og_mou_7               -1.038e+04   1.78e+04     -0.584      0.559   -4.52e+04    2.45e+04\n",
       "isd_og_mou_8               -2.758e+04   1.89e+04     -1.460      0.144   -6.46e+04    9437.563\n",
       "spl_og_mou_6               -2030.9713   2977.772     -0.682      0.495   -7867.298    3805.356\n",
       "spl_og_mou_7               -2392.8243   4096.948     -0.584      0.559   -1.04e+04    5637.046\n",
       "spl_og_mou_8               -3806.0950   2605.739     -1.461      0.144   -8913.250    1301.060\n",
       "og_others_6                -1245.0736   1776.319     -0.701      0.483   -4726.595    2236.448\n",
       "og_others_7                 -148.3731    217.740     -0.681      0.496    -575.135     278.389\n",
       "og_others_8                -2195.3611   1327.334     -1.654      0.098   -4796.887     406.165\n",
       "total_og_mou_6              2.135e+04   3.11e+04      0.687      0.492   -3.95e+04    8.22e+04\n",
       "total_og_mou_7              1.568e+04   2.68e+04      0.585      0.559   -3.69e+04    6.82e+04\n",
       "total_og_mou_8              6.813e+04   4.67e+04      1.459      0.144   -2.34e+04     1.6e+05\n",
       "loc_ic_t2t_mou_6           -1.018e+05   1.64e+04     -6.220      0.000   -1.34e+05   -6.97e+04\n",
       "loc_ic_t2t_mou_7             6.21e+04   2.14e+04      2.895      0.004    2.01e+04    1.04e+05\n",
       "loc_ic_t2t_mou_8            1.381e+05   1.52e+04      9.090      0.000    1.08e+05    1.68e+05\n",
       "loc_ic_t2m_mou_6           -1.039e+05   1.67e+04     -6.220      0.000   -1.37e+05   -7.11e+04\n",
       "loc_ic_t2m_mou_7             4.38e+04   1.51e+04      2.895      0.004    1.42e+04    7.35e+04\n",
       "loc_ic_t2m_mou_8            1.614e+05   1.78e+04      9.090      0.000    1.27e+05    1.96e+05\n",
       "loc_ic_t2f_mou_6           -3.205e+04   5151.160     -6.222      0.000   -4.21e+04    -2.2e+04\n",
       "loc_ic_t2f_mou_7            2.158e+04   7449.499      2.897      0.004    6981.513    3.62e+04\n",
       "loc_ic_t2f_mou_8            5.073e+04   5581.819      9.088      0.000    3.98e+04    6.17e+04\n",
       "loc_ic_mou_6                1.342e+05   2.82e+04      4.764      0.000     7.9e+04    1.89e+05\n",
       "loc_ic_mou_7               -5.241e+04   2.51e+04     -2.091      0.037   -1.02e+05   -3288.414\n",
       "loc_ic_mou_8               -1.096e+05   2.08e+04     -5.279      0.000    -1.5e+05   -6.89e+04\n",
       "std_ic_t2t_mou_6           -9278.7064   1.44e+04     -0.643      0.521   -3.76e+04     1.9e+04\n",
       "std_ic_t2t_mou_7           -4.942e+04   2.05e+04     -2.406      0.016   -8.97e+04   -9162.235\n",
       "std_ic_t2t_mou_8            5.071e+04   1.81e+04      2.804      0.005    1.53e+04    8.62e+04\n",
       "std_ic_t2m_mou_6           -1.104e+04   1.72e+04     -0.643      0.521   -4.47e+04    2.26e+04\n",
       "std_ic_t2m_mou_7           -3.069e+04   1.28e+04     -2.407      0.016   -5.57e+04   -5697.677\n",
       "std_ic_t2m_mou_8            4.267e+04   1.52e+04      2.805      0.005    1.29e+04    7.25e+04\n",
       "std_ic_t2f_mou_6           -4136.8282   6422.039     -0.644      0.519   -1.67e+04    8450.137\n",
       "std_ic_t2f_mou_7           -1.325e+04   5510.036     -2.405      0.016    -2.4e+04   -2450.835\n",
       "std_ic_t2f_mou_8            2.066e+04   7368.461      2.804      0.005    6217.252    3.51e+04\n",
       "std_ic_mou_6               -8256.5728   1.79e+04     -0.460      0.645   -4.34e+04    2.69e+04\n",
       "std_ic_mou_7                6.244e+04   2.22e+04      2.813      0.005    1.89e+04    1.06e+05\n",
       "std_ic_mou_8               -2705.4832    2.1e+04     -0.129      0.897   -4.38e+04    3.84e+04\n",
       "total_ic_mou_6              4.118e+04   1.81e+04      2.279      0.023    5758.923    7.66e+04\n",
       "total_ic_mou_7             -2.062e+04   1.87e+04     -1.104      0.269   -5.72e+04     1.6e+04\n",
       "total_ic_mou_8             -8.556e+04   1.55e+04     -5.536      0.000   -1.16e+05   -5.53e+04\n",
       "spl_ic_mou_6                 -97.6341     46.802     -2.086      0.037    -189.365      -5.903\n",
       "spl_ic_mou_7                  31.0942     34.050      0.913      0.361     -35.643      97.831\n",
       "spl_ic_mou_8                  10.9361      3.297      3.317      0.001       4.475      17.397\n",
       "isd_ic_mou_6               -3.624e+04   1.59e+04     -2.279      0.023   -6.74e+04   -5066.775\n",
       "isd_ic_mou_7                 1.25e+04   1.13e+04      1.104      0.270   -9694.705    3.47e+04\n",
       "isd_ic_mou_8                3.381e+04   6106.282      5.536      0.000    2.18e+04    4.58e+04\n",
       "ic_others_6                -7199.3129   3149.195     -2.286      0.022   -1.34e+04   -1027.004\n",
       "ic_others_7                 4149.6726   3753.378      1.106      0.269   -3206.814    1.15e+04\n",
       "ic_others_8                 1.707e+04   3082.551      5.538      0.000     1.1e+04    2.31e+04\n",
       "total_rech_num_6              -1.1331      0.730     -1.551      0.121      -2.565       0.298\n",
       "total_rech_num_7               5.0477      0.730      6.912      0.000       3.616       6.479\n",
       "total_rech_num_8              -8.0932      0.838     -9.663      0.000      -9.735      -6.452\n",
       "total_rech_amt_6               6.0418      3.168      1.907      0.057      -0.168      12.252\n",
       "total_rech_amt_7              -9.4816      3.710     -2.556      0.011     -16.753      -2.210\n",
       "total_rech_amt_8             -33.0258      4.309     -7.664      0.000     -41.472     -24.579\n",
       "max_rech_amt_6                -3.9072      1.022     -3.824      0.000      -5.910      -1.905\n",
       "max_rech_amt_7                -0.4242      0.830     -0.511      0.609      -2.051       1.203\n",
       "max_rech_amt_8                11.8242      1.318      8.973      0.000       9.241      14.407\n",
       "last_day_rch_amt_6            -1.0248      0.911     -1.125      0.261      -2.810       0.761\n",
       "last_day_rch_amt_7             2.1517      0.696      3.093      0.002       0.788       3.515\n",
       "last_day_rch_amt_8           -17.6083      1.233    -14.282      0.000     -20.025     -15.192\n",
       "total_rech_data_6              1.7596      0.523      3.361      0.001       0.734       2.786\n",
       "total_rech_data_7              1.0726      0.713      1.504      0.133      -0.325       2.470\n",
       "total_rech_data_8             -7.1482      1.106     -6.461      0.000      -9.317      -4.980\n",
       "max_rech_data_6                4.7109      0.865      5.444      0.000       3.015       6.407\n",
       "max_rech_data_7               -2.3616      0.931     -2.538      0.011      -4.186      -0.538\n",
       "max_rech_data_8               -5.4246      1.106     -4.903      0.000      -7.593      -3.256\n",
       "av_rech_amt_data_6           -14.4922      2.853     -5.079      0.000     -20.085      -8.899\n",
       "av_rech_amt_data_7             5.9519      2.053      2.899      0.004       1.928       9.975\n",
       "av_rech_amt_data_8            -1.8387      2.611     -0.704      0.481      -6.956       3.279\n",
       "vol_2g_mb_6                   -1.1950      0.837     -1.427      0.154      -2.836       0.446\n",
       "vol_2g_mb_7                    4.1450      0.964      4.298      0.000       2.255       6.035\n",
       "vol_2g_mb_8                   -8.8219      1.358     -6.496      0.000     -11.484      -6.160\n",
       "vol_3g_mb_6                  -11.4172      3.072     -3.716      0.000     -17.439      -5.396\n",
       "vol_3g_mb_7                    8.7082      1.914      4.551      0.000       4.958      12.459\n",
       "vol_3g_mb_8                   -7.0634      2.373     -2.976      0.003     -11.715      -2.412\n",
       "monthly_2g_6                  -0.5209      0.333     -1.562      0.118      -1.175       0.133\n",
       "monthly_2g_7                  -1.1207      0.436     -2.571      0.010      -1.975      -0.266\n",
       "monthly_2g_8                  -3.9140      0.634     -6.170      0.000      -5.157      -2.671\n",
       "sachet_2g_6                    0.3683      0.525      0.702      0.483      -0.661       1.397\n",
       "sachet_2g_7                   -0.4193      0.567     -0.740      0.460      -1.531       0.692\n",
       "sachet_2g_8                   -3.1354      0.706     -4.444      0.000      -4.518      -1.753\n",
       "monthly_3g_6                   2.3675      0.780      3.036      0.002       0.839       3.896\n",
       "monthly_3g_7                  -2.0901      1.201     -1.740      0.082      -4.444       0.264\n",
       "monthly_3g_8                  -4.9497      1.803     -2.746      0.006      -8.483      -1.417\n",
       "sachet_3g_6                    2.5049      0.945      2.652      0.008       0.654       4.356\n",
       "sachet_3g_7                    3.4215      1.102      3.104      0.002       1.261       5.582\n",
       "sachet_3g_8                   -5.4518      1.637     -3.330      0.001      -8.661      -2.243\n",
       "aon                           -0.4016      0.108     -3.729      0.000      -0.613      -0.191\n",
       "aug_vbc_3g                    -7.4819      1.855     -4.033      0.000     -11.118      -3.846\n",
       "jul_vbc_3g                    -1.9774      1.043     -1.897      0.058      -4.021       0.066\n",
       "jun_vbc_3g                     3.0169      0.813      3.711      0.000       1.424       4.610\n",
       "total_data_recharge_amnt_6     0.8672      1.450      0.598      0.550      -1.975       3.709\n",
       "total_data_recharge_amnt_7    -2.5484      1.758     -1.449      0.147      -5.995       0.898\n",
       "total_data_recharge_amnt_8    12.5081      1.969      6.354      0.000       8.650      16.366\n",
       "total_recharge_amnt_6          2.7793      1.201      2.313      0.021       0.425       5.134\n",
       "total_recharge_amnt_7         -5.7503      1.417     -4.057      0.000      -8.528      -2.972\n",
       "total_recharge_amnt_8          0.1646      1.729      0.095      0.924      -3.225       3.554\n",
       "average_amnt_6_7              -2.5980      1.011     -2.570      0.010      -4.580      -0.616\n",
       "==============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For RFE\n",
    "logml = sm.GLM(y_resampled, (sm.add_constant(X_resampled)), family=sm.families.Binomial())\n",
    "logml.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e7780",
   "metadata": {},
   "source": [
    "## Lower the p-value higher the significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27a6fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f373b0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Running rfe with 70 variables as output\n",
    "rfe = RFE(logreg, n_features_to_select=70)\n",
    "rfe = rfe.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac2cb82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True, False,  True, False, False,  True,  True,\n",
       "        True, False, False, False,  True,  True, False, False,  True,\n",
       "       False,  True,  True,  True, False,  True,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "       False, False,  True,  True,  True,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "       False, False,  True,  True, False,  True, False, False,  True,\n",
       "        True,  True,  True,  True, False,  True, False, False,  True,\n",
       "       False, False,  True,  True, False,  True, False, False,  True,\n",
       "       False, False,  True, False, False,  True, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True,  True, False,  True,  True,  True,  True,\n",
       "        True, False,  True, False, False,  True, False,  True,  True,\n",
       "        True,  True,  True, False, False,  True, False,  True,  True,\n",
       "       False, False,  True,  True,  True,  True, False, False, False,\n",
       "       False, False, False,  True, False])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.support_ # it givs whether or not the selected feature was in top 70. True means yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b474206d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arpu_6', True, 1),\n",
       " ('arpu_7', True, 1),\n",
       " ('arpu_8', True, 1),\n",
       " ('onnet_mou_6', False, 7),\n",
       " ('onnet_mou_7', True, 1),\n",
       " ('onnet_mou_8', False, 44),\n",
       " ('offnet_mou_6', False, 5),\n",
       " ('offnet_mou_7', True, 1),\n",
       " ('offnet_mou_8', True, 1),\n",
       " ('roam_ic_mou_6', True, 1),\n",
       " ('roam_ic_mou_7', False, 55),\n",
       " ('roam_ic_mou_8', False, 50),\n",
       " ('roam_og_mou_6', False, 29),\n",
       " ('roam_og_mou_7', True, 1),\n",
       " ('roam_og_mou_8', True, 1),\n",
       " ('loc_og_t2t_mou_6', False, 68),\n",
       " ('loc_og_t2t_mou_7', False, 67),\n",
       " ('loc_og_t2t_mou_8', True, 1),\n",
       " ('loc_og_t2m_mou_6', False, 4),\n",
       " ('loc_og_t2m_mou_7', True, 1),\n",
       " ('loc_og_t2m_mou_8', True, 1),\n",
       " ('loc_og_t2f_mou_6', True, 1),\n",
       " ('loc_og_t2f_mou_7', False, 20),\n",
       " ('loc_og_t2f_mou_8', True, 1),\n",
       " ('loc_og_t2c_mou_6', True, 1),\n",
       " ('loc_og_t2c_mou_7', False, 2),\n",
       " ('loc_og_t2c_mou_8', False, 3),\n",
       " ('loc_og_mou_6', False, 58),\n",
       " ('loc_og_mou_7', False, 35),\n",
       " ('loc_og_mou_8', True, 1),\n",
       " ('std_og_t2t_mou_6', False, 30),\n",
       " ('std_og_t2t_mou_7', False, 13),\n",
       " ('std_og_t2t_mou_8', False, 45),\n",
       " ('std_og_t2m_mou_6', False, 47),\n",
       " ('std_og_t2m_mou_7', False, 14),\n",
       " ('std_og_t2m_mou_8', True, 1),\n",
       " ('std_og_t2f_mou_6', False, 56),\n",
       " ('std_og_t2f_mou_7', False, 10),\n",
       " ('std_og_t2f_mou_8', True, 1),\n",
       " ('std_og_mou_6', True, 1),\n",
       " ('std_og_mou_7', True, 1),\n",
       " ('std_og_mou_8', True, 1),\n",
       " ('isd_og_mou_6', False, 71),\n",
       " ('isd_og_mou_7', False, 70),\n",
       " ('isd_og_mou_8', False, 69),\n",
       " ('spl_og_mou_6', False, 49),\n",
       " ('spl_og_mou_7', False, 21),\n",
       " ('spl_og_mou_8', True, 1),\n",
       " ('og_others_6', False, 37),\n",
       " ('og_others_7', False, 42),\n",
       " ('og_others_8', False, 62),\n",
       " ('total_og_mou_6', False, 6),\n",
       " ('total_og_mou_7', False, 9),\n",
       " ('total_og_mou_8', True, 1),\n",
       " ('loc_ic_t2t_mou_6', False, 18),\n",
       " ('loc_ic_t2t_mou_7', False, 46),\n",
       " ('loc_ic_t2t_mou_8', True, 1),\n",
       " ('loc_ic_t2m_mou_6', True, 1),\n",
       " ('loc_ic_t2m_mou_7', False, 17),\n",
       " ('loc_ic_t2m_mou_8', True, 1),\n",
       " ('loc_ic_t2f_mou_6', False, 22),\n",
       " ('loc_ic_t2f_mou_7', False, 33),\n",
       " ('loc_ic_t2f_mou_8', True, 1),\n",
       " ('loc_ic_mou_6', True, 1),\n",
       " ('loc_ic_mou_7', True, 1),\n",
       " ('loc_ic_mou_8', True, 1),\n",
       " ('std_ic_t2t_mou_6', True, 1),\n",
       " ('std_ic_t2t_mou_7', False, 12),\n",
       " ('std_ic_t2t_mou_8', True, 1),\n",
       " ('std_ic_t2m_mou_6', False, 16),\n",
       " ('std_ic_t2m_mou_7', False, 15),\n",
       " ('std_ic_t2m_mou_8', True, 1),\n",
       " ('std_ic_t2f_mou_6', False, 48),\n",
       " ('std_ic_t2f_mou_7', False, 39),\n",
       " ('std_ic_t2f_mou_8', True, 1),\n",
       " ('std_ic_mou_6', True, 1),\n",
       " ('std_ic_mou_7', False, 38),\n",
       " ('std_ic_mou_8', True, 1),\n",
       " ('total_ic_mou_6', False, 28),\n",
       " ('total_ic_mou_7', False, 26),\n",
       " ('total_ic_mou_8', True, 1),\n",
       " ('spl_ic_mou_6', False, 57),\n",
       " ('spl_ic_mou_7', False, 34),\n",
       " ('spl_ic_mou_8', True, 1),\n",
       " ('isd_ic_mou_6', False, 32),\n",
       " ('isd_ic_mou_7', False, 27),\n",
       " ('isd_ic_mou_8', True, 1),\n",
       " ('ic_others_6', False, 41),\n",
       " ('ic_others_7', False, 60),\n",
       " ('ic_others_8', False, 64),\n",
       " ('total_rech_num_6', True, 1),\n",
       " ('total_rech_num_7', True, 1),\n",
       " ('total_rech_num_8', True, 1),\n",
       " ('total_rech_amt_6', True, 1),\n",
       " ('total_rech_amt_7', True, 1),\n",
       " ('total_rech_amt_8', True, 1),\n",
       " ('max_rech_amt_6', True, 1),\n",
       " ('max_rech_amt_7', True, 1),\n",
       " ('max_rech_amt_8', True, 1),\n",
       " ('last_day_rch_amt_6', False, 36),\n",
       " ('last_day_rch_amt_7', False, 66),\n",
       " ('last_day_rch_amt_8', True, 1),\n",
       " ('total_rech_data_6', True, 1),\n",
       " ('total_rech_data_7', False, 43),\n",
       " ('total_rech_data_8', True, 1),\n",
       " ('max_rech_data_6', True, 1),\n",
       " ('max_rech_data_7', True, 1),\n",
       " ('max_rech_data_8', True, 1),\n",
       " ('av_rech_amt_data_6', True, 1),\n",
       " ('av_rech_amt_data_7', False, 19),\n",
       " ('av_rech_amt_data_8', True, 1),\n",
       " ('vol_2g_mb_6', False, 11),\n",
       " ('vol_2g_mb_7', False, 8),\n",
       " ('vol_2g_mb_8', True, 1),\n",
       " ('vol_3g_mb_6', False, 65),\n",
       " ('vol_3g_mb_7', True, 1),\n",
       " ('vol_3g_mb_8', True, 1),\n",
       " ('monthly_2g_6', True, 1),\n",
       " ('monthly_2g_7', True, 1),\n",
       " ('monthly_2g_8', True, 1),\n",
       " ('sachet_2g_6', False, 24),\n",
       " ('sachet_2g_7', False, 59),\n",
       " ('sachet_2g_8', True, 1),\n",
       " ('monthly_3g_6', False, 25),\n",
       " ('monthly_3g_7', True, 1),\n",
       " ('monthly_3g_8', True, 1),\n",
       " ('sachet_3g_6', False, 31),\n",
       " ('sachet_3g_7', False, 23),\n",
       " ('sachet_3g_8', True, 1),\n",
       " ('aon', True, 1),\n",
       " ('aug_vbc_3g', True, 1),\n",
       " ('jul_vbc_3g', True, 1),\n",
       " ('jun_vbc_3g', False, 51),\n",
       " ('total_data_recharge_amnt_6', False, 40),\n",
       " ('total_data_recharge_amnt_7', False, 53),\n",
       " ('total_data_recharge_amnt_8', False, 54),\n",
       " ('total_recharge_amnt_6', False, 61),\n",
       " ('total_recharge_amnt_7', False, 63),\n",
       " ('total_recharge_amnt_8', True, 1),\n",
       " ('average_amnt_6_7', False, 52)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to see the selected columns\n",
    "list(zip(X_resampled.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc628327",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_resampled.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bbbd2363",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>churn_probability</td> <th>  No. Observations:  </th>  <td> 27020</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>        <th>  Df Residuals:      </th>  <td> 26950</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>      <th>  Df Model:          </th>  <td>    69</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>logit</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>        <th>  Log-Likelihood:    </th> <td> -8857.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Wed, 14 Sep 2022</td>  <th>  Deviance:          </th> <td>  17714.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>16:37:35</td>      <th>  Pearson chi2:      </th> <td>2.48e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>7</td>         <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "            <td></td>               <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                 <td>   -1.6020</td> <td>    0.638</td> <td>   -2.512</td> <td> 0.012</td> <td>   -2.852</td> <td>   -0.352</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_6</th>                <td>   -0.1558</td> <td>    3.432</td> <td>   -0.045</td> <td> 0.964</td> <td>   -6.883</td> <td>    6.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_7</th>                <td>   11.4761</td> <td>    3.943</td> <td>    2.910</td> <td> 0.004</td> <td>    3.747</td> <td>   19.205</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_8</th>                <td>   32.3195</td> <td>    4.465</td> <td>    7.238</td> <td> 0.000</td> <td>   23.568</td> <td>   41.071</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_7</th>           <td>    6.3973</td> <td>    2.128</td> <td>    3.007</td> <td> 0.003</td> <td>    2.227</td> <td>   10.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_7</th>          <td>    5.5836</td> <td>    1.880</td> <td>    2.970</td> <td> 0.003</td> <td>    1.898</td> <td>    9.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_8</th>          <td>  -45.1994</td> <td>    9.766</td> <td>   -4.628</td> <td> 0.000</td> <td>  -64.340</td> <td>  -26.059</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_ic_mou_6</th>         <td>    1.9751</td> <td>    0.871</td> <td>    2.267</td> <td> 0.023</td> <td>    0.268</td> <td>    3.682</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_7</th>         <td>    1.9961</td> <td>    1.021</td> <td>    1.956</td> <td> 0.050</td> <td>   -0.004</td> <td>    3.996</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>         <td>   17.0474</td> <td>    2.907</td> <td>    5.864</td> <td> 0.000</td> <td>   11.350</td> <td>   22.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_8</th>      <td> 3215.6490</td> <td> 3.87e+04</td> <td>    0.083</td> <td> 0.934</td> <td>-7.27e+04</td> <td> 7.91e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>      <td>   -6.2335</td> <td>    1.637</td> <td>   -3.807</td> <td> 0.000</td> <td>   -9.443</td> <td>   -3.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_8</th>      <td> 1505.6518</td> <td> 1.79e+04</td> <td>    0.084</td> <td> 0.933</td> <td>-3.35e+04</td> <td> 3.65e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_6</th>      <td>   -4.7834</td> <td>    1.674</td> <td>   -2.858</td> <td> 0.004</td> <td>   -8.064</td> <td>   -1.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>      <td>  180.0511</td> <td> 2118.788</td> <td>    0.085</td> <td> 0.932</td> <td>-3972.697</td> <td> 4332.799</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2c_mou_6</th>      <td>   -6.8649</td> <td>    1.230</td> <td>   -5.583</td> <td> 0.000</td> <td>   -9.275</td> <td>   -4.455</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_8</th>          <td>-3275.0674</td> <td> 3.98e+04</td> <td>   -0.082</td> <td> 0.934</td> <td>-8.12e+04</td> <td> 7.47e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>      <td>   39.8186</td> <td>    9.793</td> <td>    4.066</td> <td> 0.000</td> <td>   20.624</td> <td>   59.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2f_mou_8</th>      <td>   -7.8225</td> <td>    2.155</td> <td>   -3.629</td> <td> 0.000</td> <td>  -12.047</td> <td>   -3.598</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_6</th>          <td>    1.6738</td> <td>    0.522</td> <td>    3.208</td> <td> 0.001</td> <td>    0.651</td> <td>    2.696</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>          <td>   -3.2116</td> <td>    2.210</td> <td>   -1.454</td> <td> 0.146</td> <td>   -7.542</td> <td>    1.119</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_8</th>          <td>   56.5097</td> <td>   31.784</td> <td>    1.778</td> <td> 0.075</td> <td>   -5.786</td> <td>  118.806</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_og_mou_8</th>          <td>    2.9042</td> <td>    2.036</td> <td>    1.426</td> <td> 0.154</td> <td>   -1.086</td> <td>    6.895</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_8</th>        <td>  -65.3701</td> <td>   32.033</td> <td>   -2.041</td> <td> 0.041</td> <td> -128.153</td> <td>   -2.587</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_8</th>      <td>-1314.4706</td> <td> 9050.822</td> <td>   -0.145</td> <td> 0.885</td> <td>-1.91e+04</td> <td> 1.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_6</th>      <td>    3.2176</td> <td>    1.833</td> <td>    1.755</td> <td> 0.079</td> <td>   -0.375</td> <td>    6.810</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_8</th>      <td>-1535.3881</td> <td> 1.06e+04</td> <td>   -0.145</td> <td> 0.885</td> <td>-2.23e+04</td> <td> 1.92e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>      <td> -491.0362</td> <td> 3326.303</td> <td>   -0.148</td> <td> 0.883</td> <td>-7010.470</td> <td> 6028.397</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_6</th>          <td>    0.5218</td> <td>    2.430</td> <td>    0.215</td> <td> 0.830</td> <td>   -4.240</td> <td>    5.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_7</th>          <td>   16.2365</td> <td>    1.647</td> <td>    9.856</td> <td> 0.000</td> <td>   13.008</td> <td>   19.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>          <td> 1712.7405</td> <td> 1.21e+04</td> <td>    0.142</td> <td> 0.887</td> <td> -2.2e+04</td> <td> 2.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_6</th>      <td>    6.3035</td> <td>    1.697</td> <td>    3.715</td> <td> 0.000</td> <td>    2.978</td> <td>    9.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_8</th>      <td>-1322.0953</td> <td> 1.66e+04</td> <td>   -0.080</td> <td> 0.936</td> <td>-3.38e+04</td> <td> 3.12e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_8</th>      <td>-1098.0856</td> <td> 1.39e+04</td> <td>   -0.079</td> <td> 0.937</td> <td>-2.84e+04</td> <td> 2.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2f_mou_8</th>      <td> -536.5155</td> <td> 6757.255</td> <td>   -0.079</td> <td> 0.937</td> <td>-1.38e+04</td> <td> 1.27e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_6</th>          <td>    0.2580</td> <td>    1.158</td> <td>    0.223</td> <td> 0.824</td> <td>   -2.012</td> <td>    2.528</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_8</th>          <td> 1431.6088</td> <td> 1.83e+04</td> <td>    0.078</td> <td> 0.938</td> <td>-3.44e+04</td> <td> 3.73e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_8</th>        <td>   -0.6429</td> <td>   13.144</td> <td>   -0.049</td> <td> 0.961</td> <td>  -26.404</td> <td>   25.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_8</th>          <td>   -7.0006</td> <td>    0.569</td> <td>  -12.306</td> <td> 0.000</td> <td>   -8.116</td> <td>   -5.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_ic_mou_8</th>          <td>    0.9898</td> <td>    5.413</td> <td>    0.183</td> <td> 0.855</td> <td>   -9.620</td> <td>   11.600</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_6</th>      <td>   -1.1237</td> <td>    0.672</td> <td>   -1.673</td> <td> 0.094</td> <td>   -2.440</td> <td>    0.193</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_7</th>      <td>    4.8547</td> <td>    0.647</td> <td>    7.506</td> <td> 0.000</td> <td>    3.587</td> <td>    6.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_8</th>      <td>   -8.5436</td> <td>    0.774</td> <td>  -11.034</td> <td> 0.000</td> <td>  -10.061</td> <td>   -7.026</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_6</th>      <td>    6.4523</td> <td>    3.093</td> <td>    2.086</td> <td> 0.037</td> <td>    0.391</td> <td>   12.513</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_7</th>      <td>   -6.8469</td> <td>    3.610</td> <td>   -1.896</td> <td> 0.058</td> <td>  -13.923</td> <td>    0.229</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_8</th>      <td>  -36.0504</td> <td>    4.446</td> <td>   -8.109</td> <td> 0.000</td> <td>  -44.764</td> <td>  -27.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_6</th>        <td>   -3.4870</td> <td>    0.922</td> <td>   -3.780</td> <td> 0.000</td> <td>   -5.295</td> <td>   -1.679</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_7</th>        <td>    0.5530</td> <td>    0.778</td> <td>    0.711</td> <td> 0.477</td> <td>   -0.972</td> <td>    2.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_8</th>        <td>   11.2516</td> <td>    1.269</td> <td>    8.867</td> <td> 0.000</td> <td>    8.764</td> <td>   13.739</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th>    <td>  -17.7898</td> <td>    1.196</td> <td>  -14.875</td> <td> 0.000</td> <td>  -20.134</td> <td>  -15.446</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_6</th>     <td>    3.2243</td> <td>    0.741</td> <td>    4.353</td> <td> 0.000</td> <td>    1.772</td> <td>    4.676</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_8</th>     <td>   -5.6245</td> <td>    0.878</td> <td>   -6.403</td> <td> 0.000</td> <td>   -7.346</td> <td>   -3.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_6</th>       <td>    3.6992</td> <td>    0.773</td> <td>    4.789</td> <td> 0.000</td> <td>    2.185</td> <td>    5.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_7</th>       <td>    0.1399</td> <td>    0.665</td> <td>    0.210</td> <td> 0.833</td> <td>   -1.164</td> <td>    1.444</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_8</th>       <td>   -4.8867</td> <td>    1.080</td> <td>   -4.523</td> <td> 0.000</td> <td>   -7.004</td> <td>   -2.769</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_6</th>    <td>  -11.6982</td> <td>    1.915</td> <td>   -6.110</td> <td> 0.000</td> <td>  -15.451</td> <td>   -7.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_8</th>    <td>   -1.6092</td> <td>    2.361</td> <td>   -0.681</td> <td> 0.496</td> <td>   -6.237</td> <td>    3.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_8</th>           <td>   -7.0016</td> <td>    1.186</td> <td>   -5.905</td> <td> 0.000</td> <td>   -9.326</td> <td>   -4.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_7</th>           <td>    5.2999</td> <td>    1.536</td> <td>    3.450</td> <td> 0.001</td> <td>    2.289</td> <td>    8.311</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_8</th>           <td>   -8.0437</td> <td>    2.256</td> <td>   -3.565</td> <td> 0.000</td> <td>  -12.466</td> <td>   -3.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_6</th>          <td>   -0.7981</td> <td>    0.286</td> <td>   -2.791</td> <td> 0.005</td> <td>   -1.359</td> <td>   -0.238</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_7</th>          <td>   -0.5359</td> <td>    0.394</td> <td>   -1.359</td> <td> 0.174</td> <td>   -1.309</td> <td>    0.237</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_8</th>          <td>   -4.6127</td> <td>    0.619</td> <td>   -7.448</td> <td> 0.000</td> <td>   -5.827</td> <td>   -3.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_8</th>           <td>   -4.7886</td> <td>    0.570</td> <td>   -8.397</td> <td> 0.000</td> <td>   -5.906</td> <td>   -3.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_7</th>          <td>   -0.3476</td> <td>    0.985</td> <td>   -0.353</td> <td> 0.724</td> <td>   -2.278</td> <td>    1.583</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_8</th>          <td>   -4.9011</td> <td>    1.696</td> <td>   -2.890</td> <td> 0.004</td> <td>   -8.225</td> <td>   -1.577</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_8</th>           <td>   -1.7848</td> <td>    1.200</td> <td>   -1.488</td> <td> 0.137</td> <td>   -4.136</td> <td>    0.567</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aon</th>                   <td>   -0.4979</td> <td>    0.101</td> <td>   -4.907</td> <td> 0.000</td> <td>   -0.697</td> <td>   -0.299</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>            <td>   -7.0817</td> <td>    1.778</td> <td>   -3.982</td> <td> 0.000</td> <td>  -10.567</td> <td>   -3.596</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jul_vbc_3g</th>            <td>   -0.5413</td> <td>    0.934</td> <td>   -0.580</td> <td> 0.562</td> <td>   -2.371</td> <td>    1.289</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_recharge_amnt_8</th> <td>   11.5719</td> <td>    3.014</td> <td>    3.839</td> <td> 0.000</td> <td>    5.664</td> <td>   17.480</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:      churn_probability   No. Observations:                27020\n",
       "Model:                            GLM   Df Residuals:                    26950\n",
       "Model Family:                Binomial   Df Model:                           69\n",
       "Link Function:                  logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -8857.2\n",
       "Date:                Wed, 14 Sep 2022   Deviance:                       17714.\n",
       "Time:                        16:37:35   Pearson chi2:                 2.48e+05\n",
       "No. Iterations:                     7                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=========================================================================================\n",
       "                            coef    std err          z      P>|z|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------\n",
       "const                    -1.6020      0.638     -2.512      0.012      -2.852      -0.352\n",
       "arpu_6                   -0.1558      3.432     -0.045      0.964      -6.883       6.571\n",
       "arpu_7                   11.4761      3.943      2.910      0.004       3.747      19.205\n",
       "arpu_8                   32.3195      4.465      7.238      0.000      23.568      41.071\n",
       "onnet_mou_7               6.3973      2.128      3.007      0.003       2.227      10.567\n",
       "offnet_mou_7              5.5836      1.880      2.970      0.003       1.898       9.269\n",
       "offnet_mou_8            -45.1994      9.766     -4.628      0.000     -64.340     -26.059\n",
       "roam_ic_mou_6             1.9751      0.871      2.267      0.023       0.268       3.682\n",
       "roam_og_mou_7             1.9961      1.021      1.956      0.050      -0.004       3.996\n",
       "roam_og_mou_8            17.0474      2.907      5.864      0.000      11.350      22.745\n",
       "loc_og_t2t_mou_8       3215.6490   3.87e+04      0.083      0.934   -7.27e+04    7.91e+04\n",
       "loc_og_t2m_mou_7         -6.2335      1.637     -3.807      0.000      -9.443      -3.024\n",
       "loc_og_t2m_mou_8       1505.6518   1.79e+04      0.084      0.933   -3.35e+04    3.65e+04\n",
       "loc_og_t2f_mou_6         -4.7834      1.674     -2.858      0.004      -8.064      -1.503\n",
       "loc_og_t2f_mou_8        180.0511   2118.788      0.085      0.932   -3972.697    4332.799\n",
       "loc_og_t2c_mou_6         -6.8649      1.230     -5.583      0.000      -9.275      -4.455\n",
       "loc_og_mou_8          -3275.0674   3.98e+04     -0.082      0.934   -8.12e+04    7.47e+04\n",
       "std_og_t2m_mou_8         39.8186      9.793      4.066      0.000      20.624      59.013\n",
       "std_og_t2f_mou_8         -7.8225      2.155     -3.629      0.000     -12.047      -3.598\n",
       "std_og_mou_6              1.6738      0.522      3.208      0.001       0.651       2.696\n",
       "std_og_mou_7             -3.2116      2.210     -1.454      0.146      -7.542       1.119\n",
       "std_og_mou_8             56.5097     31.784      1.778      0.075      -5.786     118.806\n",
       "spl_og_mou_8              2.9042      2.036      1.426      0.154      -1.086       6.895\n",
       "total_og_mou_8          -65.3701     32.033     -2.041      0.041    -128.153      -2.587\n",
       "loc_ic_t2t_mou_8      -1314.4706   9050.822     -0.145      0.885   -1.91e+04    1.64e+04\n",
       "loc_ic_t2m_mou_6          3.2176      1.833      1.755      0.079      -0.375       6.810\n",
       "loc_ic_t2m_mou_8      -1535.3881   1.06e+04     -0.145      0.885   -2.23e+04    1.92e+04\n",
       "loc_ic_t2f_mou_8       -491.0362   3326.303     -0.148      0.883   -7010.470    6028.397\n",
       "loc_ic_mou_6              0.5218      2.430      0.215      0.830      -4.240       5.284\n",
       "loc_ic_mou_7             16.2365      1.647      9.856      0.000      13.008      19.465\n",
       "loc_ic_mou_8           1712.7405   1.21e+04      0.142      0.887    -2.2e+04    2.54e+04\n",
       "std_ic_t2t_mou_6          6.3035      1.697      3.715      0.000       2.978       9.629\n",
       "std_ic_t2t_mou_8      -1322.0953   1.66e+04     -0.080      0.936   -3.38e+04    3.12e+04\n",
       "std_ic_t2m_mou_8      -1098.0856   1.39e+04     -0.079      0.937   -2.84e+04    2.62e+04\n",
       "std_ic_t2f_mou_8       -536.5155   6757.255     -0.079      0.937   -1.38e+04    1.27e+04\n",
       "std_ic_mou_6              0.2580      1.158      0.223      0.824      -2.012       2.528\n",
       "std_ic_mou_8           1431.6088   1.83e+04      0.078      0.938   -3.44e+04    3.73e+04\n",
       "total_ic_mou_8           -0.6429     13.144     -0.049      0.961     -26.404      25.118\n",
       "spl_ic_mou_8             -7.0006      0.569    -12.306      0.000      -8.116      -5.886\n",
       "isd_ic_mou_8              0.9898      5.413      0.183      0.855      -9.620      11.600\n",
       "total_rech_num_6         -1.1237      0.672     -1.673      0.094      -2.440       0.193\n",
       "total_rech_num_7          4.8547      0.647      7.506      0.000       3.587       6.122\n",
       "total_rech_num_8         -8.5436      0.774    -11.034      0.000     -10.061      -7.026\n",
       "total_rech_amt_6          6.4523      3.093      2.086      0.037       0.391      12.513\n",
       "total_rech_amt_7         -6.8469      3.610     -1.896      0.058     -13.923       0.229\n",
       "total_rech_amt_8        -36.0504      4.446     -8.109      0.000     -44.764     -27.337\n",
       "max_rech_amt_6           -3.4870      0.922     -3.780      0.000      -5.295      -1.679\n",
       "max_rech_amt_7            0.5530      0.778      0.711      0.477      -0.972       2.078\n",
       "max_rech_amt_8           11.2516      1.269      8.867      0.000       8.764      13.739\n",
       "last_day_rch_amt_8      -17.7898      1.196    -14.875      0.000     -20.134     -15.446\n",
       "total_rech_data_6         3.2243      0.741      4.353      0.000       1.772       4.676\n",
       "total_rech_data_8        -5.6245      0.878     -6.403      0.000      -7.346      -3.903\n",
       "max_rech_data_6           3.6992      0.773      4.789      0.000       2.185       5.213\n",
       "max_rech_data_7           0.1399      0.665      0.210      0.833      -1.164       1.444\n",
       "max_rech_data_8          -4.8867      1.080     -4.523      0.000      -7.004      -2.769\n",
       "av_rech_amt_data_6      -11.6982      1.915     -6.110      0.000     -15.451      -7.945\n",
       "av_rech_amt_data_8       -1.6092      2.361     -0.681      0.496      -6.237       3.019\n",
       "vol_2g_mb_8              -7.0016      1.186     -5.905      0.000      -9.326      -4.678\n",
       "vol_3g_mb_7               5.2999      1.536      3.450      0.001       2.289       8.311\n",
       "vol_3g_mb_8              -8.0437      2.256     -3.565      0.000     -12.466      -3.621\n",
       "monthly_2g_6             -0.7981      0.286     -2.791      0.005      -1.359      -0.238\n",
       "monthly_2g_7             -0.5359      0.394     -1.359      0.174      -1.309       0.237\n",
       "monthly_2g_8             -4.6127      0.619     -7.448      0.000      -5.827      -3.399\n",
       "sachet_2g_8              -4.7886      0.570     -8.397      0.000      -5.906      -3.671\n",
       "monthly_3g_7             -0.3476      0.985     -0.353      0.724      -2.278       1.583\n",
       "monthly_3g_8             -4.9011      1.696     -2.890      0.004      -8.225      -1.577\n",
       "sachet_3g_8              -1.7848      1.200     -1.488      0.137      -4.136       0.567\n",
       "aon                      -0.4979      0.101     -4.907      0.000      -0.697      -0.299\n",
       "aug_vbc_3g               -7.0817      1.778     -3.982      0.000     -10.567      -3.596\n",
       "jul_vbc_3g               -0.5413      0.934     -0.580      0.562      -2.371       1.289\n",
       "total_recharge_amnt_8    11.5719      3.014      3.839      0.000       5.664      17.480\n",
       "=========================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled_sm = sm.add_constant(X_resampled[col])\n",
    "logm2 = sm.GLM(y_resampled, X_resampled_sm, family=sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3270c989",
   "metadata": {},
   "source": [
    "### Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de453884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>loc_og_t2t_mou_8</th>\n",
       "      <th>...</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>total_recharge_amnt_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5662</th>\n",
       "      <td>554.740</td>\n",
       "      <td>782.352</td>\n",
       "      <td>673.692</td>\n",
       "      <td>38.63</td>\n",
       "      <td>845.83</td>\n",
       "      <td>661.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.56</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1360</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37574</th>\n",
       "      <td>1563.157</td>\n",
       "      <td>1579.675</td>\n",
       "      <td>1256.565</td>\n",
       "      <td>3158.18</td>\n",
       "      <td>1144.44</td>\n",
       "      <td>1327.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.91</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58341</th>\n",
       "      <td>594.217</td>\n",
       "      <td>796.737</td>\n",
       "      <td>996.393</td>\n",
       "      <td>1200.53</td>\n",
       "      <td>186.48</td>\n",
       "      <td>585.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.53</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>594</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23282</th>\n",
       "      <td>352.160</td>\n",
       "      <td>197.245</td>\n",
       "      <td>365.564</td>\n",
       "      <td>179.88</td>\n",
       "      <td>116.58</td>\n",
       "      <td>507.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>227.84</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1164</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>794.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30561</th>\n",
       "      <td>332.040</td>\n",
       "      <td>275.976</td>\n",
       "      <td>267.033</td>\n",
       "      <td>96.89</td>\n",
       "      <td>178.24</td>\n",
       "      <td>424.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.78</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>635</td>\n",
       "      <td>31.05</td>\n",
       "      <td>337.7</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         arpu_6    arpu_7    arpu_8  onnet_mou_7  offnet_mou_7  offnet_mou_8  \\\n",
       "5662    554.740   782.352   673.692        38.63        845.83        661.89   \n",
       "37574  1563.157  1579.675  1256.565      3158.18       1144.44       1327.03   \n",
       "58341   594.217   796.737   996.393      1200.53        186.48        585.36   \n",
       "23282   352.160   197.245   365.564       179.88        116.58        507.64   \n",
       "30561   332.040   275.976   267.033        96.89        178.24        424.68   \n",
       "\n",
       "       roam_ic_mou_6  roam_og_mou_7  roam_og_mou_8  loc_og_t2t_mou_8  ...  \\\n",
       "5662             0.0           0.00            0.0             15.56  ...   \n",
       "37574            0.0           0.00            0.0              5.91  ...   \n",
       "58341            0.0           0.00            0.0              8.53  ...   \n",
       "23282            0.0          34.96            0.0            227.84  ...   \n",
       "30561            0.0           0.00            0.0              3.78  ...   \n",
       "\n",
       "       monthly_2g_7  monthly_2g_8  sachet_2g_8  monthly_3g_7  monthly_3g_8  \\\n",
       "5662              0             0            0             0             0   \n",
       "37574             0             0            0             0             0   \n",
       "58341             0             0            0             0             0   \n",
       "23282             0             0            3             0             0   \n",
       "30561             0             0            0             0             0   \n",
       "\n",
       "       sachet_3g_8   aon  aug_vbc_3g  jul_vbc_3g  total_recharge_amnt_8  \n",
       "5662             0  1360        0.00         0.0                  780.0  \n",
       "37574            0   834        0.00         0.0                 1432.0  \n",
       "58341            0   594        0.00         0.0                 1142.0  \n",
       "23282            0  1164        0.00         0.0                  794.0  \n",
       "30561            0   635       31.05       337.7                  335.0  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test[col]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd20e6fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/statsmodels/tsa/tsatools.py:142: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    }
   ],
   "source": [
    "X_test_sm = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df6e96f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/statsmodels/genmod/families/links.py:188: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = res.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c63d4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5662     0.0\n",
       "37574    1.0\n",
       "58341    0.0\n",
       "23282    0.0\n",
       "30561    0.0\n",
       "45844    0.0\n",
       "30159    0.0\n",
       "62778    0.0\n",
       "45559    0.0\n",
       "35274    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6dbfcf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>...</th>\n",
       "      <th>monthly_2g_7</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>total_recharge_amnt_8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5662</th>\n",
       "      <td>1.0</td>\n",
       "      <td>554.740</td>\n",
       "      <td>782.352</td>\n",
       "      <td>673.692</td>\n",
       "      <td>38.63</td>\n",
       "      <td>845.83</td>\n",
       "      <td>661.89</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1360</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>780.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37574</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1563.157</td>\n",
       "      <td>1579.675</td>\n",
       "      <td>1256.565</td>\n",
       "      <td>3158.18</td>\n",
       "      <td>1144.44</td>\n",
       "      <td>1327.03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>834</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1432.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58341</th>\n",
       "      <td>1.0</td>\n",
       "      <td>594.217</td>\n",
       "      <td>796.737</td>\n",
       "      <td>996.393</td>\n",
       "      <td>1200.53</td>\n",
       "      <td>186.48</td>\n",
       "      <td>585.36</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>594</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23282</th>\n",
       "      <td>1.0</td>\n",
       "      <td>352.160</td>\n",
       "      <td>197.245</td>\n",
       "      <td>365.564</td>\n",
       "      <td>179.88</td>\n",
       "      <td>116.58</td>\n",
       "      <td>507.64</td>\n",
       "      <td>0.0</td>\n",
       "      <td>34.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1164</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>794.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30561</th>\n",
       "      <td>1.0</td>\n",
       "      <td>332.040</td>\n",
       "      <td>275.976</td>\n",
       "      <td>267.033</td>\n",
       "      <td>96.89</td>\n",
       "      <td>178.24</td>\n",
       "      <td>424.68</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>635</td>\n",
       "      <td>31.05</td>\n",
       "      <td>337.7</td>\n",
       "      <td>335.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const    arpu_6    arpu_7    arpu_8  onnet_mou_7  offnet_mou_7  \\\n",
       "5662     1.0   554.740   782.352   673.692        38.63        845.83   \n",
       "37574    1.0  1563.157  1579.675  1256.565      3158.18       1144.44   \n",
       "58341    1.0   594.217   796.737   996.393      1200.53        186.48   \n",
       "23282    1.0   352.160   197.245   365.564       179.88        116.58   \n",
       "30561    1.0   332.040   275.976   267.033        96.89        178.24   \n",
       "\n",
       "       offnet_mou_8  roam_ic_mou_6  roam_og_mou_7  roam_og_mou_8  ...  \\\n",
       "5662         661.89            0.0           0.00            0.0  ...   \n",
       "37574       1327.03            0.0           0.00            0.0  ...   \n",
       "58341        585.36            0.0           0.00            0.0  ...   \n",
       "23282        507.64            0.0          34.96            0.0  ...   \n",
       "30561        424.68            0.0           0.00            0.0  ...   \n",
       "\n",
       "       monthly_2g_7  monthly_2g_8  sachet_2g_8  monthly_3g_7  monthly_3g_8  \\\n",
       "5662              0             0            0             0             0   \n",
       "37574             0             0            0             0             0   \n",
       "58341             0             0            0             0             0   \n",
       "23282             0             0            3             0             0   \n",
       "30561             0             0            0             0             0   \n",
       "\n",
       "       sachet_3g_8   aon  aug_vbc_3g  jul_vbc_3g  total_recharge_amnt_8  \n",
       "5662             0  1360        0.00         0.0                  780.0  \n",
       "37574            0   834        0.00         0.0                 1432.0  \n",
       "58341            0   594        0.00         0.0                 1142.0  \n",
       "23282            0  1164        0.00         0.0                  794.0  \n",
       "30561            0   635       31.05       337.7                  335.0  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2fb4790c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27020, 71)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc21710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = res.predict(X_resampled_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41d41dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared train: 0.61567732988164\n",
      "rss train: 2596.0996366495215\n",
      "mse train: 0.09608066752958999\n"
     ]
    }
   ],
   "source": [
    "metric = []\n",
    "r2_train_lr = r2_score(y_resampled, y_pred_train)\n",
    "print(f\"r-squared train: {r2_train_lr}\")\n",
    "metric.append(r2_train_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_resampled - y_pred_train))\n",
    "print(f\"rss train: {rss1_lr}\")\n",
    "metric.append(rss1_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_resampled, y_pred_train)\n",
    "print(f\"mse train: {mse_train_lr}\")\n",
    "metric.append(mse_train_lr**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502455e8",
   "metadata": {},
   "source": [
    "## Looking at the rmse value (close to 0.1) Logistic regression doesn't seems to be a good model with such large number of  columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd93b4a0",
   "metadata": {},
   "source": [
    "## So lets move on with PCA and Logistic Regression to check if model improves or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb5679",
   "metadata": {},
   "source": [
    "## PCA on the data\n",
    "\n",
    "- While computing the principal components, we must not include the entire dataset. Model building is all about doing well on the data we haven't seen yet!\n",
    "- So we'll calculate the PCs using the train data, and apply them later on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2a5cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "228cc28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27020,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f357b520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27020, 140)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d5bfc9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4879eab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(random_state=42)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a324422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.35047464e-02,  1.01590027e-02, -8.16555980e-03, ...,\n",
       "        -3.88169272e-03, -1.04343358e-02, -4.88527815e-03],\n",
       "       [ 5.02672822e-02,  5.45672975e-02,  3.67326151e-02, ...,\n",
       "        -6.35413946e-03, -3.61551336e-03, -1.48061679e-02],\n",
       "       [ 4.94711563e-02,  7.53079967e-02,  7.15851585e-02, ...,\n",
       "         6.11361560e-02,  6.04584562e-02,  8.95058455e-02],\n",
       "       ...,\n",
       "       [-0.00000000e+00,  3.80003423e-17,  1.35725611e-16, ...,\n",
       "         3.87186002e-01,  1.10686101e-01,  3.32225143e-01],\n",
       "       [-0.00000000e+00, -2.45256886e-16, -4.25390089e-17, ...,\n",
       "        -2.07809721e-01, -6.30643273e-01,  3.26669474e-01],\n",
       "       [-0.00000000e+00, -3.23568689e-16, -4.51354345e-16, ...,\n",
       "         4.25208389e-02, -1.34130371e-01, -6.34108943e-02]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "462adf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.91252038e-01, 1.54931792e-01, 7.57588333e-02, 5.90952199e-02,\n",
       "       5.49135345e-02, 4.99767444e-02, 4.50120182e-02, 3.22952966e-02,\n",
       "       2.09118379e-02, 1.99798658e-02, 1.94920374e-02, 1.80128313e-02,\n",
       "       1.57294790e-02, 1.30437391e-02, 1.24168582e-02, 1.17542865e-02,\n",
       "       1.07906131e-02, 1.02962745e-02, 1.02103571e-02, 9.98233482e-03,\n",
       "       9.05194680e-03, 7.95905475e-03, 7.79873625e-03, 7.30364296e-03,\n",
       "       6.98156214e-03, 6.43530669e-03, 6.34687852e-03, 5.72927356e-03,\n",
       "       5.30088477e-03, 5.14238260e-03, 4.96847301e-03, 4.53954520e-03,\n",
       "       4.15873949e-03, 3.56319611e-03, 3.37376581e-03, 3.19248123e-03,\n",
       "       3.11766481e-03, 2.98699464e-03, 2.93332748e-03, 2.88736577e-03,\n",
       "       2.78812254e-03, 2.65987692e-03, 2.54834122e-03, 2.49239527e-03,\n",
       "       2.35440518e-03, 2.25087382e-03, 2.15289981e-03, 2.08662415e-03,\n",
       "       2.01152622e-03, 1.84112404e-03, 1.81619984e-03, 1.77210369e-03,\n",
       "       1.66672463e-03, 1.59797785e-03, 1.48349263e-03, 1.46678056e-03,\n",
       "       1.32160721e-03, 1.29511071e-03, 1.26543822e-03, 1.21552456e-03,\n",
       "       1.11375289e-03, 1.10179918e-03, 1.03716961e-03, 1.00784582e-03,\n",
       "       9.56853089e-04, 9.29867018e-04, 8.91347833e-04, 8.62515426e-04,\n",
       "       8.52832743e-04, 8.38191992e-04, 8.02949581e-04, 7.66093480e-04,\n",
       "       6.58901468e-04, 6.56610514e-04, 5.95930761e-04, 5.71774314e-04,\n",
       "       5.49567062e-04, 5.26976184e-04, 4.94950660e-04, 4.75854653e-04,\n",
       "       4.69201857e-04, 4.39413457e-04, 4.29065542e-04, 3.99785360e-04,\n",
       "       3.93407251e-04, 3.78678612e-04, 3.20946646e-04, 3.16244851e-04,\n",
       "       2.96500887e-04, 2.87373444e-04, 2.74223228e-04, 2.44889074e-04,\n",
       "       2.39582764e-04, 2.21496792e-04, 1.91530461e-04, 1.79517052e-04,\n",
       "       1.69574771e-04, 1.64930328e-04, 1.48998077e-04, 1.47302529e-04,\n",
       "       1.37600741e-04, 1.13081023e-04, 1.07375626e-04, 9.88307906e-05,\n",
       "       9.37233627e-05, 6.63843684e-05, 5.87171686e-05, 5.40950063e-05,\n",
       "       4.47039942e-05, 3.58974025e-05, 1.93605807e-05, 1.74781231e-05,\n",
       "       1.52727416e-05, 9.35820910e-06, 6.33649665e-06, 1.96183114e-06,\n",
       "       8.10002746e-07, 2.01846180e-07, 3.32539858e-12, 1.96532706e-12,\n",
       "       1.56970539e-12, 1.34037617e-12, 1.18575245e-12, 1.06539451e-12,\n",
       "       1.05642302e-12, 7.10698327e-13, 5.33445543e-13, 3.83558215e-13,\n",
       "       3.75829658e-13, 3.62571185e-13, 2.72778086e-13, 2.22664757e-13,\n",
       "       1.00963591e-13, 3.77178139e-32, 7.33975539e-34, 7.30336148e-34,\n",
       "       7.30336148e-34, 7.30336148e-34, 7.30336148e-34, 7.30336148e-34])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35ab804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cumu = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5653298c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa32c601fa0>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=[12,8])\n",
    "plt.plot(range(1,len(var_cumu)+1), var_cumu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e46d15",
   "metadata": {},
   "source": [
    "## Looking at the scree plot with 50 PCs we have more than 95% of variance explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6b98d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_final = IncrementalPCA(n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ef462a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca = pca_final.fit_transform(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4acf2f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27020, 50)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "51c3c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = np.corrcoef(df_train_pca.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "469fc042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3fdc23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00, -1.90802995e-07,  1.88403450e-07, ...,\n",
       "         1.06006042e-05, -2.13116352e-06, -2.95160151e-06],\n",
       "       [-1.90802995e-07,  1.00000000e+00, -2.42863067e-07, ...,\n",
       "         8.89837133e-05,  2.30076426e-06, -7.72592613e-06],\n",
       "       [ 1.88403450e-07, -2.42863067e-07,  1.00000000e+00, ...,\n",
       "        -1.26310803e-05,  3.53589238e-06,  1.27014860e-04],\n",
       "       ...,\n",
       "       [ 1.06006042e-05,  8.89837133e-05, -1.26310803e-05, ...,\n",
       "         1.00000000e+00, -3.18007773e-02,  5.39380703e-02],\n",
       "       [-2.13116352e-06,  2.30076426e-06,  3.53589238e-06, ...,\n",
       "        -3.18007773e-02,  1.00000000e+00, -1.97633793e-02],\n",
       "       [-2.95160151e-06, -7.72592613e-06,  1.27014860e-04, ...,\n",
       "         5.39380703e-02, -1.97633793e-02,  1.00000000e+00]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5852693",
   "metadata": {},
   "source": [
    "### Applying the transformation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "76137d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 70)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "2d03012a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanchoud/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py:493: FutureWarning: The feature names should match those that were passed during fit. Starting version 1.2, an error will be raised.\n",
      "Feature names seen at fit time, yet now missing:\n",
      "- av_rech_amt_data_7\n",
      "- average_amnt_6_7\n",
      "- ic_others_6\n",
      "- ic_others_7\n",
      "- ic_others_8\n",
      "- ...\n",
      "\n",
      "  warnings.warn(message, FutureWarning)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 70 features, but IncrementalPCA is expecting 140 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zh/dtjt7c1928n9c2xwnxyc60wc0000gn/T/ipykernel_41150/2504357792.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_test_pca\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpca_final\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdf_test_pca\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_incremental_pca.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    390\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    391\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 392\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/decomposition/_base.py\u001b[0m in \u001b[0;36mtransform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    118\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    598\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    599\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ensure_2d\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 600\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    601\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[0;34m(self, X, reset)\u001b[0m\n\u001b[1;32m    398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    401\u001b[0m                 \u001b[0;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m                 \u001b[0;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: X has 70 features, but IncrementalPCA is expecting 140 features as input."
     ]
    }
   ],
   "source": [
    "df_test_pca = pca_final.transform(X_test)\n",
    "df_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8128fc2c",
   "metadata": {},
   "source": [
    "## Applying logistic regression on the data on our Principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af703228",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_pca = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9149f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca = learner_pca.fit(df_train_pca, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fadaff5",
   "metadata": {},
   "source": [
    "### Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da7cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_test = model_pca.predict_proba(df_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98027341",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
