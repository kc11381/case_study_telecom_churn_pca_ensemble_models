{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85815f8b",
   "metadata": {},
   "source": [
    "# Telecom Churn case study using PCA and Ensemble\n",
    "\n",
    "### Problem Statement\n",
    "In the telecom industry, customers are able to choose from multiple service providers and actively switch from one operator to another. In this highly competitive market, the telecommunications industry experiences an average of 15-25% annual churn rate. Given the fact that it costs 5-10 times more to acquire a new customer than to retain an existing one, customer retention has now become even more important than customer acquisition.\n",
    "\n",
    "For many incumbent operators, retaining high profitable customers is the number one business\n",
    "goal. To reduce customer churn, telecom companies need to predict which customers are at high risk of churn. In this project, you will analyze customer-level data of a leading telecom firm, build predictive models to identify customers at high risk of churn.\n",
    "\n",
    "In this competition, your goal is to build a machine learning model that is able to predict churning customers based on the features provided for their usage.\n",
    "\n",
    "### Goal\n",
    "It is your job to predict if a customer will churn, given the ~170 columns containing customer behavior, usage patterns, payment patterns, and other features that might be relevant. Your target variable is \"churn_probability\"\n",
    "Note: Make sure your accuracy is greater than the sample submission that is present in the leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "a5dfb968",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import IncrementalPCA\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db327e7",
   "metadata": {},
   "source": [
    "## Step 1. Reading, Understanding and Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "75b4d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_train_df = pd.read_csv('train (1).csv')\n",
    "telecom_test_df = pd.read_csv('test (1).csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aafd7bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>...</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>31.277</td>\n",
       "      <td>87.009</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1958</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>0.000</td>\n",
       "      <td>122.787</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>710</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>60.806</td>\n",
       "      <td>103.176</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>882</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>156.362</td>\n",
       "      <td>205.260</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>982</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>240.708</td>\n",
       "      <td>128.191</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>647</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 172 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0   0        109             0.0             0.0             0.0   \n",
       "1   1        109             0.0             0.0             0.0   \n",
       "2   2        109             0.0             0.0             0.0   \n",
       "3   3        109             0.0             0.0             0.0   \n",
       "4   4        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8   arpu_6  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   31.277   \n",
       "1            6/30/2014            7/31/2014            8/31/2014    0.000   \n",
       "2            6/30/2014            7/31/2014            8/31/2014   60.806   \n",
       "3            6/30/2014            7/31/2014            8/31/2014  156.362   \n",
       "4            6/30/2014            7/31/2014            8/31/2014  240.708   \n",
       "\n",
       "    arpu_7  ...  sachet_3g_7  sachet_3g_8  fb_user_6  fb_user_7  fb_user_8  \\\n",
       "0   87.009  ...            0            0        NaN        NaN        NaN   \n",
       "1  122.787  ...            0            0        NaN        1.0        NaN   \n",
       "2  103.176  ...            0            0        NaN        NaN        NaN   \n",
       "3  205.260  ...            0            0        NaN        NaN        NaN   \n",
       "4  128.191  ...            1            0        1.0        1.0        1.0   \n",
       "\n",
       "    aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  churn_probability  \n",
       "0  1958         0.0         0.0         0.0                  0  \n",
       "1   710         0.0         0.0         0.0                  0  \n",
       "2   882         0.0         0.0         0.0                  0  \n",
       "3   982         0.0         0.0         0.0                  0  \n",
       "4   647         0.0         0.0         0.0                  0  \n",
       "\n",
       "[5 rows x 172 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08ff9072",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>last_date_of_month_6</th>\n",
       "      <th>last_date_of_month_7</th>\n",
       "      <th>last_date_of_month_8</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>...</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>69999</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>91.882</td>\n",
       "      <td>65.330</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1692</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>70000</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>414.168</td>\n",
       "      <td>515.568</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2533</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>70001</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>329.844</td>\n",
       "      <td>434.884</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>277</td>\n",
       "      <td>525.61</td>\n",
       "      <td>758.41</td>\n",
       "      <td>241.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70002</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>43.550</td>\n",
       "      <td>171.390</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1244</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70003</td>\n",
       "      <td>109</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6/30/2014</td>\n",
       "      <td>7/31/2014</td>\n",
       "      <td>8/31/2014</td>\n",
       "      <td>306.854</td>\n",
       "      <td>406.289</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>462</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 171 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  loc_ic_t2o_mou  \\\n",
       "0  69999        109             0.0             0.0             0.0   \n",
       "1  70000        109             0.0             0.0             0.0   \n",
       "2  70001        109             0.0             0.0             0.0   \n",
       "3  70002        109             0.0             0.0             0.0   \n",
       "4  70003        109             0.0             0.0             0.0   \n",
       "\n",
       "  last_date_of_month_6 last_date_of_month_7 last_date_of_month_8   arpu_6  \\\n",
       "0            6/30/2014            7/31/2014            8/31/2014   91.882   \n",
       "1            6/30/2014            7/31/2014            8/31/2014  414.168   \n",
       "2            6/30/2014            7/31/2014            8/31/2014  329.844   \n",
       "3            6/30/2014            7/31/2014            8/31/2014   43.550   \n",
       "4            6/30/2014            7/31/2014            8/31/2014  306.854   \n",
       "\n",
       "    arpu_7  ...  sachet_3g_6  sachet_3g_7  sachet_3g_8  fb_user_6  fb_user_7  \\\n",
       "0   65.330  ...            0            0            0        NaN        NaN   \n",
       "1  515.568  ...            0            0            0        NaN        NaN   \n",
       "2  434.884  ...            0            0            0        NaN        NaN   \n",
       "3  171.390  ...            0            0            0        NaN        NaN   \n",
       "4  406.289  ...            0            0            0        NaN        NaN   \n",
       "\n",
       "   fb_user_8   aon  aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  \n",
       "0        NaN  1692        0.00        0.00        0.00  \n",
       "1        NaN  2533        0.00        0.00        0.00  \n",
       "2        NaN   277      525.61      758.41      241.84  \n",
       "3        NaN  1244        0.00        0.00        0.00  \n",
       "4        NaN   462        0.00        0.00        0.00  \n",
       "\n",
       "[5 rows x 171 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b3eee97",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 172)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade9e8ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 171)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d5176fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'circle_id', 'loc_og_t2o_mou', 'std_og_t2o_mou', 'loc_ic_t2o_mou',\n",
       "       'last_date_of_month_6', 'last_date_of_month_7', 'last_date_of_month_8',\n",
       "       'arpu_6', 'arpu_7',\n",
       "       ...\n",
       "       'sachet_3g_7', 'sachet_3g_8', 'fb_user_6', 'fb_user_7', 'fb_user_8',\n",
       "       'aon', 'aug_vbc_3g', 'jul_vbc_3g', 'jun_vbc_3g', 'churn_probability'],\n",
       "      dtype='object', length=172)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cd748c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69999 entries, 0 to 69998\n",
      "Columns: 172 entries, id to churn_probability\n",
      "dtypes: float64(135), int64(28), object(9)\n",
      "memory usage: 91.9+ MB\n"
     ]
    }
   ],
   "source": [
    "telecom_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6803651e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>circle_id</th>\n",
       "      <th>loc_og_t2o_mou</th>\n",
       "      <th>std_og_t2o_mou</th>\n",
       "      <th>loc_ic_t2o_mou</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>...</th>\n",
       "      <th>sachet_3g_7</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>fb_user_6</th>\n",
       "      <th>fb_user_7</th>\n",
       "      <th>fb_user_8</th>\n",
       "      <th>aon</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>churn_probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.0</td>\n",
       "      <td>69297.0</td>\n",
       "      <td>69297.0</td>\n",
       "      <td>69297.0</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>67231.000000</td>\n",
       "      <td>67312.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>17568.000000</td>\n",
       "      <td>17865.000000</td>\n",
       "      <td>18417.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.000000</td>\n",
       "      <td>69999.00000</td>\n",
       "      <td>69999.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>34999.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>283.134365</td>\n",
       "      <td>278.185912</td>\n",
       "      <td>278.858826</td>\n",
       "      <td>133.153275</td>\n",
       "      <td>133.894438</td>\n",
       "      <td>...</td>\n",
       "      <td>0.081444</td>\n",
       "      <td>0.085487</td>\n",
       "      <td>0.916325</td>\n",
       "      <td>0.909544</td>\n",
       "      <td>0.890319</td>\n",
       "      <td>1220.639709</td>\n",
       "      <td>68.108597</td>\n",
       "      <td>65.935830</td>\n",
       "      <td>60.07674</td>\n",
       "      <td>0.101887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>20207.115084</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>334.213918</td>\n",
       "      <td>344.366927</td>\n",
       "      <td>351.924315</td>\n",
       "      <td>299.963093</td>\n",
       "      <td>311.277193</td>\n",
       "      <td>...</td>\n",
       "      <td>0.634547</td>\n",
       "      <td>0.680035</td>\n",
       "      <td>0.276907</td>\n",
       "      <td>0.286842</td>\n",
       "      <td>0.312501</td>\n",
       "      <td>952.426321</td>\n",
       "      <td>269.328659</td>\n",
       "      <td>267.899034</td>\n",
       "      <td>257.22681</td>\n",
       "      <td>0.302502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2258.709000</td>\n",
       "      <td>-1289.715000</td>\n",
       "      <td>-945.808000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>180.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>17499.500000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>93.581000</td>\n",
       "      <td>86.714000</td>\n",
       "      <td>84.095000</td>\n",
       "      <td>7.410000</td>\n",
       "      <td>6.675000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>468.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34999.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>197.484000</td>\n",
       "      <td>191.588000</td>\n",
       "      <td>192.234000</td>\n",
       "      <td>34.110000</td>\n",
       "      <td>32.280000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>868.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>52498.500000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>370.791000</td>\n",
       "      <td>365.369500</td>\n",
       "      <td>369.909000</td>\n",
       "      <td>119.390000</td>\n",
       "      <td>115.837500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1813.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>69998.000000</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27731.088000</td>\n",
       "      <td>35145.834000</td>\n",
       "      <td>33543.624000</td>\n",
       "      <td>7376.710000</td>\n",
       "      <td>8157.780000</td>\n",
       "      <td>...</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4337.000000</td>\n",
       "      <td>12916.220000</td>\n",
       "      <td>9165.600000</td>\n",
       "      <td>11166.21000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 163 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id  circle_id  loc_og_t2o_mou  std_og_t2o_mou  \\\n",
       "count  69999.000000    69999.0         69297.0         69297.0   \n",
       "mean   34999.000000      109.0             0.0             0.0   \n",
       "std    20207.115084        0.0             0.0             0.0   \n",
       "min        0.000000      109.0             0.0             0.0   \n",
       "25%    17499.500000      109.0             0.0             0.0   \n",
       "50%    34999.000000      109.0             0.0             0.0   \n",
       "75%    52498.500000      109.0             0.0             0.0   \n",
       "max    69998.000000      109.0             0.0             0.0   \n",
       "\n",
       "       loc_ic_t2o_mou        arpu_6        arpu_7        arpu_8   onnet_mou_6  \\\n",
       "count         69297.0  69999.000000  69999.000000  69999.000000  67231.000000   \n",
       "mean              0.0    283.134365    278.185912    278.858826    133.153275   \n",
       "std               0.0    334.213918    344.366927    351.924315    299.963093   \n",
       "min               0.0  -2258.709000  -1289.715000   -945.808000      0.000000   \n",
       "25%               0.0     93.581000     86.714000     84.095000      7.410000   \n",
       "50%               0.0    197.484000    191.588000    192.234000     34.110000   \n",
       "75%               0.0    370.791000    365.369500    369.909000    119.390000   \n",
       "max               0.0  27731.088000  35145.834000  33543.624000   7376.710000   \n",
       "\n",
       "        onnet_mou_7  ...   sachet_3g_7   sachet_3g_8     fb_user_6  \\\n",
       "count  67312.000000  ...  69999.000000  69999.000000  17568.000000   \n",
       "mean     133.894438  ...      0.081444      0.085487      0.916325   \n",
       "std      311.277193  ...      0.634547      0.680035      0.276907   \n",
       "min        0.000000  ...      0.000000      0.000000      0.000000   \n",
       "25%        6.675000  ...      0.000000      0.000000      1.000000   \n",
       "50%       32.280000  ...      0.000000      0.000000      1.000000   \n",
       "75%      115.837500  ...      0.000000      0.000000      1.000000   \n",
       "max     8157.780000  ...     33.000000     41.000000      1.000000   \n",
       "\n",
       "          fb_user_7     fb_user_8           aon    aug_vbc_3g    jul_vbc_3g  \\\n",
       "count  17865.000000  18417.000000  69999.000000  69999.000000  69999.000000   \n",
       "mean       0.909544      0.890319   1220.639709     68.108597     65.935830   \n",
       "std        0.286842      0.312501    952.426321    269.328659    267.899034   \n",
       "min        0.000000      0.000000    180.000000      0.000000      0.000000   \n",
       "25%        1.000000      1.000000    468.000000      0.000000      0.000000   \n",
       "50%        1.000000      1.000000    868.000000      0.000000      0.000000   \n",
       "75%        1.000000      1.000000   1813.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000   4337.000000  12916.220000   9165.600000   \n",
       "\n",
       "        jun_vbc_3g  churn_probability  \n",
       "count  69999.00000       69999.000000  \n",
       "mean      60.07674           0.101887  \n",
       "std      257.22681           0.302502  \n",
       "min        0.00000           0.000000  \n",
       "25%        0.00000           0.000000  \n",
       "50%        0.00000           0.000000  \n",
       "75%        0.00000           0.000000  \n",
       "max    11166.21000           1.000000  \n",
       "\n",
       "[8 rows x 163 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4be15a7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     0\n",
       "circle_id              0\n",
       "loc_og_t2o_mou       702\n",
       "std_og_t2o_mou       702\n",
       "loc_ic_t2o_mou       702\n",
       "                    ... \n",
       "aon                    0\n",
       "aug_vbc_3g             0\n",
       "jul_vbc_3g             0\n",
       "jun_vbc_3g             0\n",
       "churn_probability      0\n",
       "Length: 172, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "be40b9f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                     int64\n",
       "circle_id              int64\n",
       "loc_og_t2o_mou       float64\n",
       "std_og_t2o_mou       float64\n",
       "loc_ic_t2o_mou       float64\n",
       "                      ...   \n",
       "aon                    int64\n",
       "aug_vbc_3g           float64\n",
       "jul_vbc_3g           float64\n",
       "jun_vbc_3g           float64\n",
       "churn_probability      int64\n",
       "Length: 172, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a6b6c597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns which we have to impute as Zero as thy should not be dropped based on missing values becuase they are important.\n",
    "rech_cols_to_impute = [x for x in telecom_train_df.columns if 'rech' in x and \n",
    "                       'count' not in x and 'date' not in x and 'num' not in x]\n",
    "telecom_train_df[rech_cols_to_impute] = telecom_train_df[rech_cols_to_impute].apply(lambda x: x.fillna(0))\n",
    "telecom_test_df[rech_cols_to_impute] = telecom_test_df[rech_cols_to_impute].apply(lambda x: x.fillna(0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c81836f",
   "metadata": {},
   "source": [
    "### Dropping rows for both train and test datasets\n",
    " - Rows which are empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "060c74b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_train_df.dropna(axis=0, how='all', inplace=True)\n",
    "telecom_test_df.dropna(axis=0, how='all', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "af10b97f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69999, 172)\n",
      "(30000, 171)\n"
     ]
    }
   ],
   "source": [
    "print(telecom_train_df.shape)\n",
    "print(telecom_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e06618c",
   "metadata": {},
   "source": [
    "### Dropping columns for both train and test datasets\n",
    "\n",
    "    - Not needed columns like Id, last_date_of_month_6 etc.\n",
    "    - Columns having more than 70% values as null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "abd04209",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For us dates doesn't matter as long as customer is doing a recharge.\n",
    "cols_to_delete = ['id', 'last_date_of_month_6', 'last_date_of_month_7', 'last_date_of_month_8',\n",
    "                  'date_of_last_rech_data_6', 'date_of_last_rech_data_7', 'date_of_last_rech_data_8',\n",
    "                  'date_of_last_rech_6', 'date_of_last_rech_7', 'date_of_last_rech_8'\n",
    "                 ]\n",
    "telecom_train_df.drop(cols_to_delete, axis=1, inplace=True)\n",
    "telecom_test_df.drop(cols_to_delete, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4d5907c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "arpu_3g_8           0.74\n",
       "night_pck_user_8    0.74\n",
       "night_pck_user_7    0.74\n",
       "arpu_2g_8           0.74\n",
       "arpu_2g_7           0.74\n",
       "fb_user_7           0.74\n",
       "arpu_3g_7           0.74\n",
       "fb_user_8           0.74\n",
       "count_rech_3g_8     0.74\n",
       "count_rech_3g_7     0.74\n",
       "count_rech_2g_8     0.74\n",
       "count_rech_2g_7     0.74\n",
       "arpu_2g_6           0.75\n",
       "count_rech_3g_6     0.75\n",
       "night_pck_user_6    0.75\n",
       "fb_user_6           0.75\n",
       "arpu_3g_6           0.75\n",
       "count_rech_2g_6     0.75\n",
       "dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to check the % of null values\n",
    "round((pd.isnull(telecom_train_df).sum()/len(telecom_train_df.index)),2)[pd.isnull(telecom_train_df).sum()/ len(telecom_train_df.index) > 0.70].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "af4da69b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of missing data > 70% columns in train dataset\n",
    "len(round((pd.isnull(telecom_train_df).sum()/len(telecom_train_df.index)),2)[pd.isnull(telecom_train_df).sum()/ len(telecom_train_df.index) > 0.70].sort_values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "08b6ed61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count of missing data > 70% columns in test dataset\n",
    "len(round((pd.isnull(telecom_test_df).sum()/len(telecom_test_df.index)),2)[pd.isnull(telecom_test_df).sum()/ len(telecom_test_df.index) > 0.70].sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b77121",
   "metadata": {},
   "source": [
    "### As we have more than 70% data as null for 18 columns in train and test, we are dropping these columns from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "176525b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_delete = ((pd.isnull(telecom_train_df).sum()/len(telecom_train_df.index))[pd.isnull(telecom_train_df).sum()/ len(telecom_train_df.index) > 0.70].sort_values()).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "decb3b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['arpu_3g_8', 'night_pck_user_8', 'arpu_2g_8', 'count_rech_3g_8', 'fb_user_8', 'count_rech_2g_8', 'arpu_3g_7', 'fb_user_7', 'arpu_2g_7', 'night_pck_user_7', 'count_rech_2g_7', 'count_rech_3g_7', 'count_rech_3g_6', 'arpu_3g_6', 'arpu_2g_6', 'night_pck_user_6', 'fb_user_6', 'count_rech_2g_6']\n"
     ]
    }
   ],
   "source": [
    "cols_to_delete = cols_to_delete.to_list()\n",
    "print(cols_to_delete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "03312c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_train_df = telecom_train_df.drop(cols_to_delete, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be9a60c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(69999, 144)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8ada9939",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_test_df = telecom_test_df.drop(cols_to_delete, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "aa95c6a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30000, 143)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e359e28",
   "metadata": {},
   "source": [
    "## Lets check the data types of columns now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "51cfe2ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 69999 entries, 0 to 69998\n",
      "Columns: 144 entries, circle_id to churn_probability\n",
      "dtypes: float64(117), int64(27)\n",
      "memory usage: 76.9 MB\n"
     ]
    }
   ],
   "source": [
    "telecom_train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d47ca287",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 30000 entries, 0 to 29999\n",
      "Columns: 143 entries, circle_id to jun_vbc_3g\n",
      "dtypes: float64(117), int64(26)\n",
      "memory usage: 32.7 MB\n"
     ]
    }
   ],
   "source": [
    "telecom_test_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0444c3e",
   "metadata": {},
   "source": [
    "### We can see now we don't have any categorical data, all are numerical data only."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da80afd3",
   "metadata": {},
   "source": [
    "### Imputing the na values with\n",
    " - Median for numerical variables\n",
    " - Mode for categorical variables - Not needed in out this case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3ce3ad7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A generic method to impute na\n",
    "def replace_na(df, columns, data_type):\n",
    "    for col in columns:\n",
    "        if data_type == 'categorical':\n",
    "            value = pd.to_datetime(df[col]).mode()\n",
    "        else:\n",
    "            value = df[col].median()\n",
    "        df[col].fillna(value, inplace=True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b802153c",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_train_df = replace_na(telecom_train_df, telecom_train_df.columns, 'numerical')\n",
    "telecom_test_df = replace_na(telecom_test_df, telecom_test_df.columns, 'numerical')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a21f588",
   "metadata": {},
   "source": [
    "### Lets check for unique entries in train and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4bafbc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cols_to_delete_unique(df, df_columns, threshold=4):\n",
    "    # threshold=4 means column has only 1 unique value\n",
    "    # eg. telecom_train_df['circle_id'].describe().unique() --> array([30000.,   109.,     0.])\n",
    "    # Here because there are all 109 in column, we have only 3 entries in array.\n",
    "    cols_to_delete = []\n",
    "    for column in df_columns:\n",
    "        if len(df[column].describe().unique()) < threshold:\n",
    "            cols_to_delete.append(column)\n",
    "    \n",
    "    return cols_to_delete"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf0895de",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69999, 144)\n",
      "(30000, 143)\n"
     ]
    }
   ],
   "source": [
    "print(telecom_train_df.shape)\n",
    "print(telecom_test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "8c597e15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(69999, 134)\n",
      "(30000, 133)\n"
     ]
    }
   ],
   "source": [
    "# on train data\n",
    "telecom_train_df = telecom_train_df.drop(cols_to_delete_unique(telecom_train_df, telecom_train_df.columns), axis=1)\n",
    "print(telecom_train_df.shape)\n",
    "\n",
    "# on test data\n",
    "telecom_test_df = telecom_test_df.drop(cols_to_delete_unique(telecom_test_df, telecom_test_df.columns), axis=1)\n",
    "print(telecom_test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f6d3fb",
   "metadata": {},
   "source": [
    "### Lets find the high value customers based on recharge done in 6th and 7th month and update dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6656b1",
   "metadata": {},
   "source": [
    "### For train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea5fecfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "477.5"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total data recharge in 6th, 7th and 8th months\n",
    "telecom_train_df[\"total_data_recharge_amnt_6\"] = telecom_train_df.total_rech_data_6 * telecom_train_df.av_rech_amt_data_6\n",
    "telecom_train_df[\"total_data_recharge_amnt_7\"] = telecom_train_df.total_rech_data_7 * telecom_train_df.av_rech_amt_data_7\n",
    "telecom_train_df[\"total_data_recharge_amnt_8\"] = telecom_train_df.total_rech_data_8 * telecom_train_df.av_rech_amt_data_8\n",
    "\n",
    "# total amount spent on recharge in 6th, 7th and 8th months\n",
    "telecom_train_df[\"total_recharge_amnt_6\"] = telecom_train_df.total_rech_amt_6 + telecom_train_df.total_data_recharge_amnt_6\n",
    "telecom_train_df[\"total_recharge_amnt_7\"] = telecom_train_df.total_rech_amt_7 + telecom_train_df.total_data_recharge_amnt_7\n",
    "telecom_train_df[\"total_recharge_amnt_8\"] = telecom_train_df.total_rech_amt_8 + telecom_train_df.total_data_recharge_amnt_8\n",
    "\n",
    "# average recharge for 6th and 7th month\n",
    "telecom_train_df['average_amnt_6_7'] = (telecom_train_df[\"total_recharge_amnt_6\"] + telecom_train_df[\"total_recharge_amnt_7\"])/2\n",
    "\n",
    "# 70th percentile of average_amnt_6_7\n",
    "telecom_train_df['average_amnt_6_7'].quantile(.70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0768613e",
   "metadata": {},
   "source": [
    "## Filter dataset based on average_amnt_6_7 (70th percentile for train dataset is 477.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5af14b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "telecom_train_df = telecom_train_df[telecom_train_df[\"average_amnt_6_7\"]>= telecom_train_df[\"average_amnt_6_7\"].quantile(.70)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "982270cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21013, 141)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4db1002",
   "metadata": {},
   "source": [
    "## Lets visualize the 8th month and average_amnt_6_7 months data to check behavior pattern of customers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "34e0ab59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look it later\n",
    "#plt.scatter(telecom_train_df[['average_amnt_6_7', 'total_recharge_amnt_8']])\n",
    "#plt.show()\n",
    "#sns.\n",
    "#telecom_train_df.plot.scatter(x='average_amnt_6_7', y='total_recharge_amnt_8')\n",
    "#telecom_train_df.DataFrame(np.random.rand(10, 3), columns =['average_amnt_6_7', 'total_recharge_amnt_8'])\n",
    "\n",
    "#telecom_train_df.plot.bar(x=\"average_amnt_6_7\", y=\"total_recharge_amnt_8\", rot=70);\n",
    "\n",
    "#ig, ax = plt.subplots()\n",
    "\n",
    "#ax.plot(telecom_train_df['average_amnt_6_7'], telecom_train_df['total_recharge_amnt_8'])\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3127d8b",
   "metadata": {},
   "source": [
    "### For test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f97c52c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "478.0"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# total data recharge in 6th, 7th and 8th months\n",
    "telecom_test_df[\"total_data_recharge_amnt_6\"] = telecom_test_df.total_rech_data_6 * telecom_test_df.av_rech_amt_data_6\n",
    "telecom_test_df[\"total_data_recharge_amnt_7\"] = telecom_test_df.total_rech_data_7 * telecom_test_df.av_rech_amt_data_7\n",
    "telecom_test_df[\"total_data_recharge_amnt_8\"] = telecom_test_df.total_rech_data_8 * telecom_test_df.av_rech_amt_data_8\n",
    "\n",
    "# total amount spent on recharge in 6th, 7th and 8th months\n",
    "telecom_test_df[\"total_recharge_amnt_6\"] = telecom_test_df.total_rech_amt_6 + telecom_test_df.total_data_recharge_amnt_6\n",
    "telecom_test_df[\"total_recharge_amnt_7\"] = telecom_test_df.total_rech_amt_7 + telecom_test_df.total_data_recharge_amnt_7\n",
    "telecom_test_df[\"total_recharge_amnt_8\"] = telecom_test_df.total_rech_amt_8 + telecom_test_df.total_data_recharge_amnt_8\n",
    "\n",
    "# average recharge\n",
    "telecom_test_df['average_amnt_6_7'] = (telecom_test_df[\"total_recharge_amnt_6\"] + telecom_test_df[\"total_recharge_amnt_7\"])/2\n",
    "\n",
    "# 70th percentile of average_amnt_6_7\n",
    "telecom_test_df['average_amnt_6_7'].quantile(.70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10222eb0",
   "metadata": {},
   "source": [
    "### Filter dataset based on average_amnt_6_7 (70th percentile for test dataset is 478.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7cf6d5ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9003, 140)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_test_df = telecom_test_df[telecom_test_df[\"average_amnt_6_7\"]>= telecom_test_df[\"average_amnt_6_7\"].quantile(.70)]\n",
    "telecom_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40627e53",
   "metadata": {},
   "source": [
    "## Lets focus on Outliers now and treat them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d0b9f1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic method to remove outliers\n",
    "def remove_outliers(df, features):\n",
    "    for feature in features:\n",
    "        q1 = df[feature].quantile(0.25)\n",
    "        q3 = df[feature].quantile(0.99)\n",
    "        iqr = q3-q1\n",
    "        lower_value  = q1 - (1.5 * iqr)\n",
    "        higer_value = q3 + (1.5 * iqr)\n",
    "        df = df[(df[feature] <= higer_value) & (df[feature] >= lower_value)]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "537a1234",
   "metadata": {},
   "outputs": [],
   "source": [
    "#telecom_train_df = remove_outliers(telecom_train_df, telecom_train_df.columns)\n",
    "#telecom_test_df = remove_outliers(telecom_test_df, telecom_test_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "09c79cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21013, 141)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7911de6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9003, 140)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telecom_test_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad731d80",
   "metadata": {},
   "source": [
    "## Let's check for Data imbalance here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "d7df398d",
   "metadata": {},
   "outputs": [],
   "source": [
    "churn_data_rows = telecom_train_df['churn_probability'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "addc0c33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8.275829248560415"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "churn_data_rows/len(telecom_train_df) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa850d6",
   "metadata": {},
   "source": [
    "### We can see that there is a data imbalance. We have only about 8.28% of data as Churn and 91.72% as not churn.\n",
    "### So we need to apply data imbalance technique. We will use SMOTE."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0624b7f7",
   "metadata": {},
   "source": [
    "## Dividing the data from telecom_train_df to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c3467e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = telecom_train_df['churn_probability']\n",
    "X = telecom_train_df.drop(['churn_probability'], axis=1)\n",
    "\n",
    "telecom_train_df.drop('churn_probability', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b3edc2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into test and train\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ad1282",
   "metadata": {},
   "source": [
    "## Taking a backup of variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "20dae04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_ori, X_test_ori, y_train_ori, y_test_ori = X_train.copy(), X_test.copy(), y_train.copy(), y_test.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5496cd44",
   "metadata": {},
   "source": [
    "## Rescaling of the variables\n",
    "\n",
    "- We will use Min-Max scaling (Normalization) --> compresses all the data between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7ad21932",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>total_data_recharge_amnt_6</th>\n",
       "      <th>total_data_recharge_amnt_7</th>\n",
       "      <th>total_data_recharge_amnt_8</th>\n",
       "      <th>total_recharge_amnt_6</th>\n",
       "      <th>total_recharge_amnt_7</th>\n",
       "      <th>total_recharge_amnt_8</th>\n",
       "      <th>average_amnt_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6968</th>\n",
       "      <td>0.127277</td>\n",
       "      <td>0.274576</td>\n",
       "      <td>0.081830</td>\n",
       "      <td>0.004624</td>\n",
       "      <td>0.004018</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>0.011537</td>\n",
       "      <td>0.040985</td>\n",
       "      <td>0.006554</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002051</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.096264</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.069171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42203</th>\n",
       "      <td>0.156166</td>\n",
       "      <td>0.094305</td>\n",
       "      <td>0.083632</td>\n",
       "      <td>0.066057</td>\n",
       "      <td>0.041462</td>\n",
       "      <td>0.074009</td>\n",
       "      <td>0.065428</td>\n",
       "      <td>0.053213</td>\n",
       "      <td>0.049054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003787</td>\n",
       "      <td>0.009557</td>\n",
       "      <td>0.009933</td>\n",
       "      <td>0.016496</td>\n",
       "      <td>0.002008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18406</th>\n",
       "      <td>0.151447</td>\n",
       "      <td>0.122733</td>\n",
       "      <td>0.087708</td>\n",
       "      <td>0.015153</td>\n",
       "      <td>0.016084</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.056327</td>\n",
       "      <td>0.259820</td>\n",
       "      <td>0.136117</td>\n",
       "      <td>0.005055</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.008632</td>\n",
       "      <td>0.019367</td>\n",
       "      <td>0.017273</td>\n",
       "      <td>0.009450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21455</th>\n",
       "      <td>0.171177</td>\n",
       "      <td>0.128305</td>\n",
       "      <td>0.077781</td>\n",
       "      <td>0.009636</td>\n",
       "      <td>0.010909</td>\n",
       "      <td>0.006579</td>\n",
       "      <td>0.081607</td>\n",
       "      <td>0.121132</td>\n",
       "      <td>0.038009</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>...</td>\n",
       "      <td>0.029661</td>\n",
       "      <td>0.043865</td>\n",
       "      <td>0.039021</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011038</td>\n",
       "      <td>0.011124</td>\n",
       "      <td>0.015034</td>\n",
       "      <td>0.032992</td>\n",
       "      <td>0.023503</td>\n",
       "      <td>0.026840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66143</th>\n",
       "      <td>0.138174</td>\n",
       "      <td>0.087866</td>\n",
       "      <td>0.074838</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006171</td>\n",
       "      <td>0.001633</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033354</td>\n",
       "      <td>0.020053</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.098218</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043938</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.016759</td>\n",
       "      <td>0.045971</td>\n",
       "      <td>0.006063</td>\n",
       "      <td>0.026593</td>\n",
       "      <td>0.029892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         arpu_6    arpu_7    arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  \\\n",
       "6968   0.127277  0.274576  0.081830     0.004624     0.004018     0.002985   \n",
       "42203  0.156166  0.094305  0.083632     0.066057     0.041462     0.074009   \n",
       "18406  0.151447  0.122733  0.087708     0.015153     0.016084     0.008306   \n",
       "21455  0.171177  0.128305  0.077781     0.009636     0.010909     0.006579   \n",
       "66143  0.138174  0.087866  0.074838     0.000000     0.006171     0.001633   \n",
       "\n",
       "       offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  ...  \\\n",
       "6968       0.011537      0.040985      0.006554       0.000000  ...   \n",
       "42203      0.065428      0.053213      0.049054       0.000000  ...   \n",
       "18406      0.056327      0.259820      0.136117       0.005055  ...   \n",
       "21455      0.081607      0.121132      0.038009       0.005166  ...   \n",
       "66143      0.000000      0.033354      0.020053       0.000000  ...   \n",
       "\n",
       "       aug_vbc_3g  jul_vbc_3g  jun_vbc_3g  total_data_recharge_amnt_6  \\\n",
       "6968     0.000000    0.002051    0.000000                    0.000000   \n",
       "42203    0.000000    0.000000    0.000000                    0.000000   \n",
       "18406    0.000000    0.000000    0.000000                    0.000000   \n",
       "21455    0.029661    0.043865    0.039021                    0.000000   \n",
       "66143    0.098218    0.000000    0.000000                    0.043938   \n",
       "\n",
       "       total_data_recharge_amnt_7  total_data_recharge_amnt_8  \\\n",
       "6968                     0.000000                    0.000000   \n",
       "42203                    0.000000                    0.003787   \n",
       "18406                    0.000000                    0.000000   \n",
       "21455                    0.011038                    0.011124   \n",
       "66143                    0.000000                    0.016759   \n",
       "\n",
       "       total_recharge_amnt_6  total_recharge_amnt_7  total_recharge_amnt_8  \\\n",
       "6968                0.000000               0.096264               0.000000   \n",
       "42203               0.009557               0.009933               0.016496   \n",
       "18406               0.008632               0.019367               0.017273   \n",
       "21455               0.015034               0.032992               0.023503   \n",
       "66143               0.045971               0.006063               0.026593   \n",
       "\n",
       "       average_amnt_6_7  \n",
       "6968           0.069171  \n",
       "42203          0.002008  \n",
       "18406          0.009450  \n",
       "21455          0.026840  \n",
       "66143          0.029892  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating MinMaxScaler object\n",
    "scaler = MinMaxScaler()\n",
    "# fit on data\n",
    "# removed churn_probability becuase test data is not having it.\n",
    "# Also churn_probability is having 0 and 1 only. So it need not be scaled.\n",
    "train_numerical_columns = telecom_train_df.columns.to_list()\n",
    "X_train[train_numerical_columns] = scaler.fit_transform(X_train[train_numerical_columns])\n",
    "X_train.head()\n",
    "# So all numberic values are now between 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "e87381ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE ## Comments to be fixed "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "37e1ef44",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled, y_resampled = SMOTE().fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "90982153",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27020, 140)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5a229479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(y_resampled)/len(y_resampled) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0f8f8db",
   "metadata": {},
   "source": [
    "## Now there is no data imbalance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "b84d8439",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>onnet_mou_8</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_ic_mou_6</th>\n",
       "      <th>...</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "      <th>jun_vbc_3g</th>\n",
       "      <th>total_data_recharge_amnt_6</th>\n",
       "      <th>total_data_recharge_amnt_7</th>\n",
       "      <th>total_data_recharge_amnt_8</th>\n",
       "      <th>total_recharge_amnt_6</th>\n",
       "      <th>total_recharge_amnt_7</th>\n",
       "      <th>total_recharge_amnt_8</th>\n",
       "      <th>average_amnt_6_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.150615</td>\n",
       "      <td>0.099685</td>\n",
       "      <td>0.064554</td>\n",
       "      <td>0.010236</td>\n",
       "      <td>0.005052</td>\n",
       "      <td>0.001845</td>\n",
       "      <td>0.056723</td>\n",
       "      <td>0.092260</td>\n",
       "      <td>0.028195</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>0.008917</td>\n",
       "      <td>0.008442</td>\n",
       "      <td>0.000701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.145864</td>\n",
       "      <td>0.095230</td>\n",
       "      <td>0.083592</td>\n",
       "      <td>0.001022</td>\n",
       "      <td>0.000963</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>0.006797</td>\n",
       "      <td>0.003215</td>\n",
       "      <td>0.008728</td>\n",
       "      <td>...</td>\n",
       "      <td>0.040694</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>0.0319</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>0.017833</td>\n",
       "      <td>0.016884</td>\n",
       "      <td>0.008485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.152781</td>\n",
       "      <td>0.091615</td>\n",
       "      <td>0.065131</td>\n",
       "      <td>0.151258</td>\n",
       "      <td>0.103391</td>\n",
       "      <td>0.064113</td>\n",
       "      <td>0.001799</td>\n",
       "      <td>0.004487</td>\n",
       "      <td>0.001984</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.011352</td>\n",
       "      <td>0.008845</td>\n",
       "      <td>0.007362</td>\n",
       "      <td>0.002600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.190866</td>\n",
       "      <td>0.119009</td>\n",
       "      <td>0.094514</td>\n",
       "      <td>0.053212</td>\n",
       "      <td>0.032421</td>\n",
       "      <td>0.040272</td>\n",
       "      <td>0.024393</td>\n",
       "      <td>0.048810</td>\n",
       "      <td>0.029353</td>\n",
       "      <td>0.012276</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.001816</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.022596</td>\n",
       "      <td>0.019973</td>\n",
       "      <td>0.019417</td>\n",
       "      <td>0.021967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.135918</td>\n",
       "      <td>0.117934</td>\n",
       "      <td>0.085279</td>\n",
       "      <td>0.017062</td>\n",
       "      <td>0.231259</td>\n",
       "      <td>0.138588</td>\n",
       "      <td>0.002456</td>\n",
       "      <td>0.017742</td>\n",
       "      <td>0.004589</td>\n",
       "      <td>0.007378</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014353</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.018315</td>\n",
       "      <td>0.004715</td>\n",
       "      <td>0.014516</td>\n",
       "      <td>0.032468</td>\n",
       "      <td>0.001853</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      arpu_6    arpu_7    arpu_8  onnet_mou_6  onnet_mou_7  onnet_mou_8  \\\n",
       "1   0.150615  0.099685  0.064554     0.010236     0.005052     0.001845   \n",
       "2   0.145864  0.095230  0.083592     0.001022     0.000963     0.000781   \n",
       "21  0.152781  0.091615  0.065131     0.151258     0.103391     0.064113   \n",
       "23  0.190866  0.119009  0.094514     0.053212     0.032421     0.040272   \n",
       "26  0.135918  0.117934  0.085279     0.017062     0.231259     0.138588   \n",
       "\n",
       "    offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_ic_mou_6  ...  aug_vbc_3g  \\\n",
       "1       0.056723      0.092260      0.028195       0.000000  ...    0.000000   \n",
       "2       0.002031      0.006797      0.003215       0.008728  ...    0.040694   \n",
       "21      0.001799      0.004487      0.001984       0.000000  ...    0.000000   \n",
       "23      0.024393      0.048810      0.029353       0.012276  ...    0.000000   \n",
       "26      0.002456      0.017742      0.004589       0.007378  ...    0.014353   \n",
       "\n",
       "    jul_vbc_3g  jun_vbc_3g  total_data_recharge_amnt_6  \\\n",
       "1     0.000000      0.0000                         0.0   \n",
       "2     0.082745      0.0319                         0.0   \n",
       "21    0.000000      0.0000                         0.0   \n",
       "23    0.000000      0.0000                         0.0   \n",
       "26    0.000000      0.0000                         0.0   \n",
       "\n",
       "    total_data_recharge_amnt_7  total_data_recharge_amnt_8  \\\n",
       "1                     0.000000                    0.000000   \n",
       "2                     0.000000                    0.000000   \n",
       "21                    0.000000                    0.000000   \n",
       "23                    0.001816                    0.000000   \n",
       "26                    0.000000                    0.018315   \n",
       "\n",
       "    total_recharge_amnt_6  total_recharge_amnt_7  total_recharge_amnt_8  \\\n",
       "1                0.009067               0.008917               0.008442   \n",
       "2                0.009067               0.017833               0.016884   \n",
       "21               0.011352               0.008845               0.007362   \n",
       "23               0.022596               0.019973               0.019417   \n",
       "26               0.004715               0.014516               0.032468   \n",
       "\n",
       "    average_amnt_6_7  \n",
       "1           0.000701  \n",
       "2           0.008485  \n",
       "21          0.002600  \n",
       "23          0.021967  \n",
       "26          0.001853  \n",
       "\n",
       "[5 rows x 140 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lets fit the scaler for train data as well\n",
    "test_numerical_columns = telecom_test_df.columns.to_list()\n",
    "telecom_test_df[test_numerical_columns] = scaler.transform(telecom_test_df[test_numerical_columns])\n",
    "telecom_test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c9c47b1",
   "metadata": {},
   "source": [
    "## Modelling \n",
    "\n",
    "1. Logistic Regression using RFE - To get important predictors for Churn probability\n",
    "2. Logistic Regression - To know Churn probability + PCA\n",
    "    - Lasso\n",
    "    - Ridge\n",
    "3. Tree models\n",
    "    - XGBoost\n",
    "    - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6bca16f",
   "metadata": {},
   "source": [
    "## 1. Logistic Regression using RFE - To get importnat predictors for Churn probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cd4d9e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>churn_probability</td> <th>  No. Observations:  </th>  <td> 27020</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>        <th>  Df Residuals:      </th>  <td> 26886</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>      <th>  Df Model:          </th>  <td>   133</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>        <th>  Log-Likelihood:    </th> <td> -8686.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 15 Sep 2022</td>  <th>  Deviance:          </th> <td>  17373.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:44:20</td>      <th>  Pearson chi2:      </th> <td>1.06e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>100</td>        <th>  Pseudo R-squ. (CS):</th>  <td>0.5245</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>                      <td>   -4.2338</td> <td>    0.693</td> <td>   -6.108</td> <td> 0.000</td> <td>   -5.592</td> <td>   -2.875</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_6</th>                     <td>   11.6444</td> <td>    3.768</td> <td>    3.091</td> <td> 0.002</td> <td>    4.260</td> <td>   19.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_7</th>                     <td>   20.5065</td> <td>    4.395</td> <td>    4.665</td> <td> 0.000</td> <td>   11.892</td> <td>   29.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_8</th>                     <td>   40.0888</td> <td>    4.975</td> <td>    8.058</td> <td> 0.000</td> <td>   30.338</td> <td>   49.839</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_6</th>                <td>  -73.7731</td> <td>   34.902</td> <td>   -2.114</td> <td> 0.035</td> <td> -142.180</td> <td>   -5.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_7</th>                <td>  -57.4026</td> <td>   31.415</td> <td>   -1.827</td> <td> 0.068</td> <td> -118.974</td> <td>    4.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_8</th>                <td>  -26.5994</td> <td>   46.450</td> <td>   -0.573</td> <td> 0.567</td> <td> -117.640</td> <td>   64.442</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_6</th>               <td>  -77.7592</td> <td>   39.248</td> <td>   -1.981</td> <td> 0.048</td> <td> -154.683</td> <td>   -0.835</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_7</th>               <td>  -49.6550</td> <td>   25.095</td> <td>   -1.979</td> <td> 0.048</td> <td>  -98.841</td> <td>   -0.469</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_8</th>               <td>  -79.1261</td> <td>   59.041</td> <td>   -1.340</td> <td> 0.180</td> <td> -194.845</td> <td>   36.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_ic_mou_6</th>              <td>    0.6935</td> <td>    1.094</td> <td>    0.634</td> <td> 0.526</td> <td>   -1.451</td> <td>    2.838</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_ic_mou_7</th>              <td>    0.5985</td> <td>    1.311</td> <td>    0.456</td> <td> 0.648</td> <td>   -1.972</td> <td>    3.169</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_ic_mou_8</th>              <td>   -1.0197</td> <td>    1.459</td> <td>   -0.699</td> <td> 0.485</td> <td>   -3.879</td> <td>    1.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_6</th>              <td>   37.7991</td> <td>   17.860</td> <td>    2.116</td> <td> 0.034</td> <td>    2.794</td> <td>   72.804</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_7</th>              <td>   24.3298</td> <td>   10.594</td> <td>    2.297</td> <td> 0.022</td> <td>    3.567</td> <td>   45.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>              <td>   28.1282</td> <td>   22.788</td> <td>    1.234</td> <td> 0.217</td> <td>  -16.536</td> <td>   72.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_6</th>           <td>-5.135e+04</td> <td> 2.53e+04</td> <td>   -2.026</td> <td> 0.043</td> <td>-1.01e+05</td> <td>-1670.773</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_7</th>           <td>  392.5905</td> <td> 2.86e+04</td> <td>    0.014</td> <td> 0.989</td> <td>-5.57e+04</td> <td> 5.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_8</th>           <td> 2.358e+05</td> <td> 4.39e+04</td> <td>    5.365</td> <td> 0.000</td> <td>  1.5e+05</td> <td> 3.22e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_6</th>           <td>-3.751e+04</td> <td> 1.85e+04</td> <td>   -2.026</td> <td> 0.043</td> <td>-7.38e+04</td> <td>-1226.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>           <td>  238.7926</td> <td> 1.76e+04</td> <td>    0.014</td> <td> 0.989</td> <td>-3.43e+04</td> <td> 3.48e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_8</th>           <td> 1.088e+05</td> <td> 2.03e+04</td> <td>    5.366</td> <td> 0.000</td> <td> 6.91e+04</td> <td> 1.49e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_6</th>           <td>-4937.6461</td> <td> 2434.181</td> <td>   -2.028</td> <td> 0.043</td> <td>-9708.554</td> <td> -166.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_7</th>           <td>   42.4806</td> <td> 3150.797</td> <td>    0.013</td> <td> 0.989</td> <td>-6132.967</td> <td> 6217.928</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>           <td> 1.291e+04</td> <td> 2404.635</td> <td>    5.368</td> <td> 0.000</td> <td> 8195.221</td> <td> 1.76e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2c_mou_6</th>           <td>   -8.5646</td> <td>    1.556</td> <td>   -5.506</td> <td> 0.000</td> <td>  -11.614</td> <td>   -5.516</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2c_mou_7</th>           <td>   -5.1228</td> <td>    2.621</td> <td>   -1.955</td> <td> 0.051</td> <td>  -10.259</td> <td>    0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2c_mou_8</th>           <td>    7.8041</td> <td>    1.606</td> <td>    4.859</td> <td> 0.000</td> <td>    4.656</td> <td>   10.952</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_6</th>               <td> 5.286e+04</td> <td> 4.76e+04</td> <td>    1.110</td> <td> 0.267</td> <td>-4.05e+04</td> <td> 1.46e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_7</th>               <td> 5351.5146</td> <td>  3.5e+04</td> <td>    0.153</td> <td> 0.879</td> <td>-6.33e+04</td> <td>  7.4e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_8</th>               <td>    -3e+05</td> <td> 5.38e+04</td> <td>   -5.575</td> <td> 0.000</td> <td>-4.05e+05</td> <td>-1.95e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_6</th>           <td>-8.181e+04</td> <td>  3.5e+04</td> <td>   -2.338</td> <td> 0.019</td> <td> -1.5e+05</td> <td>-1.32e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_7</th>           <td>-6.991e+04</td> <td> 4.03e+04</td> <td>   -1.736</td> <td> 0.083</td> <td>-1.49e+05</td> <td> 9037.905</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2t_mou_8</th>           <td> 1.695e+05</td> <td> 4.21e+04</td> <td>    4.021</td> <td> 0.000</td> <td> 8.69e+04</td> <td> 2.52e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_6</th>           <td>-9.234e+04</td> <td> 3.95e+04</td> <td>   -2.338</td> <td> 0.019</td> <td> -1.7e+05</td> <td>-1.49e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_7</th>           <td>-5.692e+04</td> <td> 3.28e+04</td> <td>   -1.735</td> <td> 0.083</td> <td>-1.21e+05</td> <td> 7362.668</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>           <td>  2.95e+05</td> <td> 7.34e+04</td> <td>    4.022</td> <td> 0.000</td> <td> 1.51e+05</td> <td> 4.39e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2f_mou_6</th>           <td>-3754.7775</td> <td> 1605.461</td> <td>   -2.339</td> <td> 0.019</td> <td>-6901.423</td> <td> -608.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2f_mou_7</th>           <td>-4005.0415</td> <td> 2306.940</td> <td>   -1.736</td> <td> 0.083</td> <td>-8526.561</td> <td>  516.478</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2f_mou_8</th>           <td> 7480.5010</td> <td> 1862.555</td> <td>    4.016</td> <td> 0.000</td> <td> 3829.961</td> <td> 1.11e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_6</th>               <td>  6.82e+04</td> <td> 4.32e+04</td> <td>    1.579</td> <td> 0.114</td> <td>-1.64e+04</td> <td> 1.53e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>               <td> 7.621e+04</td> <td> 4.47e+04</td> <td>    1.703</td> <td> 0.089</td> <td>-1.15e+04</td> <td> 1.64e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_8</th>               <td>-3.689e+05</td> <td> 8.15e+04</td> <td>   -4.526</td> <td> 0.000</td> <td>-5.29e+05</td> <td>-2.09e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_og_mou_6</th>               <td>-1.782e+04</td> <td> 1.69e+04</td> <td>   -1.052</td> <td> 0.293</td> <td> -5.1e+04</td> <td> 1.54e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_og_mou_7</th>               <td> 4075.0435</td> <td> 1.77e+04</td> <td>    0.230</td> <td> 0.818</td> <td>-3.06e+04</td> <td> 3.87e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_og_mou_8</th>               <td>-2.978e+04</td> <td> 1.88e+04</td> <td>   -1.587</td> <td> 0.113</td> <td>-6.66e+04</td> <td> 6998.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_og_mou_6</th>               <td>-3087.2672</td> <td> 2938.677</td> <td>   -1.051</td> <td> 0.293</td> <td>-8846.969</td> <td> 2672.434</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_og_mou_7</th>               <td>  943.7676</td> <td> 4078.354</td> <td>    0.231</td> <td> 0.817</td> <td>-7049.659</td> <td> 8937.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_og_mou_8</th>               <td>-4112.3494</td> <td> 2588.663</td> <td>   -1.589</td> <td> 0.112</td> <td>-9186.035</td> <td>  961.336</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>og_others_6</th>                <td>-1880.3495</td> <td> 1753.134</td> <td>   -1.073</td> <td> 0.283</td> <td>-5316.429</td> <td> 1555.730</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>og_others_7</th>                <td>    4.0971</td> <td>  217.593</td> <td>    0.019</td> <td> 0.985</td> <td> -422.377</td> <td>  430.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>og_others_8</th>                <td>-2325.7119</td> <td> 1317.707</td> <td>   -1.765</td> <td> 0.078</td> <td>-4908.370</td> <td>  256.946</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_6</th>             <td> 3.232e+04</td> <td> 3.07e+04</td> <td>    1.054</td> <td> 0.292</td> <td>-2.78e+04</td> <td> 9.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_7</th>             <td>-6150.0258</td> <td> 2.67e+04</td> <td>   -0.230</td> <td> 0.818</td> <td>-5.85e+04</td> <td> 4.62e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_8</th>             <td> 7.363e+04</td> <td> 4.64e+04</td> <td>    1.588</td> <td> 0.112</td> <td>-1.73e+04</td> <td> 1.65e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_6</th>           <td>-1.123e+05</td> <td> 1.62e+04</td> <td>   -6.921</td> <td> 0.000</td> <td>-1.44e+05</td> <td>-8.05e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_7</th>           <td> 7.318e+04</td> <td> 2.11e+04</td> <td>    3.461</td> <td> 0.001</td> <td> 3.17e+04</td> <td> 1.15e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_8</th>           <td> 1.266e+05</td> <td> 1.52e+04</td> <td>    8.335</td> <td> 0.000</td> <td> 9.68e+04</td> <td> 1.56e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_6</th>           <td>-1.146e+05</td> <td> 1.66e+04</td> <td>   -6.921</td> <td> 0.000</td> <td>-1.47e+05</td> <td>-8.21e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_7</th>           <td> 5.161e+04</td> <td> 1.49e+04</td> <td>    3.461</td> <td> 0.001</td> <td> 2.24e+04</td> <td> 8.08e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_8</th>           <td>  1.48e+05</td> <td> 1.78e+04</td> <td>    8.335</td> <td> 0.000</td> <td> 1.13e+05</td> <td> 1.83e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_6</th>           <td>-3.535e+04</td> <td> 5107.278</td> <td>   -6.922</td> <td> 0.000</td> <td>-4.54e+04</td> <td>-2.53e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_7</th>           <td> 2.542e+04</td> <td> 7343.274</td> <td>    3.462</td> <td> 0.001</td> <td>  1.1e+04</td> <td> 3.98e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>           <td> 4.652e+04</td> <td> 5581.875</td> <td>    8.334</td> <td> 0.000</td> <td> 3.56e+04</td> <td> 5.75e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_6</th>               <td> 1.541e+05</td> <td> 2.78e+04</td> <td>    5.534</td> <td> 0.000</td> <td> 9.95e+04</td> <td> 2.09e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_7</th>               <td>-7.784e+04</td> <td> 2.48e+04</td> <td>   -3.139</td> <td> 0.002</td> <td>-1.26e+05</td> <td>-2.92e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>               <td>-9.287e+04</td> <td> 2.06e+04</td> <td>   -4.500</td> <td> 0.000</td> <td>-1.33e+05</td> <td>-5.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_6</th>           <td>-4.023e+04</td> <td> 1.43e+04</td> <td>   -2.808</td> <td> 0.005</td> <td>-6.83e+04</td> <td>-1.21e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_7</th>           <td>-4.871e+04</td> <td> 2.05e+04</td> <td>   -2.380</td> <td> 0.017</td> <td>-8.88e+04</td> <td>-8594.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_8</th>           <td>   3.7e+04</td> <td> 1.81e+04</td> <td>    2.048</td> <td> 0.041</td> <td> 1590.096</td> <td> 7.24e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_6</th>           <td>-4.785e+04</td> <td>  1.7e+04</td> <td>   -2.808</td> <td> 0.005</td> <td>-8.12e+04</td> <td>-1.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_7</th>           <td>-3.025e+04</td> <td> 1.27e+04</td> <td>   -2.381</td> <td> 0.017</td> <td>-5.52e+04</td> <td>-5344.593</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2m_mou_8</th>           <td> 3.114e+04</td> <td> 1.52e+04</td> <td>    2.049</td> <td> 0.040</td> <td> 1357.639</td> <td> 6.09e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2f_mou_6</th>           <td> -1.79e+04</td> <td> 6370.773</td> <td>   -2.809</td> <td> 0.005</td> <td>-3.04e+04</td> <td>-5409.503</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2f_mou_7</th>           <td>-1.306e+04</td> <td> 5490.899</td> <td>   -2.379</td> <td> 0.017</td> <td>-2.38e+04</td> <td>-2298.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2f_mou_8</th>           <td> 1.506e+04</td> <td> 7361.935</td> <td>    2.046</td> <td> 0.041</td> <td>  633.606</td> <td> 2.95e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_6</th>               <td> 2.952e+04</td> <td> 1.78e+04</td> <td>    1.661</td> <td> 0.097</td> <td>-5323.597</td> <td> 6.44e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_7</th>               <td>  5.31e+04</td> <td> 2.21e+04</td> <td>    2.402</td> <td> 0.016</td> <td> 9768.423</td> <td> 9.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_8</th>               <td> 1.343e+04</td> <td> 2.09e+04</td> <td>    0.642</td> <td> 0.521</td> <td>-2.76e+04</td> <td> 5.45e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_6</th>             <td> 3.916e+04</td> <td> 1.79e+04</td> <td>    2.192</td> <td> 0.028</td> <td> 4143.808</td> <td> 7.42e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_7</th>             <td>-5780.9670</td> <td> 1.86e+04</td> <td>   -0.311</td> <td> 0.756</td> <td>-4.22e+04</td> <td> 3.06e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_8</th>             <td>-8.719e+04</td> <td> 1.54e+04</td> <td>   -5.645</td> <td> 0.000</td> <td>-1.17e+05</td> <td>-5.69e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_6</th>               <td>  -91.1859</td> <td>   46.254</td> <td>   -1.971</td> <td> 0.049</td> <td> -181.841</td> <td>   -0.531</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_7</th>               <td>    3.3714</td> <td>   33.847</td> <td>    0.100</td> <td> 0.921</td> <td>  -62.967</td> <td>   69.710</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_8</th>               <td>   10.6622</td> <td>    3.303</td> <td>    3.228</td> <td> 0.001</td> <td>    4.188</td> <td>   17.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_ic_mou_6</th>               <td>-3.446e+04</td> <td> 1.57e+04</td> <td>   -2.192</td> <td> 0.028</td> <td>-6.53e+04</td> <td>-3650.070</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_ic_mou_7</th>               <td> 3501.5929</td> <td> 1.13e+04</td> <td>    0.311</td> <td> 0.756</td> <td>-1.86e+04</td> <td> 2.56e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_ic_mou_8</th>               <td> 3.445e+04</td> <td> 6102.197</td> <td>    5.645</td> <td> 0.000</td> <td> 2.25e+04</td> <td> 4.64e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ic_others_6</th>                <td>-6851.2490</td> <td> 3113.024</td> <td>   -2.201</td> <td> 0.028</td> <td> -1.3e+04</td> <td> -749.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ic_others_7</th>                <td> 1170.1870</td> <td> 3733.873</td> <td>    0.313</td> <td> 0.754</td> <td>-6148.069</td> <td> 8488.443</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>ic_others_8</th>                <td> 1.739e+04</td> <td> 3080.608</td> <td>    5.646</td> <td> 0.000</td> <td> 1.14e+04</td> <td> 2.34e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_6</th>           <td>   -0.5609</td> <td>    0.737</td> <td>   -0.761</td> <td> 0.447</td> <td>   -2.006</td> <td>    0.884</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_7</th>           <td>    3.5693</td> <td>    0.733</td> <td>    4.867</td> <td> 0.000</td> <td>    2.132</td> <td>    5.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_8</th>           <td>   -6.9772</td> <td>    0.817</td> <td>   -8.535</td> <td> 0.000</td> <td>   -8.579</td> <td>   -5.375</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_6</th>           <td>   -3.3576</td> <td>    3.199</td> <td>   -1.050</td> <td> 0.294</td> <td>   -9.628</td> <td>    2.913</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_7</th>           <td>  -11.5359</td> <td>    3.632</td> <td>   -3.176</td> <td> 0.001</td> <td>  -18.654</td> <td>   -4.418</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_8</th>           <td>  -37.1082</td> <td>    4.287</td> <td>   -8.655</td> <td> 0.000</td> <td>  -45.511</td> <td>  -28.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_6</th>             <td>   -3.4159</td> <td>    1.013</td> <td>   -3.373</td> <td> 0.001</td> <td>   -5.401</td> <td>   -1.431</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_7</th>             <td>   -0.7882</td> <td>    0.812</td> <td>   -0.971</td> <td> 0.331</td> <td>   -2.379</td> <td>    0.802</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_8</th>             <td>   11.7225</td> <td>    1.295</td> <td>    9.049</td> <td> 0.000</td> <td>    9.183</td> <td>   14.262</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_6</th>         <td>   -0.2336</td> <td>    0.921</td> <td>   -0.254</td> <td> 0.800</td> <td>   -2.040</td> <td>    1.572</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_7</th>         <td>    1.4886</td> <td>    0.699</td> <td>    2.130</td> <td> 0.033</td> <td>    0.119</td> <td>    2.858</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th>         <td>  -16.3063</td> <td>    1.229</td> <td>  -13.264</td> <td> 0.000</td> <td>  -18.716</td> <td>  -13.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_6</th>          <td>    2.5459</td> <td>    0.533</td> <td>    4.780</td> <td> 0.000</td> <td>    1.502</td> <td>    3.590</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_7</th>          <td>    1.1544</td> <td>    0.708</td> <td>    1.632</td> <td> 0.103</td> <td>   -0.232</td> <td>    2.541</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_8</th>          <td>   -6.7520</td> <td>    1.087</td> <td>   -6.213</td> <td> 0.000</td> <td>   -8.882</td> <td>   -4.622</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_6</th>            <td>    5.0115</td> <td>    0.891</td> <td>    5.623</td> <td> 0.000</td> <td>    3.265</td> <td>    6.758</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_7</th>            <td>   -2.5493</td> <td>    0.925</td> <td>   -2.755</td> <td> 0.006</td> <td>   -4.363</td> <td>   -0.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_8</th>            <td>   -6.1139</td> <td>    1.102</td> <td>   -5.547</td> <td> 0.000</td> <td>   -8.274</td> <td>   -3.954</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_6</th>         <td>  -15.3300</td> <td>    2.951</td> <td>   -5.195</td> <td> 0.000</td> <td>  -21.113</td> <td>   -9.547</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_7</th>         <td>    7.3692</td> <td>    2.047</td> <td>    3.601</td> <td> 0.000</td> <td>    3.358</td> <td>   11.380</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_8</th>         <td>   -2.7686</td> <td>    2.681</td> <td>   -1.033</td> <td> 0.302</td> <td>   -8.024</td> <td>    2.487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_6</th>                <td>   -1.2410</td> <td>    0.806</td> <td>   -1.539</td> <td> 0.124</td> <td>   -2.821</td> <td>    0.339</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_7</th>                <td>    3.1413</td> <td>    0.934</td> <td>    3.363</td> <td> 0.001</td> <td>    1.311</td> <td>    4.972</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_8</th>                <td>   -5.9188</td> <td>    1.199</td> <td>   -4.936</td> <td> 0.000</td> <td>   -8.269</td> <td>   -3.569</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_6</th>                <td>   -7.8463</td> <td>    3.035</td> <td>   -2.585</td> <td> 0.010</td> <td>  -13.795</td> <td>   -1.897</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_7</th>                <td>    5.9075</td> <td>    1.954</td> <td>    3.023</td> <td> 0.003</td> <td>    2.077</td> <td>    9.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_8</th>                <td>   -6.7596</td> <td>    2.397</td> <td>   -2.820</td> <td> 0.005</td> <td>  -11.458</td> <td>   -2.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_6</th>               <td>   -0.1225</td> <td>    0.323</td> <td>   -0.380</td> <td> 0.704</td> <td>   -0.755</td> <td>    0.510</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_7</th>               <td>   -0.9761</td> <td>    0.427</td> <td>   -2.286</td> <td> 0.022</td> <td>   -1.813</td> <td>   -0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_8</th>               <td>   -3.2613</td> <td>    0.609</td> <td>   -5.356</td> <td> 0.000</td> <td>   -4.455</td> <td>   -2.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_6</th>                <td>    0.7377</td> <td>    0.517</td> <td>    1.428</td> <td> 0.153</td> <td>   -0.275</td> <td>    1.750</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_7</th>                <td>    0.1079</td> <td>    0.563</td> <td>    0.192</td> <td> 0.848</td> <td>   -0.995</td> <td>    1.211</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_8</th>                <td>   -3.2683</td> <td>    0.675</td> <td>   -4.840</td> <td> 0.000</td> <td>   -4.592</td> <td>   -1.945</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_6</th>               <td>    2.5866</td> <td>    0.788</td> <td>    3.284</td> <td> 0.001</td> <td>    1.043</td> <td>    4.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_7</th>               <td>   -3.2562</td> <td>    1.245</td> <td>   -2.616</td> <td> 0.009</td> <td>   -5.696</td> <td>   -0.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_8</th>               <td>   -3.7848</td> <td>    1.815</td> <td>   -2.085</td> <td> 0.037</td> <td>   -7.342</td> <td>   -0.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_6</th>                <td>    3.5011</td> <td>    0.928</td> <td>    3.771</td> <td> 0.000</td> <td>    1.681</td> <td>    5.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_7</th>                <td>    3.2613</td> <td>    1.087</td> <td>    3.001</td> <td> 0.003</td> <td>    1.132</td> <td>    5.391</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_8</th>                <td>   -5.2961</td> <td>    1.578</td> <td>   -3.357</td> <td> 0.001</td> <td>   -8.388</td> <td>   -2.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aon</th>                        <td>   -0.5000</td> <td>    0.106</td> <td>   -4.701</td> <td> 0.000</td> <td>   -0.708</td> <td>   -0.292</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>                 <td>   -6.9148</td> <td>    1.794</td> <td>   -3.855</td> <td> 0.000</td> <td>  -10.430</td> <td>   -3.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jul_vbc_3g</th>                 <td>   -1.6401</td> <td>    1.035</td> <td>   -1.584</td> <td> 0.113</td> <td>   -3.670</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jun_vbc_3g</th>                 <td>    3.3461</td> <td>    0.771</td> <td>    4.341</td> <td> 0.000</td> <td>    1.835</td> <td>    4.857</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_data_recharge_amnt_6</th> <td>    1.1078</td> <td>    1.639</td> <td>    0.676</td> <td> 0.499</td> <td>   -2.106</td> <td>    4.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_data_recharge_amnt_7</th> <td>   -1.3313</td> <td>    1.748</td> <td>   -0.762</td> <td> 0.446</td> <td>   -4.757</td> <td>    2.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_data_recharge_amnt_8</th> <td>   13.6325</td> <td>    1.873</td> <td>    7.278</td> <td> 0.000</td> <td>    9.961</td> <td>   17.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_recharge_amnt_6</th>      <td>   -0.0329</td> <td>    1.364</td> <td>   -0.024</td> <td> 0.981</td> <td>   -2.707</td> <td>    2.641</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_recharge_amnt_7</th>      <td>   -5.2584</td> <td>    1.418</td> <td>   -3.710</td> <td> 0.000</td> <td>   -8.037</td> <td>   -2.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_recharge_amnt_8</th>      <td>   -0.2042</td> <td>    1.645</td> <td>   -0.124</td> <td> 0.901</td> <td>   -3.427</td> <td>    3.019</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>average_amnt_6_7</th>           <td>   -4.5559</td> <td>    1.047</td> <td>   -4.349</td> <td> 0.000</td> <td>   -6.609</td> <td>   -2.503</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:      churn_probability   No. Observations:                27020\n",
       "Model:                            GLM   Df Residuals:                    26886\n",
       "Model Family:                Binomial   Df Model:                          133\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -8686.6\n",
       "Date:                Thu, 15 Sep 2022   Deviance:                       17373.\n",
       "Time:                        09:44:20   Pearson chi2:                 1.06e+05\n",
       "No. Iterations:                   100   Pseudo R-squ. (CS):             0.5245\n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "const                         -4.2338      0.693     -6.108      0.000      -5.592      -2.875\n",
       "arpu_6                        11.6444      3.768      3.091      0.002       4.260      19.029\n",
       "arpu_7                        20.5065      4.395      4.665      0.000      11.892      29.122\n",
       "arpu_8                        40.0888      4.975      8.058      0.000      30.338      49.839\n",
       "onnet_mou_6                  -73.7731     34.902     -2.114      0.035    -142.180      -5.367\n",
       "onnet_mou_7                  -57.4026     31.415     -1.827      0.068    -118.974       4.169\n",
       "onnet_mou_8                  -26.5994     46.450     -0.573      0.567    -117.640      64.442\n",
       "offnet_mou_6                 -77.7592     39.248     -1.981      0.048    -154.683      -0.835\n",
       "offnet_mou_7                 -49.6550     25.095     -1.979      0.048     -98.841      -0.469\n",
       "offnet_mou_8                 -79.1261     59.041     -1.340      0.180    -194.845      36.593\n",
       "roam_ic_mou_6                  0.6935      1.094      0.634      0.526      -1.451       2.838\n",
       "roam_ic_mou_7                  0.5985      1.311      0.456      0.648      -1.972       3.169\n",
       "roam_ic_mou_8                 -1.0197      1.459     -0.699      0.485      -3.879       1.840\n",
       "roam_og_mou_6                 37.7991     17.860      2.116      0.034       2.794      72.804\n",
       "roam_og_mou_7                 24.3298     10.594      2.297      0.022       3.567      45.093\n",
       "roam_og_mou_8                 28.1282     22.788      1.234      0.217     -16.536      72.792\n",
       "loc_og_t2t_mou_6           -5.135e+04   2.53e+04     -2.026      0.043   -1.01e+05   -1670.773\n",
       "loc_og_t2t_mou_7             392.5905   2.86e+04      0.014      0.989   -5.57e+04    5.64e+04\n",
       "loc_og_t2t_mou_8            2.358e+05   4.39e+04      5.365      0.000     1.5e+05    3.22e+05\n",
       "loc_og_t2m_mou_6           -3.751e+04   1.85e+04     -2.026      0.043   -7.38e+04   -1226.888\n",
       "loc_og_t2m_mou_7             238.7926   1.76e+04      0.014      0.989   -3.43e+04    3.48e+04\n",
       "loc_og_t2m_mou_8            1.088e+05   2.03e+04      5.366      0.000    6.91e+04    1.49e+05\n",
       "loc_og_t2f_mou_6           -4937.6461   2434.181     -2.028      0.043   -9708.554    -166.738\n",
       "loc_og_t2f_mou_7              42.4806   3150.797      0.013      0.989   -6132.967    6217.928\n",
       "loc_og_t2f_mou_8            1.291e+04   2404.635      5.368      0.000    8195.221    1.76e+04\n",
       "loc_og_t2c_mou_6              -8.5646      1.556     -5.506      0.000     -11.614      -5.516\n",
       "loc_og_t2c_mou_7              -5.1228      2.621     -1.955      0.051     -10.259       0.013\n",
       "loc_og_t2c_mou_8               7.8041      1.606      4.859      0.000       4.656      10.952\n",
       "loc_og_mou_6                5.286e+04   4.76e+04      1.110      0.267   -4.05e+04    1.46e+05\n",
       "loc_og_mou_7                5351.5146    3.5e+04      0.153      0.879   -6.33e+04     7.4e+04\n",
       "loc_og_mou_8                   -3e+05   5.38e+04     -5.575      0.000   -4.05e+05   -1.95e+05\n",
       "std_og_t2t_mou_6           -8.181e+04    3.5e+04     -2.338      0.019    -1.5e+05   -1.32e+04\n",
       "std_og_t2t_mou_7           -6.991e+04   4.03e+04     -1.736      0.083   -1.49e+05    9037.905\n",
       "std_og_t2t_mou_8            1.695e+05   4.21e+04      4.021      0.000    8.69e+04    2.52e+05\n",
       "std_og_t2m_mou_6           -9.234e+04   3.95e+04     -2.338      0.019    -1.7e+05   -1.49e+04\n",
       "std_og_t2m_mou_7           -5.692e+04   3.28e+04     -1.735      0.083   -1.21e+05    7362.668\n",
       "std_og_t2m_mou_8             2.95e+05   7.34e+04      4.022      0.000    1.51e+05    4.39e+05\n",
       "std_og_t2f_mou_6           -3754.7775   1605.461     -2.339      0.019   -6901.423    -608.132\n",
       "std_og_t2f_mou_7           -4005.0415   2306.940     -1.736      0.083   -8526.561     516.478\n",
       "std_og_t2f_mou_8            7480.5010   1862.555      4.016      0.000    3829.961    1.11e+04\n",
       "std_og_mou_6                 6.82e+04   4.32e+04      1.579      0.114   -1.64e+04    1.53e+05\n",
       "std_og_mou_7                7.621e+04   4.47e+04      1.703      0.089   -1.15e+04    1.64e+05\n",
       "std_og_mou_8               -3.689e+05   8.15e+04     -4.526      0.000   -5.29e+05   -2.09e+05\n",
       "isd_og_mou_6               -1.782e+04   1.69e+04     -1.052      0.293    -5.1e+04    1.54e+04\n",
       "isd_og_mou_7                4075.0435   1.77e+04      0.230      0.818   -3.06e+04    3.87e+04\n",
       "isd_og_mou_8               -2.978e+04   1.88e+04     -1.587      0.113   -6.66e+04    6998.090\n",
       "spl_og_mou_6               -3087.2672   2938.677     -1.051      0.293   -8846.969    2672.434\n",
       "spl_og_mou_7                 943.7676   4078.354      0.231      0.817   -7049.659    8937.194\n",
       "spl_og_mou_8               -4112.3494   2588.663     -1.589      0.112   -9186.035     961.336\n",
       "og_others_6                -1880.3495   1753.134     -1.073      0.283   -5316.429    1555.730\n",
       "og_others_7                    4.0971    217.593      0.019      0.985    -422.377     430.571\n",
       "og_others_8                -2325.7119   1317.707     -1.765      0.078   -4908.370     256.946\n",
       "total_og_mou_6              3.232e+04   3.07e+04      1.054      0.292   -2.78e+04    9.24e+04\n",
       "total_og_mou_7             -6150.0258   2.67e+04     -0.230      0.818   -5.85e+04    4.62e+04\n",
       "total_og_mou_8              7.363e+04   4.64e+04      1.588      0.112   -1.73e+04    1.65e+05\n",
       "loc_ic_t2t_mou_6           -1.123e+05   1.62e+04     -6.921      0.000   -1.44e+05   -8.05e+04\n",
       "loc_ic_t2t_mou_7            7.318e+04   2.11e+04      3.461      0.001    3.17e+04    1.15e+05\n",
       "loc_ic_t2t_mou_8            1.266e+05   1.52e+04      8.335      0.000    9.68e+04    1.56e+05\n",
       "loc_ic_t2m_mou_6           -1.146e+05   1.66e+04     -6.921      0.000   -1.47e+05   -8.21e+04\n",
       "loc_ic_t2m_mou_7            5.161e+04   1.49e+04      3.461      0.001    2.24e+04    8.08e+04\n",
       "loc_ic_t2m_mou_8             1.48e+05   1.78e+04      8.335      0.000    1.13e+05    1.83e+05\n",
       "loc_ic_t2f_mou_6           -3.535e+04   5107.278     -6.922      0.000   -4.54e+04   -2.53e+04\n",
       "loc_ic_t2f_mou_7            2.542e+04   7343.274      3.462      0.001     1.1e+04    3.98e+04\n",
       "loc_ic_t2f_mou_8            4.652e+04   5581.875      8.334      0.000    3.56e+04    5.75e+04\n",
       "loc_ic_mou_6                1.541e+05   2.78e+04      5.534      0.000    9.95e+04    2.09e+05\n",
       "loc_ic_mou_7               -7.784e+04   2.48e+04     -3.139      0.002   -1.26e+05   -2.92e+04\n",
       "loc_ic_mou_8               -9.287e+04   2.06e+04     -4.500      0.000   -1.33e+05   -5.24e+04\n",
       "std_ic_t2t_mou_6           -4.023e+04   1.43e+04     -2.808      0.005   -6.83e+04   -1.21e+04\n",
       "std_ic_t2t_mou_7           -4.871e+04   2.05e+04     -2.380      0.017   -8.88e+04   -8594.572\n",
       "std_ic_t2t_mou_8              3.7e+04   1.81e+04      2.048      0.041    1590.096    7.24e+04\n",
       "std_ic_t2m_mou_6           -4.785e+04    1.7e+04     -2.808      0.005   -8.12e+04   -1.44e+04\n",
       "std_ic_t2m_mou_7           -3.025e+04   1.27e+04     -2.381      0.017   -5.52e+04   -5344.593\n",
       "std_ic_t2m_mou_8            3.114e+04   1.52e+04      2.049      0.040    1357.639    6.09e+04\n",
       "std_ic_t2f_mou_6            -1.79e+04   6370.773     -2.809      0.005   -3.04e+04   -5409.503\n",
       "std_ic_t2f_mou_7           -1.306e+04   5490.899     -2.379      0.017   -2.38e+04   -2298.491\n",
       "std_ic_t2f_mou_8            1.506e+04   7361.935      2.046      0.041     633.606    2.95e+04\n",
       "std_ic_mou_6                2.952e+04   1.78e+04      1.661      0.097   -5323.597    6.44e+04\n",
       "std_ic_mou_7                 5.31e+04   2.21e+04      2.402      0.016    9768.423    9.64e+04\n",
       "std_ic_mou_8                1.343e+04   2.09e+04      0.642      0.521   -2.76e+04    5.45e+04\n",
       "total_ic_mou_6              3.916e+04   1.79e+04      2.192      0.028    4143.808    7.42e+04\n",
       "total_ic_mou_7             -5780.9670   1.86e+04     -0.311      0.756   -4.22e+04    3.06e+04\n",
       "total_ic_mou_8             -8.719e+04   1.54e+04     -5.645      0.000   -1.17e+05   -5.69e+04\n",
       "spl_ic_mou_6                 -91.1859     46.254     -1.971      0.049    -181.841      -0.531\n",
       "spl_ic_mou_7                   3.3714     33.847      0.100      0.921     -62.967      69.710\n",
       "spl_ic_mou_8                  10.6622      3.303      3.228      0.001       4.188      17.136\n",
       "isd_ic_mou_6               -3.446e+04   1.57e+04     -2.192      0.028   -6.53e+04   -3650.070\n",
       "isd_ic_mou_7                3501.5929   1.13e+04      0.311      0.756   -1.86e+04    2.56e+04\n",
       "isd_ic_mou_8                3.445e+04   6102.197      5.645      0.000    2.25e+04    4.64e+04\n",
       "ic_others_6                -6851.2490   3113.024     -2.201      0.028    -1.3e+04    -749.834\n",
       "ic_others_7                 1170.1870   3733.873      0.313      0.754   -6148.069    8488.443\n",
       "ic_others_8                 1.739e+04   3080.608      5.646      0.000    1.14e+04    2.34e+04\n",
       "total_rech_num_6              -0.5609      0.737     -0.761      0.447      -2.006       0.884\n",
       "total_rech_num_7               3.5693      0.733      4.867      0.000       2.132       5.007\n",
       "total_rech_num_8              -6.9772      0.817     -8.535      0.000      -8.579      -5.375\n",
       "total_rech_amt_6              -3.3576      3.199     -1.050      0.294      -9.628       2.913\n",
       "total_rech_amt_7             -11.5359      3.632     -3.176      0.001     -18.654      -4.418\n",
       "total_rech_amt_8             -37.1082      4.287     -8.655      0.000     -45.511     -28.705\n",
       "max_rech_amt_6                -3.4159      1.013     -3.373      0.001      -5.401      -1.431\n",
       "max_rech_amt_7                -0.7882      0.812     -0.971      0.331      -2.379       0.802\n",
       "max_rech_amt_8                11.7225      1.295      9.049      0.000       9.183      14.262\n",
       "last_day_rch_amt_6            -0.2336      0.921     -0.254      0.800      -2.040       1.572\n",
       "last_day_rch_amt_7             1.4886      0.699      2.130      0.033       0.119       2.858\n",
       "last_day_rch_amt_8           -16.3063      1.229    -13.264      0.000     -18.716     -13.897\n",
       "total_rech_data_6              2.5459      0.533      4.780      0.000       1.502       3.590\n",
       "total_rech_data_7              1.1544      0.708      1.632      0.103      -0.232       2.541\n",
       "total_rech_data_8             -6.7520      1.087     -6.213      0.000      -8.882      -4.622\n",
       "max_rech_data_6                5.0115      0.891      5.623      0.000       3.265       6.758\n",
       "max_rech_data_7               -2.5493      0.925     -2.755      0.006      -4.363      -0.736\n",
       "max_rech_data_8               -6.1139      1.102     -5.547      0.000      -8.274      -3.954\n",
       "av_rech_amt_data_6           -15.3300      2.951     -5.195      0.000     -21.113      -9.547\n",
       "av_rech_amt_data_7             7.3692      2.047      3.601      0.000       3.358      11.380\n",
       "av_rech_amt_data_8            -2.7686      2.681     -1.033      0.302      -8.024       2.487\n",
       "vol_2g_mb_6                   -1.2410      0.806     -1.539      0.124      -2.821       0.339\n",
       "vol_2g_mb_7                    3.1413      0.934      3.363      0.001       1.311       4.972\n",
       "vol_2g_mb_8                   -5.9188      1.199     -4.936      0.000      -8.269      -3.569\n",
       "vol_3g_mb_6                   -7.8463      3.035     -2.585      0.010     -13.795      -1.897\n",
       "vol_3g_mb_7                    5.9075      1.954      3.023      0.003       2.077       9.738\n",
       "vol_3g_mb_8                   -6.7596      2.397     -2.820      0.005     -11.458      -2.061\n",
       "monthly_2g_6                  -0.1225      0.323     -0.380      0.704      -0.755       0.510\n",
       "monthly_2g_7                  -0.9761      0.427     -2.286      0.022      -1.813      -0.139\n",
       "monthly_2g_8                  -3.2613      0.609     -5.356      0.000      -4.455      -2.068\n",
       "sachet_2g_6                    0.7377      0.517      1.428      0.153      -0.275       1.750\n",
       "sachet_2g_7                    0.1079      0.563      0.192      0.848      -0.995       1.211\n",
       "sachet_2g_8                   -3.2683      0.675     -4.840      0.000      -4.592      -1.945\n",
       "monthly_3g_6                   2.5866      0.788      3.284      0.001       1.043       4.130\n",
       "monthly_3g_7                  -3.2562      1.245     -2.616      0.009      -5.696      -0.816\n",
       "monthly_3g_8                  -3.7848      1.815     -2.085      0.037      -7.342      -0.227\n",
       "sachet_3g_6                    3.5011      0.928      3.771      0.000       1.681       5.321\n",
       "sachet_3g_7                    3.2613      1.087      3.001      0.003       1.132       5.391\n",
       "sachet_3g_8                   -5.2961      1.578     -3.357      0.001      -8.388      -2.204\n",
       "aon                           -0.5000      0.106     -4.701      0.000      -0.708      -0.292\n",
       "aug_vbc_3g                    -6.9148      1.794     -3.855      0.000     -10.430      -3.399\n",
       "jul_vbc_3g                    -1.6401      1.035     -1.584      0.113      -3.670       0.389\n",
       "jun_vbc_3g                     3.3461      0.771      4.341      0.000       1.835       4.857\n",
       "total_data_recharge_amnt_6     1.1078      1.639      0.676      0.499      -2.106       4.321\n",
       "total_data_recharge_amnt_7    -1.3313      1.748     -0.762      0.446      -4.757       2.095\n",
       "total_data_recharge_amnt_8    13.6325      1.873      7.278      0.000       9.961      17.304\n",
       "total_recharge_amnt_6         -0.0329      1.364     -0.024      0.981      -2.707       2.641\n",
       "total_recharge_amnt_7         -5.2584      1.418     -3.710      0.000      -8.037      -2.480\n",
       "total_recharge_amnt_8         -0.2042      1.645     -0.124      0.901      -3.427       3.019\n",
       "average_amnt_6_7              -4.5559      1.047     -4.349      0.000      -6.609      -2.503\n",
       "==============================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For RFE\n",
    "logml = sm.GLM(y_resampled, (sm.add_constant(X_resampled)), family=sm.families.Binomial())\n",
    "logml.fit().summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157e7780",
   "metadata": {},
   "source": [
    "## Lower the p-value higher the significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "27a6fc4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f373b0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/usr/local/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:444: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Running rfe with 70 variables as output\n",
    "rfe = RFE(logreg, n_features_to_select=70)\n",
    "rfe = rfe.fit(X_resampled, y_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ac2cb82c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "       False, False, False, False,  True,  True, False, False,  True,\n",
       "        True,  True,  True,  True, False,  True,  True, False, False,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "       False, False,  True, False,  True,  True, False, False, False,\n",
       "       False, False,  True, False, False, False, False, False,  True,\n",
       "       False, False,  True,  True, False,  True, False, False,  True,\n",
       "        True,  True,  True,  True, False,  True, False, False, False,\n",
       "       False, False,  True,  True, False,  True, False, False,  True,\n",
       "       False, False,  True, False, False,  True, False, False, False,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "       False, False,  True, False, False,  True,  True,  True,  True,\n",
       "        True, False,  True,  True,  True,  True, False, False,  True,\n",
       "       False,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        True, False,  True, False,  True,  True, False, False, False,\n",
       "       False, False, False, False, False])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.support_ # it givs whether or not the selected feature was in top 70. True means yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b474206d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('arpu_6', True, 1),\n",
       " ('arpu_7', True, 1),\n",
       " ('arpu_8', True, 1),\n",
       " ('onnet_mou_6', True, 1),\n",
       " ('onnet_mou_7', True, 1),\n",
       " ('onnet_mou_8', False, 51),\n",
       " ('offnet_mou_6', True, 1),\n",
       " ('offnet_mou_7', True, 1),\n",
       " ('offnet_mou_8', True, 1),\n",
       " ('roam_ic_mou_6', False, 42),\n",
       " ('roam_ic_mou_7', False, 58),\n",
       " ('roam_ic_mou_8', False, 56),\n",
       " ('roam_og_mou_6', False, 16),\n",
       " ('roam_og_mou_7', True, 1),\n",
       " ('roam_og_mou_8', True, 1),\n",
       " ('loc_og_t2t_mou_6', False, 43),\n",
       " ('loc_og_t2t_mou_7', False, 64),\n",
       " ('loc_og_t2t_mou_8', True, 1),\n",
       " ('loc_og_t2m_mou_6', True, 1),\n",
       " ('loc_og_t2m_mou_7', True, 1),\n",
       " ('loc_og_t2m_mou_8', True, 1),\n",
       " ('loc_og_t2f_mou_6', True, 1),\n",
       " ('loc_og_t2f_mou_7', False, 54),\n",
       " ('loc_og_t2f_mou_8', True, 1),\n",
       " ('loc_og_t2c_mou_6', True, 1),\n",
       " ('loc_og_t2c_mou_7', False, 9),\n",
       " ('loc_og_t2c_mou_8', False, 10),\n",
       " ('loc_og_mou_6', False, 71),\n",
       " ('loc_og_mou_7', False, 44),\n",
       " ('loc_og_mou_8', True, 1),\n",
       " ('std_og_t2t_mou_6', False, 52),\n",
       " ('std_og_t2t_mou_7', False, 13),\n",
       " ('std_og_t2t_mou_8', False, 60),\n",
       " ('std_og_t2m_mou_6', False, 53),\n",
       " ('std_og_t2m_mou_7', False, 15),\n",
       " ('std_og_t2m_mou_8', True, 1),\n",
       " ('std_og_t2f_mou_6', False, 37),\n",
       " ('std_og_t2f_mou_7', False, 12),\n",
       " ('std_og_t2f_mou_8', True, 1),\n",
       " ('std_og_mou_6', False, 19),\n",
       " ('std_og_mou_7', True, 1),\n",
       " ('std_og_mou_8', True, 1),\n",
       " ('isd_og_mou_6', False, 68),\n",
       " ('isd_og_mou_7', False, 67),\n",
       " ('isd_og_mou_8', False, 70),\n",
       " ('spl_og_mou_6', False, 36),\n",
       " ('spl_og_mou_7', False, 41),\n",
       " ('spl_og_mou_8', True, 1),\n",
       " ('og_others_6', False, 26),\n",
       " ('og_others_7', False, 40),\n",
       " ('og_others_8', False, 63),\n",
       " ('total_og_mou_6', False, 22),\n",
       " ('total_og_mou_7', False, 14),\n",
       " ('total_og_mou_8', True, 1),\n",
       " ('loc_ic_t2t_mou_6', False, 18),\n",
       " ('loc_ic_t2t_mou_7', False, 33),\n",
       " ('loc_ic_t2t_mou_8', True, 1),\n",
       " ('loc_ic_t2m_mou_6', True, 1),\n",
       " ('loc_ic_t2m_mou_7', False, 32),\n",
       " ('loc_ic_t2m_mou_8', True, 1),\n",
       " ('loc_ic_t2f_mou_6', False, 46),\n",
       " ('loc_ic_t2f_mou_7', False, 45),\n",
       " ('loc_ic_t2f_mou_8', True, 1),\n",
       " ('loc_ic_mou_6', True, 1),\n",
       " ('loc_ic_mou_7', True, 1),\n",
       " ('loc_ic_mou_8', True, 1),\n",
       " ('std_ic_t2t_mou_6', True, 1),\n",
       " ('std_ic_t2t_mou_7', False, 11),\n",
       " ('std_ic_t2t_mou_8', True, 1),\n",
       " ('std_ic_t2m_mou_6', False, 24),\n",
       " ('std_ic_t2m_mou_7', False, 23),\n",
       " ('std_ic_t2m_mou_8', False, 2),\n",
       " ('std_ic_t2f_mou_6', False, 39),\n",
       " ('std_ic_t2f_mou_7', False, 27),\n",
       " ('std_ic_t2f_mou_8', True, 1),\n",
       " ('std_ic_mou_6', True, 1),\n",
       " ('std_ic_mou_7', False, 30),\n",
       " ('std_ic_mou_8', True, 1),\n",
       " ('total_ic_mou_6', False, 34),\n",
       " ('total_ic_mou_7', False, 31),\n",
       " ('total_ic_mou_8', True, 1),\n",
       " ('spl_ic_mou_6', False, 49),\n",
       " ('spl_ic_mou_7', False, 28),\n",
       " ('spl_ic_mou_8', True, 1),\n",
       " ('isd_ic_mou_6', False, 29),\n",
       " ('isd_ic_mou_7', False, 17),\n",
       " ('isd_ic_mou_8', True, 1),\n",
       " ('ic_others_6', False, 38),\n",
       " ('ic_others_7', False, 55),\n",
       " ('ic_others_8', False, 62),\n",
       " ('total_rech_num_6', True, 1),\n",
       " ('total_rech_num_7', True, 1),\n",
       " ('total_rech_num_8', True, 1),\n",
       " ('total_rech_amt_6', True, 1),\n",
       " ('total_rech_amt_7', True, 1),\n",
       " ('total_rech_amt_8', True, 1),\n",
       " ('max_rech_amt_6', True, 1),\n",
       " ('max_rech_amt_7', True, 1),\n",
       " ('max_rech_amt_8', True, 1),\n",
       " ('last_day_rch_amt_6', False, 5),\n",
       " ('last_day_rch_amt_7', False, 25),\n",
       " ('last_day_rch_amt_8', True, 1),\n",
       " ('total_rech_data_6', False, 7),\n",
       " ('total_rech_data_7', False, 65),\n",
       " ('total_rech_data_8', True, 1),\n",
       " ('max_rech_data_6', True, 1),\n",
       " ('max_rech_data_7', True, 1),\n",
       " ('max_rech_data_8', True, 1),\n",
       " ('av_rech_amt_data_6', True, 1),\n",
       " ('av_rech_amt_data_7', False, 61),\n",
       " ('av_rech_amt_data_8', True, 1),\n",
       " ('vol_2g_mb_6', True, 1),\n",
       " ('vol_2g_mb_7', True, 1),\n",
       " ('vol_2g_mb_8', True, 1),\n",
       " ('vol_3g_mb_6', False, 35),\n",
       " ('vol_3g_mb_7', False, 4),\n",
       " ('vol_3g_mb_8', True, 1),\n",
       " ('monthly_2g_6', False, 21),\n",
       " ('monthly_2g_7', True, 1),\n",
       " ('monthly_2g_8', True, 1),\n",
       " ('sachet_2g_6', True, 1),\n",
       " ('sachet_2g_7', False, 69),\n",
       " ('sachet_2g_8', True, 1),\n",
       " ('monthly_3g_6', True, 1),\n",
       " ('monthly_3g_7', True, 1),\n",
       " ('monthly_3g_8', True, 1),\n",
       " ('sachet_3g_6', True, 1),\n",
       " ('sachet_3g_7', False, 20),\n",
       " ('sachet_3g_8', True, 1),\n",
       " ('aon', False, 3),\n",
       " ('aug_vbc_3g', True, 1),\n",
       " ('jul_vbc_3g', True, 1),\n",
       " ('jun_vbc_3g', False, 48),\n",
       " ('total_data_recharge_amnt_6', False, 6),\n",
       " ('total_data_recharge_amnt_7', False, 57),\n",
       " ('total_data_recharge_amnt_8', False, 50),\n",
       " ('total_recharge_amnt_6', False, 47),\n",
       " ('total_recharge_amnt_7', False, 59),\n",
       " ('total_recharge_amnt_8', False, 8),\n",
       " ('average_amnt_6_7', False, 66)]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to see the selected columns\n",
    "list(zip(X_resampled.columns, rfe.support_, rfe.ranking_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "bc628327",
   "metadata": {},
   "outputs": [],
   "source": [
    "col = X_resampled.columns[rfe.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "bbbd2363",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>   <td>churn_probability</td> <th>  No. Observations:  </th>  <td> 27020</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                  <td>GLM</td>        <th>  Df Residuals:      </th>  <td> 26950</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Binomial</td>      <th>  Df Model:          </th>  <td>    69</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>Logit</td>       <th>  Scale:             </th> <td>  1.0000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                <td>IRLS</td>        <th>  Log-Likelihood:    </th> <td> -8940.9</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 15 Sep 2022</td>  <th>  Deviance:          </th> <td>  17882.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>09:44:49</td>      <th>  Pearson chi2:      </th> <td>1.47e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>          <td>7</td>         <th>  Pseudo R-squ. (CS):</th>  <td>0.5154</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>     <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "           <td></td>             <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th>              <td>   -4.2490</td> <td>    0.632</td> <td>   -6.725</td> <td> 0.000</td> <td>   -5.487</td> <td>   -3.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_6</th>             <td>   12.4286</td> <td>    3.462</td> <td>    3.590</td> <td> 0.000</td> <td>    5.643</td> <td>   19.214</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_7</th>             <td>   21.0016</td> <td>    3.886</td> <td>    5.404</td> <td> 0.000</td> <td>   13.384</td> <td>   28.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>arpu_8</th>             <td>   37.5968</td> <td>    4.543</td> <td>    8.275</td> <td> 0.000</td> <td>   28.692</td> <td>   46.502</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_6</th>        <td>    1.9968</td> <td>    0.565</td> <td>    3.534</td> <td> 0.000</td> <td>    0.889</td> <td>    3.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>onnet_mou_7</th>        <td>    6.7337</td> <td>    2.118</td> <td>    3.179</td> <td> 0.001</td> <td>    2.582</td> <td>   10.885</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_6</th>       <td>    1.4241</td> <td>    0.696</td> <td>    2.047</td> <td> 0.041</td> <td>    0.061</td> <td>    2.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_7</th>       <td>    6.3347</td> <td>    1.880</td> <td>    3.369</td> <td> 0.001</td> <td>    2.649</td> <td>   10.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>offnet_mou_8</th>       <td>  -49.8598</td> <td>    9.837</td> <td>   -5.068</td> <td> 0.000</td> <td>  -69.141</td> <td>  -30.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_7</th>      <td>    2.8258</td> <td>    0.975</td> <td>    2.898</td> <td> 0.004</td> <td>    0.915</td> <td>    4.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>roam_og_mou_8</th>      <td>   17.4084</td> <td>    2.893</td> <td>    6.018</td> <td> 0.000</td> <td>   11.738</td> <td>   23.078</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2t_mou_8</th>   <td> 5.145e+04</td> <td>  3.8e+04</td> <td>    1.354</td> <td> 0.176</td> <td> -2.3e+04</td> <td> 1.26e+05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_6</th>   <td>   -3.1707</td> <td>    0.992</td> <td>   -3.197</td> <td> 0.001</td> <td>   -5.115</td> <td>   -1.227</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_7</th>   <td>   -4.2345</td> <td>    1.702</td> <td>   -2.488</td> <td> 0.013</td> <td>   -7.571</td> <td>   -0.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2m_mou_8</th>   <td> 2.376e+04</td> <td> 1.75e+04</td> <td>    1.356</td> <td> 0.175</td> <td>-1.06e+04</td> <td> 5.81e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_6</th>   <td>   -5.9204</td> <td>    1.633</td> <td>   -3.625</td> <td> 0.000</td> <td>   -9.122</td> <td>   -2.719</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2f_mou_8</th>   <td> 2820.4637</td> <td> 2078.426</td> <td>    1.357</td> <td> 0.175</td> <td>-1253.177</td> <td> 6894.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_t2c_mou_6</th>   <td>   -7.8591</td> <td>    1.278</td> <td>   -6.149</td> <td> 0.000</td> <td>  -10.364</td> <td>   -5.354</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_og_mou_8</th>       <td>-5.282e+04</td> <td>  3.9e+04</td> <td>   -1.354</td> <td> 0.176</td> <td>-1.29e+05</td> <td> 2.36e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2m_mou_8</th>   <td>   43.8402</td> <td>    9.855</td> <td>    4.448</td> <td> 0.000</td> <td>   24.524</td> <td>   63.156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_t2f_mou_8</th>   <td>   -9.7312</td> <td>    2.499</td> <td>   -3.895</td> <td> 0.000</td> <td>  -14.628</td> <td>   -4.834</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_7</th>       <td>   -3.3083</td> <td>    2.141</td> <td>   -1.545</td> <td> 0.122</td> <td>   -7.504</td> <td>    0.888</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_og_mou_8</th>       <td>   23.6068</td> <td>   27.995</td> <td>    0.843</td> <td> 0.399</td> <td>  -31.263</td> <td>   78.477</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_og_mou_8</th>       <td>    0.9654</td> <td>    1.869</td> <td>    0.516</td> <td> 0.606</td> <td>   -2.698</td> <td>    4.629</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_og_mou_8</th>     <td>  -31.5769</td> <td>   28.199</td> <td>   -1.120</td> <td> 0.263</td> <td>  -86.846</td> <td>   23.693</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2t_mou_8</th>   <td>-1.258e+04</td> <td> 8572.957</td> <td>   -1.467</td> <td> 0.142</td> <td>-2.94e+04</td> <td> 4223.742</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_6</th>   <td>    3.8396</td> <td>    1.854</td> <td>    2.071</td> <td> 0.038</td> <td>    0.207</td> <td>    7.473</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2m_mou_8</th>   <td>-1.471e+04</td> <td>    1e+04</td> <td>   -1.467</td> <td> 0.142</td> <td>-3.43e+04</td> <td> 4937.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_t2f_mou_8</th>   <td>-4627.8108</td> <td> 3150.668</td> <td>   -1.469</td> <td> 0.142</td> <td>-1.08e+04</td> <td> 1547.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_6</th>       <td>    0.2304</td> <td>    2.443</td> <td>    0.094</td> <td> 0.925</td> <td>   -4.557</td> <td>    5.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_7</th>       <td>   14.8759</td> <td>    1.663</td> <td>    8.947</td> <td> 0.000</td> <td>   11.617</td> <td>   18.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>loc_ic_mou_8</th>       <td> 1.676e+04</td> <td> 1.15e+04</td> <td>    1.464</td> <td> 0.143</td> <td>-5683.095</td> <td> 3.92e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_6</th>   <td>    5.4549</td> <td>    1.692</td> <td>    3.224</td> <td> 0.001</td> <td>    2.139</td> <td>    8.771</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2t_mou_8</th>   <td>  -17.8932</td> <td>    4.378</td> <td>   -4.087</td> <td> 0.000</td> <td>  -26.474</td> <td>   -9.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_t2f_mou_8</th>   <td>  -20.5131</td> <td>    7.996</td> <td>   -2.565</td> <td> 0.010</td> <td>  -36.185</td> <td>   -4.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_6</th>       <td>    0.3587</td> <td>    1.218</td> <td>    0.295</td> <td> 0.768</td> <td>   -2.028</td> <td>    2.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>std_ic_mou_8</th>       <td>   -8.9078</td> <td>    8.231</td> <td>   -1.082</td> <td> 0.279</td> <td>  -25.041</td> <td>    7.225</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_ic_mou_8</th>     <td>   -0.3932</td> <td>   12.741</td> <td>   -0.031</td> <td> 0.975</td> <td>  -25.366</td> <td>   24.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>spl_ic_mou_8</th>       <td>   -7.4114</td> <td>    0.597</td> <td>  -12.414</td> <td> 0.000</td> <td>   -8.582</td> <td>   -6.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>isd_ic_mou_8</th>       <td>    0.9612</td> <td>    5.254</td> <td>    0.183</td> <td> 0.855</td> <td>   -9.337</td> <td>   11.259</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_6</th>   <td>   -0.4865</td> <td>    0.677</td> <td>   -0.719</td> <td> 0.472</td> <td>   -1.813</td> <td>    0.840</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_7</th>   <td>    3.5184</td> <td>    0.654</td> <td>    5.377</td> <td> 0.000</td> <td>    2.236</td> <td>    4.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_num_8</th>   <td>   -7.5146</td> <td>    0.764</td> <td>   -9.833</td> <td> 0.000</td> <td>   -9.013</td> <td>   -6.017</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_6</th>   <td>   -6.2226</td> <td>    3.077</td> <td>   -2.022</td> <td> 0.043</td> <td>  -12.254</td> <td>   -0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_7</th>   <td>  -13.2817</td> <td>    3.523</td> <td>   -3.770</td> <td> 0.000</td> <td>  -20.187</td> <td>   -6.377</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_amt_8</th>   <td>  -38.4012</td> <td>    4.365</td> <td>   -8.797</td> <td> 0.000</td> <td>  -46.957</td> <td>  -29.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_6</th>     <td>   -3.2872</td> <td>    0.942</td> <td>   -3.491</td> <td> 0.000</td> <td>   -5.133</td> <td>   -1.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_7</th>     <td>   -0.2787</td> <td>    0.770</td> <td>   -0.362</td> <td> 0.717</td> <td>   -1.787</td> <td>    1.230</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_amt_8</th>     <td>   10.7616</td> <td>    1.265</td> <td>    8.508</td> <td> 0.000</td> <td>    8.282</td> <td>   13.241</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>last_day_rch_amt_8</th> <td>  -16.2420</td> <td>    1.192</td> <td>  -13.629</td> <td> 0.000</td> <td>  -18.578</td> <td>  -13.906</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>total_rech_data_8</th>  <td>   -5.1554</td> <td>    0.935</td> <td>   -5.517</td> <td> 0.000</td> <td>   -6.987</td> <td>   -3.324</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_6</th>    <td>    4.4188</td> <td>    0.755</td> <td>    5.857</td> <td> 0.000</td> <td>    2.940</td> <td>    5.898</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_7</th>    <td>    0.5243</td> <td>    0.655</td> <td>    0.800</td> <td> 0.423</td> <td>   -0.760</td> <td>    1.808</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>max_rech_data_8</th>    <td>   -6.8163</td> <td>    1.034</td> <td>   -6.593</td> <td> 0.000</td> <td>   -8.843</td> <td>   -4.790</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_6</th> <td>  -14.7334</td> <td>    2.045</td> <td>   -7.204</td> <td> 0.000</td> <td>  -18.742</td> <td>  -10.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>av_rech_amt_data_8</th> <td>    2.4415</td> <td>    2.356</td> <td>    1.036</td> <td> 0.300</td> <td>   -2.177</td> <td>    7.060</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_6</th>        <td>   -0.7719</td> <td>    0.745</td> <td>   -1.036</td> <td> 0.300</td> <td>   -2.232</td> <td>    0.688</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_7</th>        <td>    3.0185</td> <td>    0.835</td> <td>    3.615</td> <td> 0.000</td> <td>    1.382</td> <td>    4.655</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_2g_mb_8</th>        <td>   -6.7858</td> <td>    1.191</td> <td>   -5.700</td> <td> 0.000</td> <td>   -9.119</td> <td>   -4.452</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>vol_3g_mb_8</th>        <td>   -5.3487</td> <td>    2.128</td> <td>   -2.514</td> <td> 0.012</td> <td>   -9.519</td> <td>   -1.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_7</th>       <td>   -0.9047</td> <td>    0.393</td> <td>   -2.301</td> <td> 0.021</td> <td>   -1.675</td> <td>   -0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_2g_8</th>       <td>   -3.7135</td> <td>    0.587</td> <td>   -6.330</td> <td> 0.000</td> <td>   -4.863</td> <td>   -2.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_6</th>        <td>    2.2071</td> <td>    0.547</td> <td>    4.035</td> <td> 0.000</td> <td>    1.135</td> <td>    3.279</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_2g_8</th>        <td>   -3.3865</td> <td>    0.619</td> <td>   -5.473</td> <td> 0.000</td> <td>   -4.599</td> <td>   -2.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_6</th>       <td>    2.3567</td> <td>    0.698</td> <td>    3.378</td> <td> 0.001</td> <td>    0.990</td> <td>    3.724</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_7</th>       <td>   -0.9597</td> <td>    1.065</td> <td>   -0.902</td> <td> 0.367</td> <td>   -3.046</td> <td>    1.127</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>monthly_3g_8</th>       <td>   -5.2966</td> <td>    1.769</td> <td>   -2.994</td> <td> 0.003</td> <td>   -8.764</td> <td>   -1.829</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_6</th>        <td>    4.4534</td> <td>    0.828</td> <td>    5.377</td> <td> 0.000</td> <td>    2.830</td> <td>    6.077</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>sachet_3g_8</th>        <td>   -2.2164</td> <td>    1.377</td> <td>   -1.609</td> <td> 0.108</td> <td>   -4.916</td> <td>    0.483</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>aug_vbc_3g</th>         <td>   -6.8193</td> <td>    1.681</td> <td>   -4.056</td> <td> 0.000</td> <td>  -10.115</td> <td>   -3.524</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>jul_vbc_3g</th>         <td>    1.0683</td> <td>    0.797</td> <td>    1.341</td> <td> 0.180</td> <td>   -0.493</td> <td>    2.629</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:      churn_probability   No. Observations:                27020\n",
       "Model:                            GLM   Df Residuals:                    26950\n",
       "Model Family:                Binomial   Df Model:                           69\n",
       "Link Function:                  Logit   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -8940.9\n",
       "Date:                Thu, 15 Sep 2022   Deviance:                       17882.\n",
       "Time:                        09:44:49   Pearson chi2:                 1.47e+05\n",
       "No. Iterations:                     7   Pseudo R-squ. (CS):             0.5154\n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================\n",
       "                         coef    std err          z      P>|z|      [0.025      0.975]\n",
       "--------------------------------------------------------------------------------------\n",
       "const                 -4.2490      0.632     -6.725      0.000      -5.487      -3.011\n",
       "arpu_6                12.4286      3.462      3.590      0.000       5.643      19.214\n",
       "arpu_7                21.0016      3.886      5.404      0.000      13.384      28.619\n",
       "arpu_8                37.5968      4.543      8.275      0.000      28.692      46.502\n",
       "onnet_mou_6            1.9968      0.565      3.534      0.000       0.889       3.104\n",
       "onnet_mou_7            6.7337      2.118      3.179      0.001       2.582      10.885\n",
       "offnet_mou_6           1.4241      0.696      2.047      0.041       0.061       2.788\n",
       "offnet_mou_7           6.3347      1.880      3.369      0.001       2.649      10.020\n",
       "offnet_mou_8         -49.8598      9.837     -5.068      0.000     -69.141     -30.579\n",
       "roam_og_mou_7          2.8258      0.975      2.898      0.004       0.915       4.737\n",
       "roam_og_mou_8         17.4084      2.893      6.018      0.000      11.738      23.078\n",
       "loc_og_t2t_mou_8    5.145e+04    3.8e+04      1.354      0.176    -2.3e+04    1.26e+05\n",
       "loc_og_t2m_mou_6      -3.1707      0.992     -3.197      0.001      -5.115      -1.227\n",
       "loc_og_t2m_mou_7      -4.2345      1.702     -2.488      0.013      -7.571      -0.898\n",
       "loc_og_t2m_mou_8    2.376e+04   1.75e+04      1.356      0.175   -1.06e+04    5.81e+04\n",
       "loc_og_t2f_mou_6      -5.9204      1.633     -3.625      0.000      -9.122      -2.719\n",
       "loc_og_t2f_mou_8    2820.4637   2078.426      1.357      0.175   -1253.177    6894.104\n",
       "loc_og_t2c_mou_6      -7.8591      1.278     -6.149      0.000     -10.364      -5.354\n",
       "loc_og_mou_8       -5.282e+04    3.9e+04     -1.354      0.176   -1.29e+05    2.36e+04\n",
       "std_og_t2m_mou_8      43.8402      9.855      4.448      0.000      24.524      63.156\n",
       "std_og_t2f_mou_8      -9.7312      2.499     -3.895      0.000     -14.628      -4.834\n",
       "std_og_mou_7          -3.3083      2.141     -1.545      0.122      -7.504       0.888\n",
       "std_og_mou_8          23.6068     27.995      0.843      0.399     -31.263      78.477\n",
       "spl_og_mou_8           0.9654      1.869      0.516      0.606      -2.698       4.629\n",
       "total_og_mou_8       -31.5769     28.199     -1.120      0.263     -86.846      23.693\n",
       "loc_ic_t2t_mou_8   -1.258e+04   8572.957     -1.467      0.142   -2.94e+04    4223.742\n",
       "loc_ic_t2m_mou_6       3.8396      1.854      2.071      0.038       0.207       7.473\n",
       "loc_ic_t2m_mou_8   -1.471e+04      1e+04     -1.467      0.142   -3.43e+04    4937.254\n",
       "loc_ic_t2f_mou_8   -4627.8108   3150.668     -1.469      0.142   -1.08e+04    1547.385\n",
       "loc_ic_mou_6           0.2304      2.443      0.094      0.925      -4.557       5.018\n",
       "loc_ic_mou_7          14.8759      1.663      8.947      0.000      11.617      18.135\n",
       "loc_ic_mou_8        1.676e+04   1.15e+04      1.464      0.143   -5683.095    3.92e+04\n",
       "std_ic_t2t_mou_6       5.4549      1.692      3.224      0.001       2.139       8.771\n",
       "std_ic_t2t_mou_8     -17.8932      4.378     -4.087      0.000     -26.474      -9.313\n",
       "std_ic_t2f_mou_8     -20.5131      7.996     -2.565      0.010     -36.185      -4.841\n",
       "std_ic_mou_6           0.3587      1.218      0.295      0.768      -2.028       2.746\n",
       "std_ic_mou_8          -8.9078      8.231     -1.082      0.279     -25.041       7.225\n",
       "total_ic_mou_8        -0.3932     12.741     -0.031      0.975     -25.366      24.579\n",
       "spl_ic_mou_8          -7.4114      0.597    -12.414      0.000      -8.582      -6.241\n",
       "isd_ic_mou_8           0.9612      5.254      0.183      0.855      -9.337      11.259\n",
       "total_rech_num_6      -0.4865      0.677     -0.719      0.472      -1.813       0.840\n",
       "total_rech_num_7       3.5184      0.654      5.377      0.000       2.236       4.801\n",
       "total_rech_num_8      -7.5146      0.764     -9.833      0.000      -9.013      -6.017\n",
       "total_rech_amt_6      -6.2226      3.077     -2.022      0.043     -12.254      -0.192\n",
       "total_rech_amt_7     -13.2817      3.523     -3.770      0.000     -20.187      -6.377\n",
       "total_rech_amt_8     -38.4012      4.365     -8.797      0.000     -46.957     -29.845\n",
       "max_rech_amt_6        -3.2872      0.942     -3.491      0.000      -5.133      -1.441\n",
       "max_rech_amt_7        -0.2787      0.770     -0.362      0.717      -1.787       1.230\n",
       "max_rech_amt_8        10.7616      1.265      8.508      0.000       8.282      13.241\n",
       "last_day_rch_amt_8   -16.2420      1.192    -13.629      0.000     -18.578     -13.906\n",
       "total_rech_data_8     -5.1554      0.935     -5.517      0.000      -6.987      -3.324\n",
       "max_rech_data_6        4.4188      0.755      5.857      0.000       2.940       5.898\n",
       "max_rech_data_7        0.5243      0.655      0.800      0.423      -0.760       1.808\n",
       "max_rech_data_8       -6.8163      1.034     -6.593      0.000      -8.843      -4.790\n",
       "av_rech_amt_data_6   -14.7334      2.045     -7.204      0.000     -18.742     -10.725\n",
       "av_rech_amt_data_8     2.4415      2.356      1.036      0.300      -2.177       7.060\n",
       "vol_2g_mb_6           -0.7719      0.745     -1.036      0.300      -2.232       0.688\n",
       "vol_2g_mb_7            3.0185      0.835      3.615      0.000       1.382       4.655\n",
       "vol_2g_mb_8           -6.7858      1.191     -5.700      0.000      -9.119      -4.452\n",
       "vol_3g_mb_8           -5.3487      2.128     -2.514      0.012      -9.519      -1.179\n",
       "monthly_2g_7          -0.9047      0.393     -2.301      0.021      -1.675      -0.134\n",
       "monthly_2g_8          -3.7135      0.587     -6.330      0.000      -4.863      -2.564\n",
       "sachet_2g_6            2.2071      0.547      4.035      0.000       1.135       3.279\n",
       "sachet_2g_8           -3.3865      0.619     -5.473      0.000      -4.599      -2.174\n",
       "monthly_3g_6           2.3567      0.698      3.378      0.001       0.990       3.724\n",
       "monthly_3g_7          -0.9597      1.065     -0.902      0.367      -3.046       1.127\n",
       "monthly_3g_8          -5.2966      1.769     -2.994      0.003      -8.764      -1.829\n",
       "sachet_3g_6            4.4534      0.828      5.377      0.000       2.830       6.077\n",
       "sachet_3g_8           -2.2164      1.377     -1.609      0.108      -4.916       0.483\n",
       "aug_vbc_3g            -6.8193      1.681     -4.056      0.000     -10.115      -3.524\n",
       "jul_vbc_3g             1.0683      0.797      1.341      0.180      -0.493       2.629\n",
       "======================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled_sm = sm.add_constant(X_resampled[col])\n",
    "logm2 = sm.GLM(y_resampled, X_resampled_sm, family=sm.families.Binomial())\n",
    "res = logm2.fit()\n",
    "res.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3270c989",
   "metadata": {},
   "source": [
    "### Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "de453884",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>roam_og_mou_8</th>\n",
       "      <th>...</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5662</th>\n",
       "      <td>554.740</td>\n",
       "      <td>782.352</td>\n",
       "      <td>673.692</td>\n",
       "      <td>36.86</td>\n",
       "      <td>38.63</td>\n",
       "      <td>649.01</td>\n",
       "      <td>845.83</td>\n",
       "      <td>661.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37574</th>\n",
       "      <td>1563.157</td>\n",
       "      <td>1579.675</td>\n",
       "      <td>1256.565</td>\n",
       "      <td>2761.74</td>\n",
       "      <td>3158.18</td>\n",
       "      <td>1358.03</td>\n",
       "      <td>1144.44</td>\n",
       "      <td>1327.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58341</th>\n",
       "      <td>594.217</td>\n",
       "      <td>796.737</td>\n",
       "      <td>996.393</td>\n",
       "      <td>785.66</td>\n",
       "      <td>1200.53</td>\n",
       "      <td>149.53</td>\n",
       "      <td>186.48</td>\n",
       "      <td>585.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23282</th>\n",
       "      <td>352.160</td>\n",
       "      <td>197.245</td>\n",
       "      <td>365.564</td>\n",
       "      <td>192.04</td>\n",
       "      <td>179.88</td>\n",
       "      <td>508.53</td>\n",
       "      <td>116.58</td>\n",
       "      <td>507.64</td>\n",
       "      <td>34.96</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30561</th>\n",
       "      <td>332.040</td>\n",
       "      <td>275.976</td>\n",
       "      <td>267.033</td>\n",
       "      <td>116.49</td>\n",
       "      <td>96.89</td>\n",
       "      <td>152.34</td>\n",
       "      <td>178.24</td>\n",
       "      <td>424.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.05</td>\n",
       "      <td>337.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 70 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         arpu_6    arpu_7    arpu_8  onnet_mou_6  onnet_mou_7  offnet_mou_6  \\\n",
       "5662    554.740   782.352   673.692        36.86        38.63        649.01   \n",
       "37574  1563.157  1579.675  1256.565      2761.74      3158.18       1358.03   \n",
       "58341   594.217   796.737   996.393       785.66      1200.53        149.53   \n",
       "23282   352.160   197.245   365.564       192.04       179.88        508.53   \n",
       "30561   332.040   275.976   267.033       116.49        96.89        152.34   \n",
       "\n",
       "       offnet_mou_7  offnet_mou_8  roam_og_mou_7  roam_og_mou_8  ...  \\\n",
       "5662         845.83        661.89           0.00            0.0  ...   \n",
       "37574       1144.44       1327.03           0.00            0.0  ...   \n",
       "58341        186.48        585.36           0.00            0.0  ...   \n",
       "23282        116.58        507.64          34.96            0.0  ...   \n",
       "30561        178.24        424.68           0.00            0.0  ...   \n",
       "\n",
       "       monthly_2g_8  sachet_2g_6  sachet_2g_8  monthly_3g_6  monthly_3g_7  \\\n",
       "5662              0            0            0             0             0   \n",
       "37574             0            0            0             0             0   \n",
       "58341             0            0            0             0             0   \n",
       "23282             0            0            3             0             0   \n",
       "30561             0            0            0             0             0   \n",
       "\n",
       "       monthly_3g_8  sachet_3g_6  sachet_3g_8  aug_vbc_3g  jul_vbc_3g  \n",
       "5662              0            0            0        0.00         0.0  \n",
       "37574             0            0            0        0.00         0.0  \n",
       "58341             0            0            0        0.00         0.0  \n",
       "23282             0            0            0        0.00         0.0  \n",
       "30561             0            0            0       31.05       337.7  \n",
       "\n",
       "[5 rows x 70 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = X_test[col]\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dd20e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_sm = sm.add_constant(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "df6e96f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.9/site-packages/statsmodels/genmod/families/links.py:187: RuntimeWarning: overflow encountered in exp\n",
      "  t = np.exp(-z)\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = res.predict(X_test_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "2c63d4ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5662     0.0\n",
       "37574    0.0\n",
       "58341    0.0\n",
       "23282    0.0\n",
       "30561    0.0\n",
       "45844    0.0\n",
       "30159    0.0\n",
       "62778    0.0\n",
       "45559    0.0\n",
       "35274    0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6dbfcf16",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>const</th>\n",
       "      <th>arpu_6</th>\n",
       "      <th>arpu_7</th>\n",
       "      <th>arpu_8</th>\n",
       "      <th>onnet_mou_6</th>\n",
       "      <th>onnet_mou_7</th>\n",
       "      <th>offnet_mou_6</th>\n",
       "      <th>offnet_mou_7</th>\n",
       "      <th>offnet_mou_8</th>\n",
       "      <th>roam_og_mou_7</th>\n",
       "      <th>...</th>\n",
       "      <th>monthly_2g_8</th>\n",
       "      <th>sachet_2g_6</th>\n",
       "      <th>sachet_2g_8</th>\n",
       "      <th>monthly_3g_6</th>\n",
       "      <th>monthly_3g_7</th>\n",
       "      <th>monthly_3g_8</th>\n",
       "      <th>sachet_3g_6</th>\n",
       "      <th>sachet_3g_8</th>\n",
       "      <th>aug_vbc_3g</th>\n",
       "      <th>jul_vbc_3g</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5662</th>\n",
       "      <td>1.0</td>\n",
       "      <td>554.740</td>\n",
       "      <td>782.352</td>\n",
       "      <td>673.692</td>\n",
       "      <td>36.86</td>\n",
       "      <td>38.63</td>\n",
       "      <td>649.01</td>\n",
       "      <td>845.83</td>\n",
       "      <td>661.89</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37574</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1563.157</td>\n",
       "      <td>1579.675</td>\n",
       "      <td>1256.565</td>\n",
       "      <td>2761.74</td>\n",
       "      <td>3158.18</td>\n",
       "      <td>1358.03</td>\n",
       "      <td>1144.44</td>\n",
       "      <td>1327.03</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58341</th>\n",
       "      <td>1.0</td>\n",
       "      <td>594.217</td>\n",
       "      <td>796.737</td>\n",
       "      <td>996.393</td>\n",
       "      <td>785.66</td>\n",
       "      <td>1200.53</td>\n",
       "      <td>149.53</td>\n",
       "      <td>186.48</td>\n",
       "      <td>585.36</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23282</th>\n",
       "      <td>1.0</td>\n",
       "      <td>352.160</td>\n",
       "      <td>197.245</td>\n",
       "      <td>365.564</td>\n",
       "      <td>192.04</td>\n",
       "      <td>179.88</td>\n",
       "      <td>508.53</td>\n",
       "      <td>116.58</td>\n",
       "      <td>507.64</td>\n",
       "      <td>34.96</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30561</th>\n",
       "      <td>1.0</td>\n",
       "      <td>332.040</td>\n",
       "      <td>275.976</td>\n",
       "      <td>267.033</td>\n",
       "      <td>116.49</td>\n",
       "      <td>96.89</td>\n",
       "      <td>152.34</td>\n",
       "      <td>178.24</td>\n",
       "      <td>424.68</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.05</td>\n",
       "      <td>337.7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       const    arpu_6    arpu_7    arpu_8  onnet_mou_6  onnet_mou_7  \\\n",
       "5662     1.0   554.740   782.352   673.692        36.86        38.63   \n",
       "37574    1.0  1563.157  1579.675  1256.565      2761.74      3158.18   \n",
       "58341    1.0   594.217   796.737   996.393       785.66      1200.53   \n",
       "23282    1.0   352.160   197.245   365.564       192.04       179.88   \n",
       "30561    1.0   332.040   275.976   267.033       116.49        96.89   \n",
       "\n",
       "       offnet_mou_6  offnet_mou_7  offnet_mou_8  roam_og_mou_7  ...  \\\n",
       "5662         649.01        845.83        661.89           0.00  ...   \n",
       "37574       1358.03       1144.44       1327.03           0.00  ...   \n",
       "58341        149.53        186.48        585.36           0.00  ...   \n",
       "23282        508.53        116.58        507.64          34.96  ...   \n",
       "30561        152.34        178.24        424.68           0.00  ...   \n",
       "\n",
       "       monthly_2g_8  sachet_2g_6  sachet_2g_8  monthly_3g_6  monthly_3g_7  \\\n",
       "5662              0            0            0             0             0   \n",
       "37574             0            0            0             0             0   \n",
       "58341             0            0            0             0             0   \n",
       "23282             0            0            3             0             0   \n",
       "30561             0            0            0             0             0   \n",
       "\n",
       "       monthly_3g_8  sachet_3g_6  sachet_3g_8  aug_vbc_3g  jul_vbc_3g  \n",
       "5662              0            0            0        0.00         0.0  \n",
       "37574             0            0            0        0.00         0.0  \n",
       "58341             0            0            0        0.00         0.0  \n",
       "23282             0            0            0        0.00         0.0  \n",
       "30561             0            0            0       31.05       337.7  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_sm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2fb4790c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27020, 71)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled_sm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fc21710b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = res.predict(X_resampled_sm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "41d41dd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "r-squared train: 0.6110305840445045\n",
      "rss train: 2627.4884047793716\n",
      "mse train: 0.09724235398887386\n"
     ]
    }
   ],
   "source": [
    "metric = []\n",
    "r2_train_lr = r2_score(y_resampled, y_pred_train)\n",
    "print(f\"r-squared train: {r2_train_lr}\")\n",
    "metric.append(r2_train_lr)\n",
    "\n",
    "rss1_lr = np.sum(np.square(y_resampled - y_pred_train))\n",
    "print(f\"rss train: {rss1_lr}\")\n",
    "metric.append(rss1_lr)\n",
    "\n",
    "mse_train_lr = mean_squared_error(y_resampled, y_pred_train)\n",
    "print(f\"mse train: {mse_train_lr}\")\n",
    "metric.append(mse_train_lr**0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "502455e8",
   "metadata": {},
   "source": [
    "## Looking at the rmse value (close to 0.1) Logistic regression doesn't seems to be a good model with such large number of  columns."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd93b4a0",
   "metadata": {},
   "source": [
    "## So lets move on with PCA and Logistic Regression to check if model improves or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecb5679",
   "metadata": {},
   "source": [
    "## PCA on the data\n",
    "\n",
    "- While computing the principal components, we must not include the entire dataset. Model building is all about doing well on the data we haven't seen yet!\n",
    "- So we'll calculate the PCs using the train data, and apply them later on the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e2a5cd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Looking at the data again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "228cc28f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27020,)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f357b520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27020, 140)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_resampled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "d5bfc9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "4879eab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>PCA(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "PCA(random_state=42)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.fit(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6a324422",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.75628023e-02,  1.43390915e-02, -4.81114112e-03, ...,\n",
       "        -2.83025648e-03, -9.37201440e-03, -3.73479832e-03],\n",
       "       [ 5.00764402e-02,  5.51487621e-02,  3.85216639e-02, ...,\n",
       "        -2.94272716e-03, -7.84809775e-04, -1.00851464e-02],\n",
       "       [ 4.74801646e-02,  7.46315751e-02,  7.05575729e-02, ...,\n",
       "         6.38306541e-02,  6.04925620e-02,  9.31211307e-02],\n",
       "       ...,\n",
       "       [-0.00000000e+00,  4.98538313e-16, -3.92573486e-16, ...,\n",
       "         1.02697590e-02,  7.20904950e-02, -4.21340996e-01],\n",
       "       [ 0.00000000e+00,  1.61775361e-16,  4.65669106e-17, ...,\n",
       "         3.77294196e-01,  2.16466877e-01, -5.65774399e-01],\n",
       "       [ 0.00000000e+00,  1.41503495e-16, -5.31836718e-16, ...,\n",
       "        -6.70215798e-02,  6.70337883e-01,  2.29016937e-01]])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "462adf05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.89921060e-01, 1.55282457e-01, 7.48236572e-02, 5.94077580e-02,\n",
       "       5.52837106e-02, 5.05027770e-02, 4.48319368e-02, 3.28960552e-02,\n",
       "       2.12714096e-02, 1.98180620e-02, 1.93956901e-02, 1.82391954e-02,\n",
       "       1.56358644e-02, 1.30826743e-02, 1.22483041e-02, 1.19748744e-02,\n",
       "       1.08487218e-02, 1.04456568e-02, 1.01387695e-02, 9.92885240e-03,\n",
       "       8.94345705e-03, 8.08312610e-03, 7.89979764e-03, 7.21819661e-03,\n",
       "       6.84286490e-03, 6.43605882e-03, 6.25725535e-03, 5.68220541e-03,\n",
       "       5.36029325e-03, 5.15152515e-03, 4.96285065e-03, 4.64201597e-03,\n",
       "       4.16832749e-03, 3.78090042e-03, 3.41609669e-03, 3.35941398e-03,\n",
       "       3.06122706e-03, 2.94917057e-03, 2.91572700e-03, 2.87876647e-03,\n",
       "       2.72295778e-03, 2.63850066e-03, 2.51440345e-03, 2.46113685e-03,\n",
       "       2.34941136e-03, 2.24393535e-03, 2.07605271e-03, 2.05317701e-03,\n",
       "       2.01742738e-03, 1.82031698e-03, 1.75459979e-03, 1.72684764e-03,\n",
       "       1.68007595e-03, 1.63219184e-03, 1.55420069e-03, 1.48570873e-03,\n",
       "       1.35800629e-03, 1.29735067e-03, 1.25288769e-03, 1.23957517e-03,\n",
       "       1.21296637e-03, 1.10454297e-03, 1.01172198e-03, 9.80295928e-04,\n",
       "       9.44191209e-04, 9.17750601e-04, 8.73928319e-04, 8.37543704e-04,\n",
       "       8.28112065e-04, 8.13263469e-04, 8.06825663e-04, 7.35527182e-04,\n",
       "       6.80395005e-04, 6.66047662e-04, 5.87542943e-04, 5.74611446e-04,\n",
       "       5.48227791e-04, 5.18629012e-04, 4.88889515e-04, 4.69718404e-04,\n",
       "       4.61470969e-04, 4.40677731e-04, 4.24129702e-04, 4.06814376e-04,\n",
       "       3.90789731e-04, 3.72911320e-04, 3.21852153e-04, 3.18816343e-04,\n",
       "       2.94747242e-04, 2.82402787e-04, 2.73850373e-04, 2.42548184e-04,\n",
       "       2.36280044e-04, 2.23075328e-04, 1.76832981e-04, 1.74131758e-04,\n",
       "       1.66667937e-04, 1.63337835e-04, 1.48877642e-04, 1.44634108e-04,\n",
       "       1.39381955e-04, 1.11186199e-04, 1.04772498e-04, 9.56958112e-05,\n",
       "       9.24597724e-05, 6.17613411e-05, 5.78449450e-05, 5.39235131e-05,\n",
       "       4.36553741e-05, 3.78719088e-05, 2.02757135e-05, 1.75703660e-05,\n",
       "       1.42915842e-05, 8.76556960e-06, 6.42751106e-06, 1.97572310e-06,\n",
       "       8.37642873e-07, 1.94757580e-07, 3.27798872e-12, 1.93358708e-12,\n",
       "       1.53672127e-12, 1.31120869e-12, 1.16871649e-12, 1.05332348e-12,\n",
       "       1.04429483e-12, 7.02788504e-13, 5.24536060e-13, 3.75504651e-13,\n",
       "       3.69484566e-13, 3.57120494e-13, 2.69634542e-13, 2.18419203e-13,\n",
       "       9.83074597e-14, 1.56114621e-33, 1.40772510e-33, 1.25976197e-33,\n",
       "       9.61520121e-34, 7.46136662e-34, 7.46136662e-34, 7.46136662e-34])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca.explained_variance_ratio_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "35ab804f",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_cumu = np.cumsum(pca.explained_variance_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "5653298c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1369659a0>]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=[12,8])\n",
    "plt.plot(range(1,len(var_cumu)+1), var_cumu)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e46d15",
   "metadata": {},
   "source": [
    "## Looking at the scree plot with 50 PCs we have more than 95% of variance explained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "6b98d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_final = IncrementalPCA(n_components=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ef462a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_pca = pca_final.fit_transform(X_resampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "4acf2f4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27020, 50)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_pca.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "51c3c638",
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = np.corrcoef(df_train_pca.transpose())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "469fc042",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e3fdc23f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.00000000e+00, -2.92919637e-07,  2.09144858e-07, ...,\n",
       "         1.80826532e-05,  2.82094580e-06,  3.42166894e-06],\n",
       "       [-2.92919637e-07,  1.00000000e+00, -1.49875986e-07, ...,\n",
       "         7.22217252e-05, -2.32589351e-05,  1.01608309e-05],\n",
       "       [ 2.09144858e-07, -1.49875986e-07,  1.00000000e+00, ...,\n",
       "        -2.89197403e-05,  2.08158247e-05,  6.39965825e-05],\n",
       "       ...,\n",
       "       [ 1.80826532e-05,  7.22217252e-05, -2.89197403e-05, ...,\n",
       "         1.00000000e+00, -2.38006794e-02,  6.16292151e-02],\n",
       "       [ 2.82094580e-06, -2.32589351e-05,  2.08158247e-05, ...,\n",
       "        -2.38006794e-02,  1.00000000e+00, -2.04525420e-02],\n",
       "       [ 3.42166894e-06,  1.01608309e-05,  6.39965825e-05, ...,\n",
       "         6.16292151e-02, -2.04525420e-02,  1.00000000e+00]])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrmat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5852693",
   "metadata": {},
   "source": [
    "### Applying the transformation on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "76137d7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 70)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2d03012a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6304, 50)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test_pca = pca_final.transform(X_test_ori)\n",
    "df_test_pca.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8128fc2c",
   "metadata": {},
   "source": [
    "## Applying logistic regression on the data on our Principal components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "af703228",
   "metadata": {},
   "outputs": [],
   "source": [
    "learner_pca = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "c9149f26",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pca = learner_pca.fit(df_train_pca, y_resampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fadaff5",
   "metadata": {},
   "source": [
    "### Making predictions on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "9da7cae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_probs_test = model_pca.predict_proba(df_test_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "98027341",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.8'"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"{:2.2}\".format(metrics.roc_auc_score(y_test, pred_probs_test[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169fcb86-5c15-4af0-9f41-bf1337d8df35",
   "metadata": {},
   "source": [
    "##### So we could see the accuracy coming to 80%.\n",
    "We got a rough idea with PCA and Logistic Regression.\n",
    "We now move to Lasso and Ridge Regression for further analysis and actual conclusion on right predictors and coefficients.\n",
    "Let's try other models to see how it performs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbe4de2-2ddd-4477-bdf8-bec63bad5f83",
   "metadata": {},
   "source": [
    "### Ridge and Lasso Regression\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e41d1e-68ee-4f8f-ac7c-d1295a41a737",
   "metadata": {},
   "source": [
    "#### Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "7ac62178-e44d-44d4-a66a-7f01e6dcaa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 28 candidates, totalling 140 fits\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3,\n",
       "                                   0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0,\n",
       "                                   4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50,\n",
       "                                   100, 500, 1000]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             verbose=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={&#x27;alpha&#x27;: [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3,\n",
       "                                   0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0,\n",
       "                                   4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50,\n",
       "                                   100, 500, 1000]},\n",
       "             return_train_score=True, scoring=&#x27;neg_mean_absolute_error&#x27;,\n",
       "             verbose=1)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=Ridge(),\n",
       "             param_grid={'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, 0.2, 0.3,\n",
       "                                   0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0,\n",
       "                                   4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50,\n",
       "                                   100, 500, 1000]},\n",
       "             return_train_score=True, scoring='neg_mean_absolute_error',\n",
       "             verbose=1)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# list of alphas to tune - if value too high it will lead to underfitting, if it is too low, \n",
    "# it will not handle the overfitting\n",
    "params = {'alpha': [0.0001, 0.001, 0.01, 0.05, 0.1, \n",
    " 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9, 1.0, 2.0, 3.0, \n",
    " 4.0, 5.0, 6.0, 7.0, 8.0, 9.0, 10.0, 20, 50, 100, 500, 1000 ]}\n",
    "\n",
    "ridge = Ridge()\n",
    "\n",
    "# cross validation\n",
    "folds = 5\n",
    "model_cv = GridSearchCV(estimator = ridge, \n",
    "                        param_grid = params, \n",
    "                        scoring= 'neg_mean_absolute_error',  \n",
    "                        cv = folds, \n",
    "                        return_train_score=True,\n",
    "                        verbose = 1)  \n",
    "\n",
    "\n",
    "model_cv.fit(X_train_ori, y_train_ori)   #### Question: It should be run on smote date ? if yes, should we perform test/train split on new smote data?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "64ef3402-9e82-4f08-abf7-da8a954dcc15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.2}\n"
     ]
    }
   ],
   "source": [
    "# Printing the best hyperparameter alpha\n",
    "print(model_cv.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "2630e3d7-1bd8-4b0e-a28b-33a97c0c59e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Ridge(alpha=0.2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" checked><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Ridge</label><div class=\"sk-toggleable__content\"><pre>Ridge(alpha=0.2)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "Ridge(alpha=0.2)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting Ridge model for alpha = 9.0 and printing coefficients which have been penalised\n",
    "alpha = .2\n",
    "\n",
    "ridge = Ridge(alpha=alpha)\n",
    "        \n",
    "ridge.fit(X_train, y_train) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "d1458459-eb5b-4b64-8c53-496ae8ce9f5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_alpha</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>...</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_train_score</th>\n",
       "      <th>split1_train_score</th>\n",
       "      <th>split2_train_score</th>\n",
       "      <th>split3_train_score</th>\n",
       "      <th>split4_train_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>std_train_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.023257</td>\n",
       "      <td>0.003675</td>\n",
       "      <td>0.004093</td>\n",
       "      <td>0.001358</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>{'alpha': 0.0001}</td>\n",
       "      <td>-0.123371</td>\n",
       "      <td>-0.129412</td>\n",
       "      <td>-0.121247</td>\n",
       "      <td>-0.117858</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123464</td>\n",
       "      <td>0.003889</td>\n",
       "      <td>28</td>\n",
       "      <td>-0.122060</td>\n",
       "      <td>-0.120269</td>\n",
       "      <td>-0.122520</td>\n",
       "      <td>-0.123028</td>\n",
       "      <td>-0.121376</td>\n",
       "      <td>-0.121851</td>\n",
       "      <td>0.000959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.019398</td>\n",
       "      <td>0.000930</td>\n",
       "      <td>0.003069</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>{'alpha': 0.001}</td>\n",
       "      <td>-0.123325</td>\n",
       "      <td>-0.129368</td>\n",
       "      <td>-0.121199</td>\n",
       "      <td>-0.117824</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123421</td>\n",
       "      <td>0.003886</td>\n",
       "      <td>27</td>\n",
       "      <td>-0.122021</td>\n",
       "      <td>-0.120225</td>\n",
       "      <td>-0.122477</td>\n",
       "      <td>-0.122992</td>\n",
       "      <td>-0.121331</td>\n",
       "      <td>-0.121809</td>\n",
       "      <td>0.000962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.019766</td>\n",
       "      <td>0.000383</td>\n",
       "      <td>0.003173</td>\n",
       "      <td>0.000140</td>\n",
       "      <td>0.0100</td>\n",
       "      <td>{'alpha': 0.01}</td>\n",
       "      <td>-0.122929</td>\n",
       "      <td>-0.129009</td>\n",
       "      <td>-0.120797</td>\n",
       "      <td>-0.117541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.123058</td>\n",
       "      <td>0.003868</td>\n",
       "      <td>26</td>\n",
       "      <td>-0.121703</td>\n",
       "      <td>-0.119860</td>\n",
       "      <td>-0.122126</td>\n",
       "      <td>-0.122700</td>\n",
       "      <td>-0.120958</td>\n",
       "      <td>-0.121469</td>\n",
       "      <td>0.000985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020324</td>\n",
       "      <td>0.000590</td>\n",
       "      <td>0.003159</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>{'alpha': 0.05}</td>\n",
       "      <td>-0.122084</td>\n",
       "      <td>-0.128271</td>\n",
       "      <td>-0.119976</td>\n",
       "      <td>-0.116946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122310</td>\n",
       "      <td>0.003838</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.121046</td>\n",
       "      <td>-0.119113</td>\n",
       "      <td>-0.121446</td>\n",
       "      <td>-0.122110</td>\n",
       "      <td>-0.120221</td>\n",
       "      <td>-0.120787</td>\n",
       "      <td>0.001037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.020361</td>\n",
       "      <td>0.000446</td>\n",
       "      <td>0.003267</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>{'alpha': 0.1}</td>\n",
       "      <td>-0.121740</td>\n",
       "      <td>-0.127995</td>\n",
       "      <td>-0.119735</td>\n",
       "      <td>-0.116757</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122053</td>\n",
       "      <td>0.003815</td>\n",
       "      <td>2</td>\n",
       "      <td>-0.120825</td>\n",
       "      <td>-0.118849</td>\n",
       "      <td>-0.121248</td>\n",
       "      <td>-0.121909</td>\n",
       "      <td>-0.119995</td>\n",
       "      <td>-0.120565</td>\n",
       "      <td>0.001059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_alpha  \\\n",
       "0       0.023257      0.003675         0.004093        0.001358       0.0001   \n",
       "1       0.019398      0.000930         0.003069        0.000258       0.0010   \n",
       "2       0.019766      0.000383         0.003173        0.000140       0.0100   \n",
       "3       0.020324      0.000590         0.003159        0.000198       0.0500   \n",
       "4       0.020361      0.000446         0.003267        0.000090       0.1000   \n",
       "\n",
       "              params  split0_test_score  split1_test_score  split2_test_score  \\\n",
       "0  {'alpha': 0.0001}          -0.123371          -0.129412          -0.121247   \n",
       "1   {'alpha': 0.001}          -0.123325          -0.129368          -0.121199   \n",
       "2    {'alpha': 0.01}          -0.122929          -0.129009          -0.120797   \n",
       "3    {'alpha': 0.05}          -0.122084          -0.128271          -0.119976   \n",
       "4     {'alpha': 0.1}          -0.121740          -0.127995          -0.119735   \n",
       "\n",
       "   split3_test_score  ...  mean_test_score  std_test_score  rank_test_score  \\\n",
       "0          -0.117858  ...        -0.123464        0.003889               28   \n",
       "1          -0.117824  ...        -0.123421        0.003886               27   \n",
       "2          -0.117541  ...        -0.123058        0.003868               26   \n",
       "3          -0.116946  ...        -0.122310        0.003838                7   \n",
       "4          -0.116757  ...        -0.122053        0.003815                2   \n",
       "\n",
       "   split0_train_score  split1_train_score  split2_train_score  \\\n",
       "0           -0.122060           -0.120269           -0.122520   \n",
       "1           -0.122021           -0.120225           -0.122477   \n",
       "2           -0.121703           -0.119860           -0.122126   \n",
       "3           -0.121046           -0.119113           -0.121446   \n",
       "4           -0.120825           -0.118849           -0.121248   \n",
       "\n",
       "   split3_train_score  split4_train_score  mean_train_score  std_train_score  \n",
       "0           -0.123028           -0.121376         -0.121851         0.000959  \n",
       "1           -0.122992           -0.121331         -0.121809         0.000962  \n",
       "2           -0.122700           -0.120958         -0.121469         0.000985  \n",
       "3           -0.122110           -0.120221         -0.120787         0.001037  \n",
       "4           -0.121909           -0.119995         -0.120565         0.001059  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_result_r = pd.DataFrame(model_cv.cv_results_)\n",
    "cv_result_r['param_alpha'] = cv_result_r['param_alpha'].astype('float32')\n",
    "cv_result_r.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "325a426e-73ce-43ec-a3e9-51bf96cf5546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1152x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(16,8))\n",
    "plt.plot(cv_result_r['param_alpha'],cv_result_r['mean_train_score'])\n",
    "plt.plot(cv_result_r['param_alpha'],cv_result_r['mean_test_score'])\n",
    "plt.xscale('log')\n",
    "plt.ylabel('R2 Score')\n",
    "plt.xlabel('Alpha')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc841c3a-67da-4c65-ad08-8593c0bbc2bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
